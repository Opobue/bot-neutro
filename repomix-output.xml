This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/**/*, internal/**/*, lib/**/*, contracts/**/*, docs/**/*
- Files matching these patterns are excluded: node_modules/**/*, build/**/*, dist/**/*, **/*.pyc
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
docs/02_ESTADO_Y_NORTE.md
docs/adr/ADR_TEMPLATE.md
docs/BOOTSTRAP_SKB_HILO.md
docs/CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md
docs/CONFIG/ENV_VARS.md
docs/CONTRATO_API_PUBLICA_V1.md
docs/CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md
docs/CONTRATO_NEUTRO_API.md
docs/CONTRATO_NEUTRO_AUDIO_PIPELINE.md
docs/CONTRATO_NEUTRO_AUDIO_STATS_V1.md
docs/CONTRATO_NEUTRO_AUDIO.md
docs/CONTRATO_NEUTRO_CONTRIBUCION.md
docs/CONTRATO_NEUTRO_EVENTOS.md
docs/CONTRATO_NEUTRO_HEADERS.md
docs/CONTRATO_NEUTRO_LLM_TIERS_COSTOS_V1.md
docs/CONTRATO_NEUTRO_LLM.md
docs/CONTRATO_NEUTRO_OBSERVABILIDAD.md
docs/CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md
docs/CONTRATO_NEUTRO_RATE_LIMIT.md
docs/CONTRATO_NEUTRO_SESIONES_STORAGE_V1.md
docs/CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md
docs/CONTRATO_SKB_GOBERNANZA.md
docs/DECISIONES/DECISION_POLITICA_SESIONES_AUDIO_V1_20251217.md
docs/GOBERNANZA/KAIZEN_GUARDRAILS.md
docs/HISTORIAL_PR.md
docs/LEGACY_SENSEI_MAP.md
docs/MATRIZ_CUMPLIMIENTO_CONTRATOS.md
docs/MUNAY_CONTRATO_MODULO_AUDIO.md
docs/MUNAY_CONTRATO_PROGRESO_USUARIO.md
docs/MUNAY_GOB_GLOBAL.md
docs/NEUTRO_MIGRATION_PLAN.md
docs/NEUTRO_OVERVIEW.md
docs/NEUTRO_SLO_AUDIO_OPERACIONAL.md
docs/NEUTRO_STARTER_KIT.md
docs/ORDEN_KAIZEN_L1_AUDITORIA_20251217.md
docs/PLANTILLA_ORDEN_EJECUCION_KAIZEN.md
docs/prometheus_rules_slo_audio.yml
docs/ROADMAP_CAPA_SUPERIOR_V1.md
docs/RUNBOOK_AZURE_SPEECH.md
docs/RUNBOOK_LLM.md
docs/UX_CLIENTE_OFICIAL_MUNAY_V1.md
src/bot_neutro/__init__.py
src/bot_neutro/api.py
src/bot_neutro/audio_pipeline.py
src/bot_neutro/audio_storage.py
src/bot_neutro/llm_tiers.py
src/bot_neutro/metrics_runtime.py
src/bot_neutro/middleware/__init__.py
src/bot_neutro/middleware/correlation.py
src/bot_neutro/middleware/logging.py
src/bot_neutro/middleware/rate_limit.py
src/bot_neutro/middleware/request_latency.py
src/bot_neutro/providers/__init__.py
src/bot_neutro/providers/azure.py
src/bot_neutro/providers/factory.py
src/bot_neutro/providers/interfaces.py
src/bot_neutro/providers/openai_llm.py
src/bot_neutro/providers/stub.py
src/bot_neutro/security_ids.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="docs/CONTRATO_NEUTRO_API.md">
# Contrato Neutro de API HTTP

Este contrato define las rutas HTTP base del Bot Neutro. Cualquier bot derivado debe preservar rutas, semántica y headers básicos.

Los endpoints `/text` y `/actions` son opcionales: forman parte del contrato recomendado del Bot Neutro, pero una implementación mínima puede omitirlos siempre que preserve `/healthz`, `/readyz`, `/version`, `/metrics` y `/audio`.

## Endpoints core

### `/healthz`
- **Método**: `GET`
- **Objetivo**: Comprobación de salud básica.
- **Headers relevantes**: `X-Correlation-Id` opcional para trazabilidad.
- **Response (200)**:
```
{}
```

### `/readyz`
- **Método**: `GET`
- **Objetivo**: Verifica dependencias mínimas para readiness.
- **Headers relevantes**: `X-Correlation-Id` opcional.
- **Response (200)**:
```
{}
```

### `/version`
- **Método**: `GET`
- **Objetivo**: Exponer versión desplegada.
- **Headers relevantes**: `X-Correlation-Id` opcional.
- **Response (200)** (ejemplo simplificado):
```
{"version": "<hash|tag>"}
```

### `/metrics`
- **Método**: `GET`
- **Objetivo**: Exponer métricas Prometheus.
- **Headers relevantes**: `content-type: text/plain; version=0.0.4; charset=utf-8`
- **Response (200)**: payload Prometheus con métricas como `sensei_request_latency_seconds_bucket`.

### `/audio`
- **Método**: `POST`
- **Objetivo**: Procesar audio entrante (STT → LLM → TTS si aplica).
- **Headers relevantes**:
  - `X-API-Key` si la autenticación está habilitada.
  - `X-Correlation-Id` para trazabilidad.
  - `X-Outcome` / `X-Outcome-Detail` en la respuesta para estado.
- **Request** (`multipart/form-data`):
```
----boundary
Content-Disposition: form-data; name="file"; filename="sample.wav"
Content-Type: audio/wav

<bytes>
----boundary--
```
- **Response (200)** (ejemplo simplificado):
```
{
  "transcript": "hola mundo",
  "reply_text": "respuesta generada",
  "audio_url": "https://.../tts.wav"
}
```

### `/text` (si está disponible)
- **Método**: `POST`
- **Objetivo**: Procesar texto directo a través del LLM.
- **Headers relevantes**: `X-API-Key`, `X-Correlation-Id`, `X-Outcome`.
- **Request** (ejemplo simplificado):
```
{"message": "hola"}
```
- **Response (200)**:
```
{"reply_text": "respuesta generada"}
```

### `/actions` (si está disponible)
- **Método**: `POST`
- **Objetivo**: Ejecutar acciones externas derivadas del LLM.
- **Headers relevantes**: `X-API-Key`, `X-Correlation-Id`, `X-Outcome`.
- **Request** (ejemplo simplificado):
```
{
  "action": "call_webhook",
  "payload": {"foo": "bar"}
}
```
- **Response (200)**:
```
{"status": "accepted"}
```

## Semántica de headers y contratos relacionados
- Los headers estándar están definidos en [CONTRATO_NEUTRO_HEADERS](./CONTRATO_NEUTRO_HEADERS.md).
- Observabilidad y métricas del endpoint `/metrics` se detallan en [CONTRATO_NEUTRO_OBSERVABILIDAD](./CONTRATO_NEUTRO_OBSERVABILIDAD.md).
- Reglas de rate limit aplicables a `/audio`, `/text` y `/actions` se describen en [CONTRATO_NEUTRO_RATE_LIMIT](./CONTRATO_NEUTRO_RATE_LIMIT.md).

## Compatibilidad con tests actuales
- Las rutas `/healthz`, `/readyz`, `/version`, `/metrics` y `/audio` coinciden con las verificadas por los tests existentes.
- El `content-type` del endpoint `/metrics` se alinea con las aserciones de la suite de métricas.
- La inclusión de `X-Outcome` y `X-Outcome-Detail` refleja los checks de rate limit y manejo de errores sin modificar código en `src/`.
</file>

<file path="docs/CONTRATO_NEUTRO_EVENTOS.md">
# Contrato Neutro de Eventos

Define los eventos lógicos que el Bot Neutro debe reconocer y reflejar en observabilidad y logging.

## Eventos lógicos principales
- **Request recibido**: entrada a cualquier endpoint (`/audio`, `/text`, `/actions`, health checks).
- **Respuesta generada**: resultado exitoso de LLM o acción.
- **Error de proveedor**: fallos de STT/TTS/LLM u otras dependencias.
- **Rate limit alcanzado**: request bloqueado por límites configurados.
- **Validación fallida**: errores de formato o contenido en la solicitud.

## Representación
- **Logs JSON**: incluyen `event_type`, `corr_id` (poblado desde el header `X-Correlation-Id`), `outcome`, ruta y metadatos relevantes.
- **Métricas Prometheus**: contadores y histogramas reflejan volúmenes, errores y latencias por evento/ruta.

## Extensión futura
- Colas, webhooks u otros sistemas de mensajería deberán alinearse con estos eventos lógicos para mantener coherencia de trazas y métricas.

## Compatibilidad con tests actuales
- Los eventos de rate limit y errores se reflejan en los contadores que la suite valida (`errors_total`, `sensei_rate_limit_hits_total`).
- La generación de respuestas exitosas y su latencia están cubiertas por los histogramas verificados en tests de métricas.
- No introduce nuevas rutas ni cambios de comportamiento, asegurando que la suite existente siga pasando en verde.
</file>

<file path="docs/CONTRATO_NEUTRO_HEADERS.md">
# Contrato Neutro de Headers

Los headers estándar aseguran trazabilidad y uniformidad en las respuestas del Bot Neutro y sus derivados.

## Headers principales
- **`X-Outcome`**: estado general de la respuesta. Valores esperados: `ok` | `error`.
- **`X-Outcome-Detail`**: contexto adicional cuando `X-Outcome=error` (ej.: `rate_limit`, `provider_failure`, `validation_error`).
- **`X-Correlation-Id`**: identificador de trazabilidad propagado entre servicios y logs.

### Semántica de `X-Outcome` y `X-Outcome-Detail`

- `X-Outcome` **es obligatorio** en todas las respuestas:
  - `ok` para respuestas 2xx.
  - `error` para respuestas 4xx y 5xx.

- `X-Outcome-Detail` **solo se incluye cuando `X-Outcome=error`**:
  - Debe contener una clave estable de error (ej.: `audio.bad_request`, `auth.unauthorized`, `audio.stt_error`).
  - No se envía en respuestas 2xx por defecto.

- En consecuencia:
  - Las respuestas exitosas (`2xx`) del Bot Neutro exponen `X-Outcome: ok` y **no incluyen** `X-Outcome-Detail`.
  - Cualquier error manejado debe exponer `X-Outcome: error` junto con un `X-Outcome-Detail` específico según el contrato correspondiente (audio, auth, rate-limit, etc.).

## Uso en middleware y endpoints
- Todos los endpoints deben preservar estos headers, incluidos los añadidos por bots derivados.
- En logs JSON estructurados, el valor de `X-Correlation-Id` se representa en el campo `corr_id`, usado para correlacionar trazas y métricas.
- En respuestas 429 por rate limit, `X-Outcome` se fija en `error` y `X-Outcome-Detail` en `rate_limit`.

## Compatibilidad con tests actuales
- Los tests de rate limit verifican la presencia de `X-Outcome` y `X-Outcome-Detail` en respuestas 429.
- La propagación de `X-Correlation-Id` mantiene la trazabilidad usada por las pruebas de métricas y logging.
- No se altera ninguna ruta ni lógica existente, manteniendo `pytest -q` y `pytest -k metrics -q` en verde.
</file>

<file path="docs/LEGACY_SENSEI_MAP.md">
# Mapa de código legacy de SenseiKaizen

| Ruta | Rol actual | ¿Usado por el Bot Neutro HTTP? | Prioridad para limpieza | Notas | Fase sugerida | Acción objetivo |
| --- | --- | --- | --- | --- | --- | --- |
| `src/sensei/config.py` | Configuración histórica con validaciones y helpers ligados al bot original (Notion, Google, scheduler, etc.). | Dudoso (se usa por compatibilidad en algunos tests pero no es la fuente principal del HTTP neutro). | Alta | Requiere separar constantes neutras de credenciales y lógicas heredadas; mover a paquete específico o eliminar en favor de `settings.py`. | F2/F3 | Refactor para separar settings neutros de lógica legacy; no borrar de golpe. |
| `src/sensei/integrations/notion_wrapper.py` | Shim que bloquea la antigua integración con Notion. | No | Alta | Mantener aislado; mover a repositorio de bot específico o borrar cuando se elimine dependencia. | F3 | Mover a repo legacy de integraciones externas. |
| `src/sensei/integrations/supabase_wrapper.py` | Accesos directos a tablas de Supabase para hábitos/compras/entregables. | No | Alta | Candidato a extracción completa a bot específico; requiere tests dedicados si se mantiene. | F3 | Extraer a módulo opcional para hábitos/compras. |
| `src/sensei/services/gcal.py` | Cliente de Google Calendar (service account) usado por el bot viejo. | No | Media | Puede moverse a proveedor opcional; actualmente sin uso en rutas HTTP neutras. | F3 | Mover a paquete gcal opcional o repo aparte. |
| `src/sensei/calendar_utils.py` | Stubs de utilidades de Calendar para compatibilidad con código antiguo. | No | Media | Extraíble junto con `services/gcal.py` una vez se eliminen dependencias. | F3 | Mover a paquete gcal opcional o repo aparte. |
| `src/sensei/schedule_utils.py` | Helper de scheduling (APScheduler) para check-ins heredados. | No | Media | No usado por el contrato HTTP; se puede aislar o eliminar tras confirmar ausencia en runtimes. | F3 | Extraer o eliminar tras validar que no impacta Bot Neutro. |
| `gcal_utils.py` | Wrapper de conveniencia que recarga el servicio de Calendar legacy. | No | Media | Dependencia auxiliar de `services/gcal.py`; mover junto con integración o retirar. | F3 | Mover a paquete gcal opcional o repo aparte. |
| `tests/__init__.py` | Bootstrap de pruebas con stubs de Notion, APScheduler, Rich y rate limit para el stack legacy. | Dudoso | Media | Mezcla configuraciones neutras con soportes legacy; dividir fixtures cuando se separe el código. | F2/F3 | Refactor de fixtures para separar neutral vs legacy. |
| `tests/unit/test_config_extra.py` | Cobertura de la configuración heredada en `config.py`. | No | Media | Podría migrarse a suite de bot específico o eliminarse tras retirar `config.py`. | F2/F3 | Mover a suite legacy o eliminar tras refactor de config. |
| `tests/unit/test_check_config_modes.py` | Valida restricciones legacy (modos TTS/STT en `config.py`). | No | Media | Se puede eliminar junto con la configuración heredada. | F2/F3 | Mover a suite legacy o eliminar cuando se retire config. |
| `tests/unit/test_supabase_wrapper.py` | Verifica que los accesos Supabase legacy devuelven listas. | No | Alta | Depende directamente de integración legacy; remover al extraer Supabase. | F3 | Mover a suite de tests legacy; no requerido por Bot Neutro. |
| `tests/integration/test_supabase.py` | Smoke test de la integración Supabase legacy. | No | Alta | Igual que el unitario: mover o eliminar con la integración. | F3 | Mover a suite de tests legacy; no requerido por Bot Neutro. |
| `tests/unit/test_gcal_utils.py` | Pruebas del wrapper de Google Calendar legacy. | No | Media | Remover al extraer gcal. | F3 | Mover a suite legacy o eliminar con la extracción gcal. |
| `tests/unit/test_report_daily.py` | Valida script legacy de reportes diarios sobre base SQLite. | No | Media | Asociado a pipelines heredados; evaluar si se mantiene en repositorio aparte. | F4 | Mantener solo si se preserva el pipeline legacy de reportes; de lo contrario, eliminar. |

Las columnas "Fase sugerida" y "Acción objetivo" se alinean con
[NEUTRO_MIGRATION_PLAN](./NEUTRO_MIGRATION_PLAN.md) y sirven como guía
para futuras órdenes Kaizen de limpieza. Esta orden L5 no mueve ni elimina
ningún archivo; solo documenta el plan.
</file>

<file path="docs/MUNAY_CONTRATO_PROGRESO_USUARIO.md">
# Munay: Contrato de Progreso de Usuario

Este contrato describe cómo Munay modela y consulta el progreso diario del usuario, enlazando eventos de audio procesados por el Bot Neutro.

## Entidad `munay_progress_daily`

| Campo                | Descripción                                      |
| -------------------- | ------------------------------------------------ |
| `user_id`            | Identificador interno de usuario en Munay.       |
| `date`               | Fecha (YYYY-MM-DD).                              |
| `acts_of_self_care`  | Conteo de acciones de autocuidado.               |
| `journal_entries`    | Conteo de entradas de diario (`journal_entry`).  |
| `coach_interactions` | Conteo de interacciones de coaching de hábitos.  |
| `insights`           | Conteo de insights (`insight`).                  |
| `crisis_flags`       | Conteo de flags de crisis (`crisis_flag`).       |
| `streak_days`        | Racha de días consecutivos con actividad.        |
| `last_updated_at`    | Timestamp de última actualización.               |

## Relación con eventos y sesiones de audio

Cada fila de `munay_progress_daily` se alimenta a partir de `munay_event`, y cada evento referencia el `audio_session` correspondiente proveniente del Bot Neutro.

## Endpoint de consulta

- `GET /munay/users/{user_id}/progress`
- Respuesta JSON de ejemplo:

```json
{
  "user_id": "user-123",
  "date": "2024-06-01",
  "acts_of_self_care": 2,
  "journal_entries": 1,
  "coach_interactions": 1,
  "insights": 1,
  "crisis_flags": 0,
  "streak_days": 5,
  "last_updated_at": "2024-06-01T18:30:00Z"
}
```

Todas las respuestas incluyen `X-Correlation-Id` y respetan los headers estándar del Bot Neutro.
</file>

<file path="docs/NEUTRO_MIGRATION_PLAN.md">
# Plan de migración: Bot Neutro vs código legacy SenseiKaizen

Este documento define las fases para migrar el repositorio actual
hacia un Bot Neutro limpio, separando el código legacy específico
de SenseiKaizen sin romper el contrato HTTP ni la suite de tests.

## Fases de migración (alto nivel)

- **Fase 0 — Estado actual (ahora)**
  - Bot Neutro definido por los contratos `NEUTRO_*` y `CONTRATO_NEUTRO_*`.
  - Código legacy etiquetado con comentarios `LEGACY_NEUTRO` / `LEGACY_NEUTRO (MIXTO)`.
  - Ninguna funcionalidad legacy ha sido eliminada.

- **Fase 1 — Aislar dependencias legacy en el mapa**
  - Usar `LEGACY_SENSEI_MAP.md` como fuente de verdad de qué es legacy.
  - Marcar en el mapa el destino previsto de cada módulo (eliminar, mover a repo aparte, mantener como opcional).
  - No tocar aún los módulos; solo actualizar documentación.

- **Fase 2 — Clonar Bot Neutro mínimo en nuevo repo**
  - Usar `NEUTRO_STARTER_KIT.md` como guía para crear un repo nuevo con solo:
    - Core HTTP (`/healthz`, `/readyz`, `/version`, `/metrics`, `/audio`).
    - Middleware, métricas y settings requeridos por el contrato neutro.
  - Excluir cualquier módulo marcado como `LEGACY_NEUTRO` salvo que se documente lo contrario.

- **Fase 3 — Extraer integraciones legacy**
  - Mover integraciones como Supabase, Notion, Google Calendar y schedulers a:
    - Un repo “sensei-legacy”, o
    - Un paquete opcional, documentado como extensión.
  - Ajustar los tests para que el Bot Neutro no dependa de esas integraciones.

- **Fase 4 — Limpieza final del repo original**
  - Una vez el clon Neutro tenga CI/test en verde, decidir:
    - Si el repo actual se congela como legacy.
    - O si se hace limpieza final (remover archivos legacy de este mismo repo).

## Criterios para decidir qué es “Neutro” vs “Legacy”

- Es **Neutro** si:
  - Lo referencian los contratos `CONTRATO_NEUTRO_*`.
  - Es necesario para `/healthz`, `/readyz`, `/version`, `/metrics`, `/audio`.
  - Lo cubren tests que validan el contrato HTTP/observabilidad.

- Es **Legacy** si:
  - Está etiquetado con `LEGACY_NEUTRO`.
  - Depende de integraciones concretas: Notion, Supabase, Google Calendar, APScheduler de check-ins antiguos, scripts de reportes diarios, etc.
  - No es requerido por el Bot Neutro ni por los tests de contratos neutros.

## Reglas de seguridad antes de tocar código legacy

- No borrar módulos legacy sin antes:
  - Quitar sus tests o moverlos a otro repo.
  - Confirmar que `pytest -q` sigue en verde.
- No modificar endpoints `/healthz`, `/readyz`, `/version`, `/metrics`, `/audio` sin actualizar primero los contratos `CONTRATO_NEUTRO_*`.
- Cualquier cambio que afecte a legacy debe referenciar explícitamente:
  - `LEGACY_SENSEI_MAP.md`
  - `NEUTRO_MIGRATION_PLAN.md`

## Compatibilidad con la suite actual

Este plan de migración es solo documental.
No introduce cambios en `src/` ni en la configuración de tests.
Después de crear y mantener este archivo, los comandos
`pytest -q` y `pytest -k metrics -q` deben seguir pasando en verde.
</file>

<file path="docs/NEUTRO_OVERVIEW.md">
# Bot Neutro: Overview

El **Bot Neutro** es la base común para bots como Munay y futuras variantes. Define contratos estables para API HTTP, audio, texto, acciones, observabilidad, headers, rate limit y el uso de LLMs sin imponer detalles de negocio. Este documento actúa como punto de entrada y referencia cruzada hacia los contratos específicos.

## Propósito
- Establecer un contrato homogéneo que mantenga compatibilidad con las pruebas actuales.
- Asegurar que cualquier bot derivado respete las mismas rutas, semántica de headers y expectativas de observabilidad.
- Servir como guía de referencia rápida para integradores y equipos que extienden el sistema.

## Componentes definidos
- **API HTTP neutra**: rutas base `/healthz`, `/readyz`, `/version`, `/metrics`, `/audio`, `/text`, `/actions` (según disponibilidad), con semántica y headers comunes.
- Los endpoints `/text` y `/actions` son opcionales: forman parte del contrato recomendado del Bot Neutro, pero una implementación mínima puede omitirlos siempre que preserve `/healthz`, `/readyz`, `/version`, `/metrics` y `/audio`.
- **Headers estándar**: trazabilidad (`X-Correlation-Id`) y estado (`X-Outcome`, `X-Outcome-Detail`).
- **Observabilidad**: endpoint `/metrics` con exportación Prometheus, métricas núcleo y SLOs orientativos.
- **Rate limit**: política de allowlist y semántica de respuestas 429.
- **Audio**: contrato de entrada/salida para `/audio` y su integración con métricas y usage.
- **LLM**: expectativas de latencia, manejo de errores y rol como "cerebro" agnóstico al proveedor.
- **Eventos lógicos**: trazabilidad mediante logs JSON y métricas.

## Reutilización para Munay y otros bots
- Los bots derivados deben reutilizar este contrato como baseline, preservando rutas, headers y comportamiento observable.
- Extensiones específicas (nuevos endpoints o acciones) pueden añadirse siempre que mantengan coherencia con observabilidad y rate limit.
- Las pruebas existentes sirven como red de seguridad para garantizar que el contrato neutro sigue vigente.

## Contratos relacionados
- [Contrato de API neutra](./CONTRATO_NEUTRO_API.md)
- [Contrato de headers](./CONTRATO_NEUTRO_HEADERS.md)
- [Contrato de observabilidad](./CONTRATO_NEUTRO_OBSERVABILIDAD.md)
- [Contrato de rate limit](./CONTRATO_NEUTRO_RATE_LIMIT.md)
- [Contrato de audio](./CONTRATO_NEUTRO_AUDIO.md)
- [Contrato de LLM](./CONTRATO_NEUTRO_LLM.md)
- [Contrato de eventos](./CONTRATO_NEUTRO_EVENTOS.md)
- Nuevos contratos Neutro: [Pipeline de audio](./CONTRATO_NEUTRO_AUDIO_PIPELINE.md) y [Storage de sesiones de audio](./CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md).
- Contratos cliente de referencia (Munay): [Módulo de audio](./MUNAY_CONTRATO_MODULO_AUDIO.md) y [Progreso de usuario](./MUNAY_CONTRATO_PROGRESO_USUARIO.md).

## Compatibilidad con tests actuales
- Mantiene la enumeración de endpoints (`/healthz`, `/readyz`, `/version`, `/metrics`, `/audio`) que ya son verificados por la suite.
- Conserva la semántica de headers y content-type descrita en los tests de observabilidad y rate limit.
- No requiere cambios en `src/`, asegurando que `pytest -q` y `pytest -k metrics -q` permanezcan en verde.

## Relación con código legacy

El repositorio actual aún contiene componentes legacy específicos del bot original (SenseiKaizen).
Estos módulos están inventariados en [LEGACY_SENSEI_MAP](./LEGACY_SENSEI_MAP.md) y etiquetados
en el código con el marcador `LEGACY_NEUTRO`. El contrato del Bot Neutro se define de forma
independiente para facilitar la futura extracción o eliminación de ese código legacy.
Para los detalles de cómo se migrará este código legacy y en qué fases,
ver [NEUTRO_MIGRATION_PLAN](./NEUTRO_MIGRATION_PLAN.md).
</file>

<file path="docs/NEUTRO_STARTER_KIT.md">
# Starter Kit del Bot Neutro

## Propósito del Starter Kit
- Define el **mínimo conjunto de archivos** necesario para clonar un bot en blanco alineado al contrato neutro.
- Sirve como base para bots como Munay u otros derivados que compartan la misma arquitectura HTTP y de observabilidad.
- Es 100% compatible con la suite actual (`pytest -q`, `pytest -k metrics -q`) sin requerir cambios en código.
- No fija proveedor de LLM ni STT/TTS; establece contratos y estructura para que cada implementación conecte sus propios proveedores.
- Facilita la trazabilidad estándar (headers, logs y métricas) sin imponer lógica de negocio específica.

## Conjunto mínimo de archivos (referencia)
Estos archivos ya existen en el repositorio y conforman la referencia de un Bot Neutro. No se modifican en esta orden; solo se listan para orientar clonados futuros.

- **Core API / HTTP**:
  - `src/sensei/api.py`
  - Rutas principales: `src/sensei/routes/audio.py`, y (si existen) `src/sensei/routes/text.py`, `src/sensei/routes/actions.py`.
- **Middleware y observabilidad**:
  - `src/sensei/middleware/log_json.py`
  - `src/sensei/middleware/observability.py`
  - `src/sensei/middleware/rate_limit.py`
  - `src/sensei/routers/metrics.py` o el módulo equivalente que expone `/metrics`.
- **Autenticación / API keys**:
  - `src/sensei/services/api_keys.py`
- **Providers / LLM / STT / TTS**:
  - `src/sensei/providers/factory.py`
- **Métricas y uso de audio**:
  - `src/sensei/metrics.py`
- **Configuración / settings**:
  - `src/sensei/settings.py`
- **Tests clave que protegen el contrato neutro**:
  - Tests de healthz/readyz/version.
  - Tests de `/metrics` (observabilidad, Prometheus).
  - Tests de rate limit.
  - Tests de `/audio`.

Importante: esta lista es de referencia y no implica mover ni modificar archivos en L3.

## Pasos conceptuales para clonar un Bot Neutro
1. Crear un nuevo repositorio vacío.
2. Copiar la estructura base de `src/sensei` necesaria (sin los módulos opcionales que no se requieran).
3. Copiar los contratos `docs/NEUTRO_OVERVIEW.md` y todos los `CONTRATO_NEUTRO_*.md`.
4. Ajustar el nombre del bot (p. ej., de `sensei` → `munay` en una fase posterior), manteniendo la estructura y los contratos intactos.
5. Preservar los endpoints `/healthz`, `/readyz`, `/version`, `/metrics`, `/audio` y los headers estándar; `/text` y `/actions` pueden omitirse si no se requieren en la versión mínima.

La implementación concreta del nuevo bot se realizará en una fase posterior (otra orden Kaizen), no en L3.

> Nota: en el repositorio actual, los componentes marcados como legacy están documentados
> en [LEGACY_SENSEI_MAP](./LEGACY_SENSEI_MAP.md). Al clonar un Bot Neutro, se recomienda
> incluir solo los módulos alineados al contrato neutro y dejar fuera el código marcado
> como `LEGACY_NEUTRO`, salvo que se necesite explícitamente.

## Relación con los contratos neutros
El starter kit está gobernado por los contratos existentes:
- `NEUTRO_OVERVIEW.md`
- `CONTRATO_NEUTRO_API.md`
- `CONTRATO_NEUTRO_HEADERS.md`
- `CONTRATO_NEUTRO_OBSERVABILIDAD.md`
- `CONTRATO_NEUTRO_RATE_LIMIT.md`
- `CONTRATO_NEUTRO_AUDIO.md`
- `CONTRATO_NEUTRO_LLM.md`
- `CONTRATO_NEUTRO_EVENTOS.md`

Cualquier bot derivado debe seguir estos contratos salvo extensiones explícitamente documentadas.

## Compatibilidad con la suite de tests actual
Este starter kit no introduce cambios en `src/` ni en la configuración actual de tests. Después de crear estos documentos, los comandos `pytest -q` y `pytest -k metrics -q` deben seguir pasando en verde sin modificaciones adicionales.
</file>

<file path="src/bot_neutro/__init__.py">
"""bot-neutro core package."""

__version__ = "0.1.0"

from .api import create_app

__all__ = ["create_app", "__version__"]
</file>

<file path="src/bot_neutro/middleware/correlation.py">
import uuid
from typing import Callable

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response


class CorrelationIdMiddleware(BaseHTTPMiddleware):
    """Ensure every request carries an X-Correlation-Id header."""

    header_name = "X-Correlation-Id"

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        correlation_id = request.headers.get(self.header_name) or str(uuid.uuid4())
        request.state.correlation_id = correlation_id

        response = await call_next(request)
        response.headers[self.header_name] = correlation_id
        return response
</file>

<file path="src/bot_neutro/middleware/logging.py">
import json
import logging
from typing import Callable

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

logger = logging.getLogger("bot_neutro")
logging.basicConfig(level=logging.INFO)


class JSONLoggingMiddleware(BaseHTTPMiddleware):
    """Emit structured JSON logs for inbound requests."""

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        response = await call_next(request)

        payload = {
            "method": request.method,
            "path": request.url.path,
            "status": response.status_code,
            "corr_id": getattr(request.state, "correlation_id", ""),
        }
        logger.info(json.dumps(payload))
        return response
</file>

<file path="docs/adr/ADR_TEMPLATE.md">
# Plantilla ADR

> Todos los cambios de arquitectura, seguridad o SLO/SLA deben documentarse en un ADR usando esta plantilla.

## Título

## ID

(Usar formato `ADR-0001`, `ADR-0002`, ...)

## Estado

(Propuesto | Aprobado | Obsoleto)

## Contexto

## Decisión

## Consecuencias

## Contratos afectados

## Relación con SLO/SLA

## Fecha / Autor
</file>

<file path="docs/CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md">
# CLIENTE_OFICIAL_MUNAY_TECNICO_V1

## Objetivo
Cliente web mínimo para consumir el endpoint `/audio` siguiendo los contratos:
- `docs/CONTRATO_API_PUBLICA_V1.md`
- `docs/CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md`
- `docs/UX_CLIENTE_OFICIAL_MUNAY_V1.md`
- `docs/02_ESTADO_Y_NORTE.md`

## Stack elegido
- React + TypeScript + Vite (SPA simple)
- Ubicación del código: `clients/munay-dashboard/`

## Estructura de carpetas
```
clients/munay-dashboard/
├─ index.html
├─ package.json
├─ tsconfig.json
├─ vite.config.ts
├─ .env.example
└─ src/
   ├─ main.tsx
   ├─ App.tsx
   ├─ styles.css
   ├─ config.ts
   ├─ api/client.ts
   └─ components/
      ├─ AudioUploader.tsx
      └─ ResultPanel.tsx
```

## Variables de entorno
- `VITE_API_BASE_URL`: URL base del backend (ej. `http://127.0.0.1:8000`).
- `VITE_API_KEY`: API Key que se enviará en `X-API-Key`.
- `VITE_DEFAULT_TIER`: tier por defecto (`freemium` o `premium`).

Crear `clients/munay-dashboard/.env.local` copiando de `.env.example` y ajustando valores.

## Comandos de desarrollo
Desde `clients/munay-dashboard/`:
- `npm install` – instala dependencias.
- `npm run dev` – levanta el dashboard en modo desarrollo.
- `npm run build` – verifica que compile para producción.
- `npm run preview` – sirve el build generado.

## Flujo de uso
1. Levantar backend local: `uvicorn bot_neutro.api:app --reload`.
2. Configurar `.env.local` con `VITE_API_BASE_URL`, `VITE_API_KEY`, `VITE_DEFAULT_TIER`.
3. Ejecutar `npm run dev` y abrir el puerto que indique Vite.
4. Seleccionar un archivo de audio (WAV/MP3 recomendado), elegir tier y presionar “Enviar a /audio”.

La consola del navegador loguea: `corr_id`, `usage.total_ms`, `usage.provider_llm`.

## Casos de prueba manual (checklist)
- Caso 1: `freemium`, audio válido, API Key correcta → 200 OK, se visualizan `transcript`, `reply_text`, `usage.total_ms`, `usage.provider_llm`, `corr_id`.
- Caso 2: API Key incorrecta → error 401 claro en UI.
- Caso 3: sin archivo → error 422 claro en UI.
- Caso 4: falta de crédito / modo stub → UI funcional, badge “Modo stub activo”, `provider_llm` con `stub`.

## Observabilidad mínima
- Consola del navegador registra `corr_id`, `usage.total_ms`, `usage.provider_llm` por cada respuesta exitosa.

## Consideraciones de seguridad
- `VITE_API_KEY` se incrusta en el bundle del frontend. Este cliente está pensado para uso local o entornos controlados.
- Para distribuciones públicas se recomienda colocar un backend proxy que firme o valide peticiones en lugar de exponer una API Key estática en el navegador.
</file>

<file path="docs/CONTRATO_NEUTRO_AUDIO_STATS_V1.md">
# CONTRATO_NEUTRO_AUDIO_STATS_V1

## Propósito
Exponer **estadísticas agregadas** del pipeline de audio por tenant (API key), sin permitir lectura/listado de sesiones ni fuga de PII.

## Endpoint
`GET /audio/stats`

### Autenticación
- Requiere `X-API-Key` válida.
- Multi-tenant estricto: responde **solo** con agregados del tenant autenticado.

### Respuesta 200 (JSON)
Campos mínimos:
- `api_key_id`: string (ID derivado; NO es el secreto `X-API-Key`; se usa `sha256(X-API-Key)` en hex y se trunca a 12 chars)
- `totals`:
  - `sessions_current`: int (conteo inspeccionado para el agregado; puede estar capado por `AUDIO_STATS_MAX_SESSIONS`)
  - `limit_applied`: int (valor efectivo aplicado como cap)
  - `sessions_purged_total`: int (contador acumulado del runtime, no por-tenant)
- `by_provider`:
  - `stt`: { "<provider_id>": int }
  - `llm`: { "<provider_id>": int }
  - `tts`: { "<provider_id>": int }

### Prohibiciones (privacidad)
Este endpoint **NO PUEDE** devolver (directa o indirectamente):
- `transcript`, `reply_text`, `meta_tags`, `user_external_id`, `corr_id`, `tts_storage_ref`
- listas de sesiones, ids de sesión ni detalles por sesión

### Errores
- 401 si falta/invalid `X-API-Key` (según el comportamiento actual del core).

## Dependencias
- Debe cumplir `docs/CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md`.
- No desbloquea endpoints de lectura/listado de sesiones.
</file>

<file path="docs/CONTRATO_NEUTRO_AUDIO.md">
# Contrato Neutro de Audio (`/audio`)

Define la interacción de audio para el Bot Neutro, manteniendo neutralidad de proveedor.

## Entrada
- **Endpoint**: `POST /audio`
- **Formato**: `multipart/form-data`
- **Campo**: `file`
- **Tipos aceptados**: audio común (ej.: `audio/wav`, `audio/mpeg`); los tipos exactos dependen de validaciones actuales.
- **Header opcional**: `x-munay-llm-tier` para seleccionar modelo LLM (`freemium`/`premium`, case-insensitive). Valores ausentes o inválidos se tratan como `freemium`.

## Flujo de procesamiento
1. Recepción del archivo y validación básica de tipo/tamaño.
2. Transcripción (STT) a texto.
3. Procesamiento en el LLM con contexto disponible.
4. Generación de respuesta en texto y, si corresponde, síntesis TTS.
5. Respuesta JSON con transcript, texto final y referencia al audio TTS (url o bytes según implementación).

## Respuestas
- **200 OK**: incluye `transcript`, `reply_text` y `audio`/`audio_url` si aplica.
- **415 Unsupported Media Type**: tipo de archivo no soportado.
- **400/500**: errores de validación o internos. Se devuelven con `X-Outcome: error` y `X-Outcome-Detail` apropiado.

## Métricas y observabilidad
- La latencia del request se registra en `sensei_request_latency_seconds_bucket` con etiqueta de ruta `/audio`.
- Errores incrementan `errors_total`.
- Uso de audio puede registrarse vía `UsageMetrics` (segundos, proveedor, fallback) según contrato existente.

## Compatibilidad con tests actuales
- Mantiene el método `POST` y la forma `multipart/form-data` que verifican los tests de audio.
- La integración con métricas de latencia y contadores concuerda con las aserciones en `pytest -k metrics`.
- No altera validaciones ni proveedores, preservando el comportamiento esperado por la suite completa.
</file>

<file path="docs/CONTRATO_NEUTRO_LLM_TIERS_COSTOS_V1.md">
# CONTRATO_NEUTRO_LLM_TIERS_COSTOS_V1

## Propósito y alcance
- Formalizar la gobernanza de tiers LLM en un entorno multi-tenant donde **la API-Key es la fuente de verdad** para determinar el plan autorizado.
- Evitar la escalada unilateral vía header `x-munay-llm-tier`; el header solo es una **solicitud del cliente** que debe validarse contra el plan.
- Establecer la semántica de validación, errores, observabilidad y cuotas/costos **sin implementar todavía la verificación** (se realizará en una orden L2).

## Definiciones
- `tier`: nivel de servicio del LLM. Valores permitidos en V1: `freemium`, `premium`. El contrato es extensible (p. ej. `enterprise`).
- `tier_solicitado`: valor enviado por el cliente en el header `x-munay-llm-tier` (case-insensitive). Si no se envía, se considera ausente.
- `tier_autorizado`: valor determinado **server-side** a partir de la API-Key autenticada. Es la única fuente de verdad.

## Interfaz (request)
- Header opcional `x-munay-llm-tier`:
  - Valores aceptados: `freemium` | `premium` (case-insensitive, se normaliza a minúsculas).
  - Si el header está ausente: se usa `tier_autorizado` por defecto.
  - Si el valor es inválido: se considera **header inválido**. Propuesta de respuesta: `400 Bad Request`, `X-Outcome=error`, `X-Outcome-Detail=llm.tier_invalid`. El estado actual (L1) mantiene compatibilidad degradando a `freemium` para no romper clientes; la validación estricta llegará en L2.

## Fuente de verdad (server-side)
- La API-Key autenticada define el `tier_autorizado` y las cuotas/costos asociadas.
- El header **NO** puede elevar privilegios ni modificar las cuotas; sirve como hint para elegir el modelo dentro del tier autorizado.
- La lógica de validación (L2) debe ejecutarse **antes** de construir el contexto `llm_tier` para el pipeline.

## Reglas de decisión
1) **Header ausente** → usar `tier_autorizado`.
2) **Header presente y válido**:
   - Si `tier_solicitado` ≤ `tier_autorizado` (misma categoría o inferior) → permitido; `context["llm_tier"] = tier_solicitado`.
   - Si `tier_solicitado` > `tier_autorizado` → denegar. Respuesta propuesta: `403 Forbidden`, `X-Outcome=error`, `X-Outcome-Detail=llm.tier_forbidden`.
3) **Header inválido** → proponer `400 Bad Request`, `X-Outcome-Detail=llm.tier_invalid`. (Estado actual: se degrada a `freemium` y sigue la ejecución para no romper contratos previos.)

Nota de orden en V1: `freemium < premium`.

## Respuesta y errores (semántica)
- Headers obligatorios en toda respuesta: `X-Outcome`, `X-Correlation-Id`; `X-Outcome-Detail` cuando aplica un error/bloqueo.
- Códigos/`X-Outcome-Detail` propuestos:
  - `403 Forbidden` + `X-Outcome-Detail=llm.tier_forbidden` cuando el cliente solicita un tier superior al autorizado.
  - `400 Bad Request` + `X-Outcome-Detail=llm.tier_invalid` cuando el header tiene un valor fuera de catálogo.
  - `200 OK` + `X-Outcome` según convención vigente (p. ej. `ok`/`success`) cuando el tier solicitado es aceptado (o ausente y se usa el autorizado).
- Los mensajes de error no deben exponer PII ni la API-Key; se puede incluir un `api_key_id` derivado y `tier_autorizado` en logs internos.

## Observabilidad mínima obligatoria
- **Métrica de denegación**: contador `llm_tier_denied_total{route="/audio", requested_tier, authorized_tier}` que se incrementa cuando `tier_solicitado` > `tier_autorizado`.
- **Errores agregados**: incremento de `errors_total{route="/audio"}` (agregado) en cada denegación.
- **Logs estructurados** (JSON) por request, con al menos: `corr_id` (de `X-Correlation-Id`), `api_key_id` derivado (no secreto), `requested_tier`, `authorized_tier`, `outcome` (`accepted` | `downgraded` | `denied`), `route`.
- **Correlación**: `X-Correlation-Id` debe estar presente siempre; se usa para enlazar métricas, logs y traces.

## Cuotas y costos (política parametrizable)
- Las cuotas se expresan en unidades neutrales para evitar decisiones monetarias prematuras. Referencias iniciales (configurables por env/config en L2):
  - `freemium`: límite diario sugerido de `requests_per_day`, `tokens_per_day`, modelo máximo permitido `freemium`.
  - `premium`: límites superiores o sin tope práctico, con acceso a modelos `premium`.
- Los montos monetarios quedan `TBD` y requieren ADR específico. Este contrato solo fija las unidades y la necesidad de asociarlas a la API-Key.

## Estado de implementación (L1)
- Hoy `/audio` solo normaliza `x-munay-llm-tier` a `context["llm_tier"]` cuando es `freemium|premium` y aplica fallback seguro a `freemium` ante valores faltantes/invalidos.
- **No existe enforcement** contra la API-Key: el header puede solicitar `premium` aunque la key no lo tenga asignado. Esto es el gap a cubrir en L2.
- Métricas y logs de denegación aún no existen; deberán instrumentarse junto con la validación en la orden L2.

## Camino a enforcement (orden L2 futura)
- Implementar la resolución de `tier_autorizado` por API-Key antes de llamar al pipeline.
- Aplicar las reglas de decisión anteriores y devolver los códigos/headers propuestos.
- Instrumentar las métricas `llm_tier_denied_total` e incrementar `errors_total{route="/audio"}` en cada bloqueo.
- Agregar pruebas de runtime (unitarias y contractuales) que cubran: header ausente, tier válido ≤ autorizado, tier superior denegado, header inválido.

## Compatibilidad y bloqueos
- Este contrato no introduce nuevos endpoints ni cambia las firmas existentes; define reglas de validación y observabilidad para futuras implementaciones.
- No debe romper clientes actuales: hasta que se libere L2, el comportamiento observable sigue siendo el actual (fallback a `freemium`).
- Cualquier cambio en catálogo de tiers o modelo de cuotas requiere actualización del contrato y, si es irreversible (p. ej., modelo de cobro), un ADR dedicado.
</file>

<file path="docs/CONTRATO_NEUTRO_OBSERVABILIDAD.md">
# Contrato Neutro de Observabilidad

Define la exposición de métricas y expectativas de SLO para el Bot Neutro. Las implementaciones deben mantener compatibilidad con el endpoint `/metrics` y las métricas núcleo ya presentes.

## Endpoint `/metrics`
- **Método**: `GET`
- **Contenido**: `content-type: text/plain; version=0.0.4; charset=utf-8` (formato Prometheus).
- **Rol**: única fuente de scrape para Prometheus y dashboards.
- **Allowlist**: excluido de rate limit para no bloquear monitoreo.

## Métricas núcleo expuestas
- **Histogram de latencia**: `sensei_request_latency_seconds_bucket` con etiquetas por ruta.
- **Contadores de errores**: `errors_total{route=...}` categorizado por ruta (incluye `/audio`), visibles aun cuando estén en `0` para rutas clave.
- **Rate limit**: `sensei_rate_limit_hits_total` incrementa por cada respuesta 429 emitida por el middleware; se expone con valor `0` antes de observar eventos.
- **Memoria y operaciones**: `mem_reads_total` y `mem_writes_total` cuentan lecturas/escrituras en el repositorio en memoria de sesiones de audio y se publican aun si están en `0`.
- **Requests por ruta**: `sensei_requests_total{route=...}` para volumen y perfil de tráfico, incluyendo `/metrics`.

## SLOs orientativos
- **Latencia audio p95**: `audio_p95_ms ≤ 1500 ms`.
- **Error rate máximo**: `error_rate_max ≤ 1%`.
- **Uptime objetivo**: `uptime_target ≥ 99.9%`.
- **Alertas de budget burn**: disparo en 85% / 90% / 95% del presupuesto de errores o latencia.

## Relación con rate limit y eventos
- Los rechazos por rate limit incrementan `sensei_rate_limit_hits_total` y deben emitirse como eventos de `rate_limit alcanzado`.
- Los fallos de proveedores o validaciones se reflejan en `errors_total` y en logs JSON.
- Las operaciones de almacenamiento de sesiones incrementan `mem_writes_total` al crear y `mem_reads_total` al listar.

## Compatibilidad con tests actuales
- El `content-type` especificado coincide con las aserciones de la suite de métricas (`pytest -k metrics`).
- Las métricas listadas corresponden a las que los tests validan en payloads Prometheus (latencia, contadores y rate limit).
- El allowlist de `/metrics` mantiene el comportamiento comprobado por los tests de rate limit y disponibilidad.
</file>

<file path="docs/CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md">
# CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md

## Alcance
- Aplica a la entidad `audio_session` definida en `docs/CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md` y a cualquier repositorio o endpoint que permita leerla o listarla.

## Control de acceso y multi-tenant
- Multi-tenant estricto: aislamiento por `api_key_id`/tenant; se prohíbe cualquier acceso cruzado entre tenants.
- Toda lectura requiere autenticación con `X-API-Key` válida.
- La lectura/listado de sesiones solo puede devolver datos cuando `api_key_id` solicitado == `api_key_id` autenticada.
- `list_by_user` únicamente puede entregar sesiones cuando `api_key_id` de la sesión coincide con la autenticada; colisiones de `user_external_id` entre tenants no generan error pero nunca revelan datos de otros tenants.

## Campos sensibles y minimización
- Se consideran sensibles: `transcript`, `reply_text`, `meta_tags`, `user_external_id`.
- Minimización: las vistas o dashboards agregados (métricas, estadísticas de uso, reportes sin granularidad de sesión) excluyen por defecto los campos sensibles listados arriba.

## Retención y purga obligatoria
- `retention_days` por defecto es 30; el campo `expires_at` es obligatorio en cada `audio_session`.
- Variables de configuración: `AUDIO_SESSION_RETENTION_DAYS` (días de retención, entero) y `AUDIO_SESSION_PURGE_ENABLED` (1/0 para habilitar la purga automática). Defaults seguros deben aplicarse si las variables no están definidas.
- La purga debe eliminar sesiones con `expires_at <= now`; las sesiones sin `expires_at` se consideran expiradas para evitar retención indefinida.

## Auditoría, logging y rate-limit de lecturas
- Registrar accesos de lectura (sin agregar PII adicional) cuando existan endpoints de lectura.
- Aplicar rate-limit de lecturas cuando existan endpoints de lectura para evitar scraping o abusos.

## Bloqueo y dependencias
- Está prohibido exponer endpoints o dashboards de lectura hasta cumplir esta política (sin excepciones salvo nueva Orden Kaizen).
- La política es de cumplimiento obligatorio y se referencia desde `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`.
</file>

<file path="docs/CONTRATO_NEUTRO_RATE_LIMIT.md">
# Contrato Neutro de Rate Limit

Define la semántica de control de tráfico para el Bot Neutro, incluyendo rutas excluidas y comportamiento al alcanzar el límite.

## Allowlist permanente
- `/metrics`
- `/healthz`
- `/readyz`

Estas rutas no están sujetas a rate limit para garantizar monitoreo y liveness.

## Configuración
- Controlado por variables de entorno actuales: `RATE_LIMIT_ENABLED`, `RATE_LIMIT_AUDIO_WINDOW_SECONDS`, `RATE_LIMIT_AUDIO_MAX_REQUESTS`.
- Equivalencia con nomenclatura previa: `RATE_LIMIT_AUDIO_WINDOW_SECONDS` ≈ ventana en segundos usada por `RATE_LIMIT_PER_MIN` y `RATE_LIMIT_AUDIO_MAX_REQUESTS` ≈ burst máximo (`RATE_LIMIT_BURST`).
- Cuando está habilitado, aplica a `/audio`, `/text`, `/actions` u otras rutas no allowlisted.

## Respuesta ante límite alcanzado
- **Código**: `429 Too Many Requests`.
- **Headers**:
  - `X-Outcome: error`
  - `X-Outcome-Detail: rate_limit`
- **Body**: mensaje de error genérico, manteniendo la forma actual de la API.

## Observabilidad
- Cada rechazo incrementa `sensei_rate_limit_hits_total` en `/metrics` y mantiene los headers `X-Outcome: error` y `X-Outcome-Detail: rate_limit`.
- Los eventos de rate limit deben reflejarse en logs JSON estructurados.

## Compatibilidad con tests actuales
- La allowlist de `/metrics`, `/healthz` y `/readyz` coincide con las expectativas validadas por los tests de rate limit.
- El código 429 y los headers `X-Outcome`/`X-Outcome-Detail` replican las aserciones de la suite existente.
- No se modifica lógica de runtime, por lo que `pytest -q` y `pytest -k metrics -q` permanecen en verde.
</file>

<file path="docs/CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md">
# Contrato Neutro de Storage de Sesiones de Audio

Este documento describe el esquema y las operaciones mínimas para persistir sesiones de audio procesadas por el Bot Neutro.

## Entidad `audio_session`

| Campo                     | Tipo / Notas                                           |
| ------------------------- | ------------------------------------------------------ |
| `id`                      | Identificador interno (UUID recomendado).             |
| `corr_id`                 | Correlation ID externo recibido en la petición.       |
| `api_key_id`              | Identificador lógico de la API key usada.             |
| `user_external_id`        | Identificador del usuario en el cliente.              |
| `created_at`              | Timestamp de creación.                                |
| `expires_at`              | Timestamp de expiración (`created_at` + `retention_days`). |
| `request_mime_type`       | MIME type del audio de entrada.                       |
| `request_duration_seconds`| Duración aproximada del audio de entrada.             |
| `transcript`              | Texto transcrito (STT).                               |
| `reply_text`              | Texto de respuesta (LLM).                             |
| `tts_available`           | Booleano indicando si hay audio TTS disponible.       |
| `tts_storage_ref`         | Referencia (URL/path) al audio TTS persistido.        |
| `usage_stt_ms`            | Milisegundos consumidos en STT.                       |
| `usage_llm_ms`            | Milisegundos consumidos en LLM.                       |
| `usage_tts_ms`            | Milisegundos consumidos en TTS.                       |
| `usage_total_ms`          | Milisegundos totales del pipeline.                    |
| `provider_stt`            | Proveedor STT usado.                                  |
| `provider_llm`            | Proveedor LLM usado.                                  |
| `provider_tts`            | Proveedor TTS usado.                                  |
| `meta_tags`               | Diccionario de etiquetas libres (string → string).    |

## Operaciones mínimas

- `create(audio_session)`: persiste la sesión completa y calcula `expires_at` según la política de retención vigente.
- `list_by_api_key(api_key_id, limit, offset, api_key_id_autenticada)`: lista sesiones por API key ordenadas por `created_at DESC` **solo si** `api_key_id == api_key_id_autenticada`.
- `list_by_user(user_external_id, limit, offset, api_key_id_autenticada)`: lista sesiones por usuario ordenadas por `created_at DESC` **solo** para sesiones cuyo `api_key_id` coincide con `api_key_id_autenticada`.
- Si `api_key_id_autenticada` es `None`, la operación debe fallar con `AccessDeniedError` (o equivalente de la implementación).

## Política de privacidad y seguridad

El almacenamiento de sesiones debe cumplir **obligatoriamente** con la política definida en `docs/CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md`.

## Índices recomendados

- Índice compuesto: `(user_external_id, created_at DESC)`.
- Índice compuesto: `(api_key_id, created_at DESC)`.
- Índice único en `corr_id`.
</file>

<file path="docs/DECISIONES/DECISION_POLITICA_SESIONES_AUDIO_V1_20251217.md">
# DECISION_POLITICA_SESIONES_AUDIO_V1_20251217

- Decisión: no exponer endpoints de lectura hasta cumplir política.
- Decisión: retention default 30 días, configurable por env.
- Decisión: enforcement mínimo en storage in-memory (expires_at + purge + tenant isolation).
- Riesgo mitigado: fuga de PII entre tenants.
- Próxima orden sugerida: persistencia + endpoints seguros (L3), cuando se defina auth/roles y rate-limit de lecturas.
</file>

<file path="docs/MUNAY_CONTRATO_MODULO_AUDIO.md">
# Munay: Contrato de Consumo del Módulo de Audio del Bot Neutro

Este documento describe cómo el cliente Munay consume el endpoint `/audio` del Bot Neutro.

## Petición

- **Método**: `POST /audio`
- **Contenido**: `multipart/form-data`
  - Campo obligatorio `file`: archivo de audio
- **Headers obligatorios**:
  - `X-API-Key`
  - `X-Correlation-Id`
  - `x-munay-user-id`
  - `x-munay-context`

## Contextos permitidos

`x-munay-context` admite los valores:

- `diario_emocional`
- `coach_habitos`
- `reflexion_general`

## Mapeo a eventos Munay

El consumo de `/audio` genera un `munay_event` con los siguientes mapeos:

- `diario_emocional` → `journal_entry`
- `coach_habitos` → `habit_coaching`
- `reflexion_general` → `insight`
- El sistema puede marcar `crisis_flag` si el pipeline detecta alerta.

Cada evento se enriquece con `audio_session_id` retornado por el Bot Neutro.

## Respuesta esperada

El backend neutro responde con un JSON que incluye la transcripción, la respuesta generada y la URL pública del TTS. Ejemplo:

```json
{
  "session_id": "uuid-de-la-sesion",
  "corr_id": "corr-id-correlacion",
  "transcript": "texto reconocido",
  "reply_text": "respuesta generada",
  "tts_url": "https://.../tts.wav",
  "usage": {
    "input_seconds": 1.0,
    "output_seconds": 1.5,
    "stt_ms": 123,
    "llm_ms": 456,
    "tts_ms": 200,
    "total_ms": 779,
    "provider_stt": "X",
    "provider_llm": "Y",
    "provider_tts": "Z"
  },
  "meta": {
    "context": "diario_emocional"
  }
}
```

Munay usará `tts_url` como URL pública del audio TTS. En futuras versiones, el cliente puede cachear o descargar este recurso, pero el contrato neutro solo garantiza la URL, no los bytes inline. El cliente también debe propagar `session_id`, `corr_id` y `meta` (incluyendo `meta.context`) en su propio modelo de observabilidad y trazabilidad.
</file>

<file path="docs/NEUTRO_SLO_AUDIO_OPERACIONAL.md">
# SLO Operacionales para /audio (plantilla de referencia)

> **Estado:** Plantilla de referencia. El wiring real a Prometheus/Alertmanager se definirá en una orden L3 o ADR futuro.

## 1. Resumen de SLO oficiales (NORTE v2.1)
- Latencia p95 de `/audio` ≤ **1500 ms**.
- Error rate máximo de `/audio` ≤ **1%**.
- Uptime objetivo: **99.9%**.
- Alertas de budget burn al **85% / 90% / 95%** del presupuesto de errores/latencia.

## 2. Definición operativa
- **Ventanas de observación sugeridas**: 5m (rápida) y 1h (estabilidad), manteniendo coherencia con CI_REAL.
- **Métricas base** (expuestas por `metrics_runtime`):
  - `sensei_request_latency_seconds_bucket{route="/audio"}` (histograma seconds).
  - `sensei_requests_total{route="/audio"}` (counter).
  - `errors_total{route="/audio"}` (counter).
  - `sensei_rate_limit_hits_total` (counter global de rechazos 429 en `/audio`).
- **Nota sobre extensiones futuras**: si en el futuro se añade un label `status` a `errors_total` (por ejemplo, `errors_total{route="/audio",status="5xx"}`), se podrán distinguir explícitamente los 429 del resto. Esa extensión requerirá un contrato o ADR adicional antes de usarse en producción.
- **Errores contados en el SLO**: 4xx/5xx. Las respuestas 429 pueden excluirse del denominador si se quiere medir pureza de negocio; se documentan ambas variantes en las queries.
- **Latencia**: se evalúa con p95; valores >1500 ms violan el SLO.
- **Alcance**: Solo `/audio`. El resto de rutas puede usar las mismas plantillas ajustando la label `route`.

## 3. Queries de monitoreo (PromQL)
> Estas queries son plantillas de referencia copy-pasteables. La integración real depende del stack Prometheus que se defina en una orden futura (L3/ADR).

- **Latencia p95 de /audio** (ventana 5m):
  ```promql
  histogram_quantile(
    0.95,
    sum(rate(sensei_request_latency_seconds_bucket{route="/audio"}[5m])) by (le)
  )
```

* **Error rate /audio** (incluyendo 429):

  ```promql
  sum(rate(errors_total{route="/audio"}[5m]))
    /
  sum(rate(sensei_requests_total{route="/audio"}[5m]))
  ```
* **CI_FUTURO – Error rate /audio excluyendo 429** (requiere un label futuro `status` en `errors_total`):

  ```promql
  sum(rate(errors_total{route="/audio",status!="429"}[5m]))
    /
  sum(rate(sensei_requests_total{route="/audio"}[5m]))
  ```
* **Tasa de rate-limit /audio** (counter global del middleware de `/audio`):

  ```promql
  sum(rate(sensei_rate_limit_hits_total[5m]))
  ```

## 4. Reglas de alerta (referencia)

> Implementadas como ejemplo en `docs/prometheus_rules_slo_audio.yml`. No se despliegan automáticamente.

Principios:

* **Violación SLO de latencia**: p95 > 1.5s sostenido (for 10m).
* **Violación SLO de error rate**: error_rate > 1% sostenido.
* **Budget burn**: alertas al 85/90/95% del presupuesto permitido (1% de errores, 1500ms de latencia p95). Se usan umbrales directos para simplificar la lectura.

## 5. Prueba de carga manual para /audio (k6)

> El script es solo para validación manual/local. **No** se invoca desde los workflows actuales (`ci_tests.yml`, `validate_norte.yml`).

Archivo: `tools/load/k6_audio_slo.js` (usa `tools/load/sample_silence.wav`).

Ejemplo de ejecución local (desde la raíz del repo, con el backend corriendo en `localhost:8000`):

```bash
k6 run \
  -e API_BASE_URL=http://localhost:8000 \
  -e API_KEY=YOUR_API_KEY \
  -e RPS=10 \
  -e TEST_DURATION=2m \
  tools/load/k6_audio_slo.js
```

Notas:

* Ajusta `RPS`, `TEST_DURATION` y `VUS` según la capacidad del entorno. Valores bajos (p.ej. RPS=5, duración 30s) son seguros para desarrollo.
* El script reporta métricas de cliente (`audio_client_latency_ms`, `audio_client_errors`) y respeta los headers `X-API-Key` y `X-Correlation-Id`.
* Mientras corre, observa `/metrics` para validar incrementos de `sensei_requests_total`, `errors_total` y `sensei_rate_limit_hits_total`.

## 6. Próximos pasos (orden L3/ADR sugerida)

* Definir despliegue real de Prometheus/Alertmanager usando estas plantillas.
* Evaluar integración opcional del k6 de carga en un pipeline CI_FUTURO.
* Formalizar en un ADR la semántica definitiva de exclusión/inclusión de 429 para el SLO de error rate.
</file>

<file path="docs/prometheus_rules_slo_audio.yml">
# Plantilla de reglas de alerta para SLO de /audio
# No se despliega automáticamente; usar como referencia en orden L3/ADR futuro.

groups:
  - name: audio-slo
    rules:
      - alert: SenseiAudioLatencySLOViolation
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(sensei_request_latency_seconds_bucket{route="/audio"}[5m])) by (le)
          ) > 1.5
        for: 10m
        labels:
          severity: page
          slo: audio_latency_p95
        annotations:
          summary: "Latencia p95 de /audio supera 1500ms"
          description: |
            La latencia p95 de /audio excede 1.5s durante 10m. Revisar backpressure y dependencias.

      - alert: SenseiAudioErrorRateSLOViolation
        expr: |
          (sum(rate(errors_total{route="/audio"}[5m]))
            /
           sum(rate(sensei_requests_total{route="/audio"}[5m]))) > 0.01
        for: 10m
        labels:
          severity: page
          slo: audio_error_rate
        annotations:
          summary: "Error rate de /audio supera 1%"
          description: |
            El ratio de errores de /audio es mayor a 1% por más de 10m.

      - alert: SenseiAudioErrorBudgetBurn85
        expr: |
          (sum(rate(errors_total{route="/audio"}[5m]))
            /
           sum(rate(sensei_requests_total{route="/audio"}[5m]))) > 0.0085
        for: 5m
        labels:
          severity: warn
          slo: audio_error_budget
        annotations:
          summary: "Budget burn /audio >85%"
          description: "Consumo del budget de errores de /audio supera 85% del 1% permitido."

      - alert: SenseiAudioErrorBudgetBurn90
        expr: |
          (sum(rate(errors_total{route="/audio"}[5m]))
            /
           sum(rate(sensei_requests_total{route="/audio"}[5m]))) > 0.009
        for: 5m
        labels:
          severity: warn
          slo: audio_error_budget
        annotations:
          summary: "Budget burn /audio >90%"
          description: "Consumo del budget de errores de /audio supera 90% del 1% permitido."

      - alert: SenseiAudioErrorBudgetBurn95
        expr: |
          (sum(rate(errors_total{route="/audio"}[5m]))
            /
           sum(rate(sensei_requests_total{route="/audio"}[5m]))) > 0.0095
        for: 5m
        labels:
          severity: page
          slo: audio_error_budget
        annotations:
          summary: "Budget burn /audio >95%"
          description: "Consumo del budget de errores de /audio supera 95% del 1% permitido."

      - alert: SenseiAudioLatencyBudgetBurn85
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(sensei_request_latency_seconds_bucket{route="/audio"}[5m])) by (le)
          ) > 1.275
        for: 5m
        labels:
          severity: warn
          slo: audio_latency_budget
        annotations:
          summary: "p95 /audio supera 85% del umbral"
          description: "La latencia p95 de /audio supera 85% del límite de 1500ms."

      - alert: SenseiAudioLatencyBudgetBurn90
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(sensei_request_latency_seconds_bucket{route="/audio"}[5m])) by (le)
          ) > 1.35
        for: 5m
        labels:
          severity: warn
          slo: audio_latency_budget
        annotations:
          summary: "p95 /audio supera 90% del umbral"
          description: "La latencia p95 de /audio supera 90% del límite de 1500ms."

      - alert: SenseiAudioLatencyBudgetBurn95
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(sensei_request_latency_seconds_bucket{route="/audio"}[5m])) by (le)
          ) > 1.425
        for: 5m
        labels:
          severity: page
          slo: audio_latency_budget
        annotations:
          summary: "p95 /audio supera 95% del umbral"
          description: "La latencia p95 de /audio supera 95% del límite de 1500ms."
</file>

<file path="docs/ROADMAP_CAPA_SUPERIOR_V1.md">
# Roadmap de la capa superior sobre el núcleo Bot Neutro

## 1. Contexto
- Core `/audio` estabilizado como API Pública v1 (`CONTRATO_API_PUBLICA_V1.md`).
- LLM con fallback a stub; proveedores externos son detalles internos con resiliencia por defecto.
- Objetivo: traje neutro reutilizable para múltiples bots y clientes (Munay como primero), listo para operar aun con fallas externas.

## 2. Opciones de siguiente capa

### A. Dashboards/observabilidad
- ¿Qué implicaría?
  - Exponer y consumir métricas clave ya disponibles (`usage.*`, `provider_*`, `corr_id`, histogramas de latencia, contadores de rate-limit, etc.).
  - Diseñar paneles base: llamadas por periodo, latencias p95/p99, `error_rate`, uso por `X-API-Key`, desglose stub vs proveedor real.
  - Documentar queries/alertas mínimas y cómo operarlas (PromQL + k6 como validación).
- Impacto
  - Visibilidad end-to-end del comportamiento del core y salud de SLOs.
  - Base tangible para SLAs y soporte a clientes (incluyendo Munay) con diagnósticos rápidos.
- Esfuerzo aproximado
  - Integrar dashboard de referencia (Grafana/Metabase) y publicar queries recomendadas.
  - Ajustar exportadores/labels si falta granularidad por ruta o API key.

### B. Primer cliente oficial (Munay dashboard o mini CLI)
- ¿Qué implicaría?
  - Construir un cliente humano para `/audio` que permita probar el traje sin intermediarios adicionales.
  - Alternativas: dashboard web mínimo para subir/grabar audio y ver respuesta, o CLI que capture audio local y envíe a `/audio` con headers.
  - Definir flujos básicos: autenticación por `X-API-Key`, selección de `x-munay-llm-tier`, manejo de correlación y visualización de `usage`.
- Impacto
  - Validación UX real del contrato público; feedback inmediato sobre headers, latencias percibidas y mensajes de error.
  - Muestra concreta para Munay y terceros de cómo consumir la API; acelera demos y onboarding.
- Esfuerzo aproximado
  - Diseño ligero de flujos y UX mínima; no requiere acoplar toda la app Munay todavía.
  - Instrumentar el cliente con logs/corr_id para ejercer trazabilidad con el core.

### C. Límites/planes por `X-API-Key`
- ¿Qué implicaría?
  - Diseñar un catálogo de planes (Free/Pro/Enterprise) con cuotas: QPS, minutos de audio/mes, tamaño máximo de archivo, políticas de burst.
  - Definir headers/errores asociados (`X-Outcome-Detail`, mensajes de límite) y reporting de consumo.
  - Borrador de governance para tenants: ciclo de vida de API keys, suspensiones, upgrades y auditoría.
- Impacto
  - Visión clara de negocio API; habilita pricing, multi-tenant real y soporte a socios externos.
  - Prepara al core para monetización y compliance mínima.
- Esfuerzo aproximado
  - Solo diseño/contratos en esta fase: matrices de límites, respuestas esperadas y relación con métricas existentes.
  - Implementación de enforcement vendrá en orden posterior.

## 3. Tabla comparativa de decisión
| Opción | Impacto en Munay | Impacto negocio API | Complejidad técnica inmediata | Desbloqueos futuros | Nota |
| ------ | ---------------- | ------------------- | ----------------------------- | ------------------- | ---- |
| A | Medio: visibilidad y diagnósticos para pruebas internas de Munay. | Alto: fundación para SLAs y soporte formal. | Medio: requiere wiring de dashboards y quizá ajustes de métricas. | Alta: habilita reportes y base para billing/planes. | Ya hay métricas base; falta capa de visualización y queries curadas. |
| B | Alto: UX real para validación y demos de Munay; prueba directa del contrato `/audio`. | Medio: ejemplo oficial acelera adopción de terceros. | Medio-bajo: cliente mínimo sin tocar backend. | Medio: genera feedback para priorizar futuras mejoras de API/observabilidad. | Alinea al traje con uso humano inmediato; reduce incertidumbre UX. |
| C | Medio: clarifica expectativas de uso de Munay como tenant. | Muy alto: define estrategia de monetización y límites. | Bajo-medio: trabajo de diseño contractual; no requiere código inmediato. | Alta: prepara enforcement y reporting comercial. | Depende parcialmente de visibilidad (A) para medir consumo real. |

## 4. Decisión
- **Opción elegida: B. Primer cliente oficial (Munay dashboard o mini CLI).**
- Justificación
  - Proporciona validación real del contrato `/audio` con usuarios humanos y headers oficiales (`X-API-Key`, `x-munay-llm-tier`).
  - Entrega un artefacto demostrable para Munay y terceros, acelerando demos y onboarding sin depender de integraciones completas.
  - Genera feedback directo sobre latencia percibida, mensajes de error y UX, insumos necesarios antes de invertir en dashboards o planes.
  - Requiere menor complejidad técnica inmediata que A, manteniendo el backend intacto.
  - Sirve de referencia viva para futuros clientes, reforzando el traje como plataforma neutral.
- Otras opciones
  - **A. Dashboards/observabilidad:** marcada como **Fase siguiente**; se aprovechará el cliente para validar qué métricas/queries son más útiles.
  - **C. Límites/planes por `X-API-Key`:** marcada como **Fase siguiente**; se diseñará después de contar con señales de uso real y observabilidad mejorada.

## 5. Próxima ORDEN KAIZEN sugerida
- **Título preliminar:** `ORDEN KAIZEN L2 – Primer cliente oficial de /audio (Munay dashboard o mini CLI)`
- Alcance esperado: definir UX mínima, flujos de autenticación por API key, manejo de audio (grabación/subida), headers recomendados y trazabilidad con `corr_id`/`usage`.
</file>

<file path="docs/UX_CLIENTE_OFICIAL_MUNAY_V1.md">
# UX_CLIENTE_OFICIAL_MUNAY_V1 – Dashboard mínimo para `/audio`

## 1. Objetivo UX

- Permitir que cualquier persona, sin conocer el backend, pueda:
  - Subir o grabar un audio rápidamente.
  - Ver de forma clara la transcripción y la respuesta generada.
  - Entender si está interactuando con el modelo real o con el stub.

## 2. Wireframes textuales

### Pantalla única (dashboard mínimo)

- **Header**: "Bot Neutro – Cliente Oficial Munay".
- **Sección Entrada**:
  - Botón "Subir audio" y opción "Grabar audio" (uno de los dos es suficiente si solo se implementa upload en la primera iteración).
  - Tooltip o texto breve indicando formato recomendado (wav, mono 16 kHz).
- **Sección Opciones**:
  - Selector de tier (toggle/combo): `freemium` (default) / `premium`.
  - Campo de configuración (oculto o modal) para API base y API key.
- **Sección Resultado**:
  - Bloque de `transcript` (texto grande, multilinea).
  - Bloque de `reply_text` (separado visualmente del transcript).
  - Métricas clave: `total_ms`, `provider_llm`, `corr_id`.
  - Etiqueta sutil "Modo stub activo" cuando `provider_llm` indique stub.
- **Estado de carga**: overlay o spinner deshabilitando acciones mientras se envía.

## 3. Casos de uso

1. **Prueba rápida freemium**
   - Usuario deja tier en `freemium`, sube audio corto, ve transcript + reply en segundos.

2. **Prueba premium**
   - Usuario selecciona `premium`, envía audio y valida que `provider_llm` refleje el proveedor premium.

3. **Error por API key incorrecta**
   - Con API key inválida, al enviar muestra error 401: "API Key inválida o ausente".

4. **Modo stub por falta de crédito**
   - Backend responde con `provider_llm` que contiene `stub`; UI muestra alerta/label "Modo stub activo (respuesta de prueba)" pero mantiene UX normal.
</file>

<file path="src/bot_neutro/audio_storage.py">
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, TypedDict

from .metrics_runtime import METRICS


class AccessDeniedError(Exception):
    """Señala violaciones de control de acceso multi-tenant en el storage."""


class UsagePayload(TypedDict):
    input_seconds: float
    output_seconds: float
    stt_ms: int
    llm_ms: int
    tts_ms: int
    total_ms: int
    providers: Dict[str, str]


class AudioSession(TypedDict, total=False):
    id: str
    session_id: str
    corr_id: str
    api_key_id: str
    user_external_id: Optional[str]
    created_at: datetime
    expires_at: datetime
    status: str
    request_mime_type: str
    request_duration_seconds: Optional[float]
    transcript: str
    reply_text: str
    tts_available: bool
    tts_storage_ref: Optional[str]
    usage_stt_ms: int
    usage_llm_ms: int
    usage_tts_ms: int
    usage_total_ms: int
    provider_stt: str
    provider_llm: str
    provider_tts: str
    usage: UsagePayload
    client_meta: Optional[Dict[str, str]]
    meta_tags: Optional[Dict[str, str]]


def _parse_retention_days() -> int:
    raw_retention = os.getenv("AUDIO_SESSION_RETENTION_DAYS", "30")
    try:
        retention_days = int(raw_retention)
    except ValueError:
        retention_days = 30
    if retention_days < 0:
        retention_days = 0
    if retention_days > 30:
        retention_days = 30
    return retention_days


def _parse_flag(name: str, default: str) -> bool:
    return os.getenv(name, default) != "0"


def _sanitize_client_meta(meta: Optional[Dict[str, str]]) -> Optional[Dict[str, str]]:
    if not meta:
        return None
    sanitized: Dict[str, str] = {}
    if "munay_context" in meta:
        sanitized["munay_context"] = meta["munay_context"]
    elif "context" in meta:
        sanitized["munay_context"] = meta["context"]
    return sanitized or None


def _build_usage_payload(session: AudioSession) -> UsagePayload:
    usage = session.get("usage")
    if usage:
        return usage
    providers = {
        "stt": session.get("provider_stt", "stt"),
        "llm": session.get("provider_llm", "llm"),
        "tts": session.get("provider_tts", "tts"),
    }
    return UsagePayload(
        input_seconds=float(session.get("request_duration_seconds") or 0.0),
        output_seconds=0.0,
        stt_ms=session.get("usage_stt_ms", 0),
        llm_ms=session.get("usage_llm_ms", 0),
        tts_ms=session.get("usage_tts_ms", 0),
        total_ms=session.get("usage_total_ms", 0),
        providers=providers,
    )


class FileAudioSessionRepository:
    def __init__(
        self,
        track_session_metrics: bool = False,
        storage_path: Optional[str] = None,
    ) -> None:
        self._items: List[AudioSession] = []
        self._retention_days = _parse_retention_days()
        self._purge_enabled = _parse_flag("AUDIO_SESSION_PURGE_ENABLED", "1")
        self._persist_transcript = _parse_flag(
            "AUDIO_SESSION_PERSIST_TRANSCRIPT", "0"
        )
        self._persist_reply_text = _parse_flag(
            "AUDIO_SESSION_PERSIST_REPLY_TEXT", "0"
        )
        self._track_session_metrics = track_session_metrics
        self._storage_path = Path(
            storage_path
            or os.getenv("AUDIO_SESSION_STORAGE_PATH", "/tmp/bot_neutro_audio_sessions.json")
        )
        self._load_from_disk()
        if self._purge_enabled:
            self.purge_expired(now=datetime.utcnow())

    def clear(self) -> None:
        """Borra todas las sesiones (para tests)."""

        self._items.clear()
        if self._storage_path.exists():
            if self._storage_path.is_file():
                self._storage_path.unlink()
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(0)

    def create(self, session: AudioSession) -> AudioSession:
        """Inserta la sesión; si ya existe `id`, puede sobrescribir o ignorar."""

        now = datetime.utcnow()
        created_at = session.get("created_at", now)
        retention_delta = timedelta(days=self._retention_days)
        expires_at = created_at + retention_delta
        if self._persist_transcript or self._persist_reply_text:
            expires_at = min(expires_at, created_at + timedelta(days=1))

        session_id = session.get("id") or session.get("session_id") or ""
        stored: AudioSession = dict(session)
        stored["id"] = session_id
        stored["session_id"] = session_id
        stored["created_at"] = created_at
        stored["expires_at"] = expires_at
        stored["status"] = session.get("status", "processed")
        stored["usage"] = _build_usage_payload(session)
        stored["client_meta"] = _sanitize_client_meta(session.get("client_meta"))

        if not self._persist_transcript:
            stored.pop("transcript", None)
        if not self._persist_reply_text:
            stored.pop("reply_text", None)

        if self._purge_enabled:
            self.purge_expired(now=now)

        if self._purge_enabled and expires_at <= now:
            METRICS.inc_audio_sessions_purged(1)
            if self._track_session_metrics:
                METRICS.set_audio_sessions_current(len(self._items))
            return stored

        self._items.append(stored)
        METRICS.inc_mem_write()
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(len(self._items))
        self._persist()
        return stored

    def list_by_user(
        self,
        user_external_id: str,
        limit: int = 50,
        offset: int = 0,
        api_key_id_autenticada: Optional[str] = None,
    ) -> List[AudioSession]:
        """Filtra por `user_external_id`, ordena por `created_at DESC`, aplica offset/limit."""

        if api_key_id_autenticada is None:
            raise AccessDeniedError("api_key_id_autenticada is required")

        if self._purge_enabled:
            self.purge_expired(now=datetime.utcnow())

        filtered = [
            item
            for item in self._items
            if item.get("user_external_id") == user_external_id
            and item.get("api_key_id") == api_key_id_autenticada
        ]
        sorted_items = sorted(filtered, key=lambda s: s["created_at"], reverse=True)
        METRICS.inc_mem_read()
        return sorted_items[offset : offset + limit]

    def list_by_api_key(
        self,
        api_key_id: str,
        limit: int = 50,
        offset: int = 0,
        api_key_id_autenticada: Optional[str] = None,
    ) -> List[AudioSession]:
        """Filtra por `api_key_id`, ordena por `created_at DESC`, aplica offset/limit."""

        if api_key_id_autenticada is None:
            raise AccessDeniedError("api_key_id_autenticada is required")
        if api_key_id != api_key_id_autenticada:
            raise AccessDeniedError("access denied for api_key_id")

        if self._purge_enabled:
            self.purge_expired(now=datetime.utcnow())

        filtered = [item for item in self._items if item.get("api_key_id") == api_key_id]
        sorted_items = sorted(filtered, key=lambda s: s["created_at"], reverse=True)
        METRICS.inc_mem_read()
        return sorted_items[offset : offset + limit]

    def purge_expired(self, now: Optional[datetime] = None) -> None:
        if now is None:
            now = datetime.utcnow()

        try:
            before_count = len(self._items)
            self._items = [
                item for item in self._items if item.get("expires_at", now) > now
            ]
            purged = before_count - len(self._items)
            if purged > 0:
                METRICS.inc_audio_sessions_purged(purged)
            if self._track_session_metrics:
                METRICS.set_audio_sessions_current(len(self._items))
            if purged > 0:
                self._persist()
        except Exception:
            METRICS.inc_error("/audio")

    def _load_from_disk(self) -> None:
        if not self._storage_path.exists():
            if self._track_session_metrics:
                METRICS.set_audio_sessions_current(0)
            return
        try:
            data = json.loads(self._storage_path.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            data = []
        items: List[AudioSession] = []
        for item in data if isinstance(data, list) else []:
            if not isinstance(item, dict):
                continue
            created_at = item.get("created_at")
            expires_at = item.get("expires_at")
            if isinstance(created_at, str):
                try:
                    item["created_at"] = datetime.fromisoformat(created_at)
                except ValueError:
                    continue
            if isinstance(expires_at, str):
                try:
                    item["expires_at"] = datetime.fromisoformat(expires_at)
                except ValueError:
                    continue
            items.append(item)
        self._items = items
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(len(self._items))

    def _serialize(self, item: AudioSession) -> AudioSession:
        payload = dict(item)
        created_at = payload.get("created_at")
        expires_at = payload.get("expires_at")
        if isinstance(created_at, datetime):
            payload["created_at"] = created_at.isoformat()
        if isinstance(expires_at, datetime):
            payload["expires_at"] = expires_at.isoformat()
        return payload

    def _persist(self) -> None:
        try:
            if len(self._items) == 0:
                return
            self._storage_path.parent.mkdir(parents=True, exist_ok=True)
            serialized = [self._serialize(item) for item in self._items]
            tmp_path = self._storage_path.with_suffix(".tmp")
            tmp_path.write_text(
                json.dumps(serialized, ensure_ascii=False), encoding="utf-8"
            )
            tmp_path.replace(self._storage_path)
        except OSError:
            METRICS.inc_error("/audio")
        except Exception:
            METRICS.inc_error("/audio")


class InMemoryAudioSessionRepository(FileAudioSessionRepository):
    def __init__(self, track_session_metrics: bool = False) -> None:
        self._items = []
        self._retention_days = _parse_retention_days()
        self._purge_enabled = _parse_flag("AUDIO_SESSION_PURGE_ENABLED", "1")
        self._persist_transcript = _parse_flag("AUDIO_SESSION_PERSIST_TRANSCRIPT", "0")
        self._persist_reply_text = _parse_flag("AUDIO_SESSION_PERSIST_REPLY_TEXT", "0")
        self._track_session_metrics = track_session_metrics
        self._storage_path: Optional[Path] = None
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(0)

    def clear(self) -> None:
        self._items.clear()
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(0)

    def _load_from_disk(self) -> None:
        self._items = []
        if self._track_session_metrics:
            METRICS.set_audio_sessions_current(0)

    def _persist(self) -> None:
        return


_DEFAULT_AUDIO_SESSION_REPOSITORY: Optional[FileAudioSessionRepository] = None


def get_default_audio_session_repository() -> FileAudioSessionRepository:
    global _DEFAULT_AUDIO_SESSION_REPOSITORY
    if _DEFAULT_AUDIO_SESSION_REPOSITORY is None:
        _DEFAULT_AUDIO_SESSION_REPOSITORY = FileAudioSessionRepository(
            track_session_metrics=True
        )
    return _DEFAULT_AUDIO_SESSION_REPOSITORY

__all__ = [
    "AudioSession",
    "AccessDeniedError",
    "FileAudioSessionRepository",
    "InMemoryAudioSessionRepository",
    "get_default_audio_session_repository",
]
</file>

<file path="src/bot_neutro/llm_tiers.py">
from __future__ import annotations

import os
from typing import Optional, Set

from .security_ids import derive_api_key_id

TIER_FREEMIUM = "freemium"
TIER_PREMIUM = "premium"
TIERS = {TIER_FREEMIUM, TIER_PREMIUM}
TIER_ORDER = {TIER_FREEMIUM: 0, TIER_PREMIUM: 1}


class TierInvalidError(ValueError):
    """Raised when a requested LLM tier is invalid."""


def _load_premium_api_key_ids() -> Set[str]:
    raw = os.getenv("MUNAY_LLM_PREMIUM_API_KEY_IDS", "")
    return {item.strip() for item in raw.split(",") if item.strip()}


def normalize_requested_tier(value: str | None) -> Optional[str]:
    if value is None:
        return None
    normalized = value.strip().lower()
    if normalized in TIERS:
        return normalized
    raise TierInvalidError(f"Invalid LLM tier: {value}")


def resolve_authorized_tier(api_key: str) -> str:
    if not api_key:
        return TIER_FREEMIUM
    premium_ids = _load_premium_api_key_ids()
    if derive_api_key_id(api_key) in premium_ids:
        return TIER_PREMIUM
    return TIER_FREEMIUM


def is_forbidden(requested: Optional[str], authorized: str) -> bool:
    if requested is None:
        return False
    authorized_rank = TIER_ORDER.get(authorized, TIER_ORDER[TIER_FREEMIUM])
    requested_rank = TIER_ORDER.get(requested, TIER_ORDER[TIER_FREEMIUM])
    return requested_rank > authorized_rank


def effective_tier(requested: Optional[str], authorized: str) -> str:
    if requested is None:
        return authorized
    if is_forbidden(requested, authorized):
        return authorized
    return requested


__all__ = [
    "TierInvalidError",
    "effective_tier",
    "is_forbidden",
    "normalize_requested_tier",
    "resolve_authorized_tier",
]
</file>

<file path="src/bot_neutro/middleware/__init__.py">
from .correlation import CorrelationIdMiddleware
from .logging import JSONLoggingMiddleware
from .rate_limit import RateLimitMiddleware
from .request_latency import RequestLatencyMiddleware

__all__ = [
    "CorrelationIdMiddleware",
    "JSONLoggingMiddleware",
    "RateLimitMiddleware",
    "RequestLatencyMiddleware",
]
</file>

<file path="src/bot_neutro/middleware/request_latency.py">
import math
import time
from typing import Callable

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

from bot_neutro.metrics_runtime import METRICS


class RequestLatencyMiddleware(BaseHTTPMiddleware):
    """Capture latency per request and feed the runtime histogram."""

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start = time.perf_counter()
        try:
            response = await call_next(request)
            return response
        finally:
            duration_seconds = time.perf_counter() - start
            route = request.url.path or "unknown"
            if not math.isnan(duration_seconds):
                METRICS.observe_latency(route, duration_seconds)
</file>

<file path="src/bot_neutro/providers/openai_llm.py">
"""OpenAI LLM provider implementation."""

import logging
import os
import time
from typing import Optional

from .interfaces import LLMProvider

logger = logging.getLogger(__name__)


class OpenAILLMProvider(LLMProvider):
    provider_id = "openai-llm"
    latency_ms = 0

    def __init__(
        self,
        api_key: str,
        model_freemium: str,
        model_premium: Optional[str] = None,
        base_url: Optional[str] = None,
        fallback: Optional[LLMProvider] = None,
        timeout_seconds: Optional[float] = None,
    ) -> None:
        self._api_key = api_key
        self._base_url = base_url
        self._model_freemium = model_freemium
        self._model_premium = model_premium or model_freemium
        self._fallback = fallback
        self._timeout_seconds = timeout_seconds
        self._client = None
        self._client_factory = self._require_client()

    @staticmethod
    def _require_client():
        try:
            from openai import OpenAI
        except ImportError as exc:  # pragma: no cover - defensive path
            raise RuntimeError("openai SDK not installed") from exc
        return OpenAI

    @classmethod
    def from_env(cls, fallback: Optional[LLMProvider] = None) -> "OpenAILLMProvider":
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is required for OpenAILLMProvider")

        model_freemium = os.getenv("OPENAI_MODEL_FREEMIUM")
        if not model_freemium:
            raise RuntimeError("OPENAI_MODEL_FREEMIUM is required for OpenAILLMProvider")

        model_premium = os.getenv("OPENAI_MODEL_PREMIUM")
        base_url = os.getenv("OPENAI_BASE_URL")
        timeout_env = os.getenv("OPENAI_TIMEOUT_SECONDS")
        timeout_seconds = float(timeout_env) if timeout_env else None

        return cls(
            api_key=api_key,
            model_freemium=model_freemium,
            model_premium=model_premium,
            base_url=base_url,
            fallback=fallback,
            timeout_seconds=timeout_seconds,
        )

    def _get_client(self):
        if self._client is None:
            self._client = self._client_factory(api_key=self._api_key, base_url=self._base_url)
        return self._client

    def generate_reply(self, transcript: str, context: dict) -> str:
        tier = context.get("llm_tier", "freemium") if context else "freemium"
        model = self._model_premium if tier == "premium" else self._model_freemium

        start = time.perf_counter()
        client = self._get_client()

        messages = [
            {"role": "system", "content": "Eres el núcleo neutral de Bot Neutro. Responde claro y breve."},
            {"role": "user", "content": transcript},
        ]

        try:
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                timeout=self._timeout_seconds,
            )
            reply = response.choices[0].message.content.strip()
            self.latency_ms = int((time.perf_counter() - start) * 1000)
            return reply
        except Exception as exc:  # pragma: no cover - requires network
            logger.warning(
                "openai_llm_error",
                exc_info=exc,
                extra={"provider_id": self.provider_id, "tier": tier, "model": model},
            )
            fallback = self._fallback
            if fallback:
                reply = fallback.generate_reply(transcript, context)
                self.latency_ms = getattr(fallback, "latency_ms", self.latency_ms)
                self.provider_id = f"{self.provider_id}|{fallback.provider_id}"
                return reply
            raise
</file>

<file path="src/bot_neutro/security_ids.py">
from __future__ import annotations

import hashlib
from typing import Optional


def derive_api_key_id(api_key: Optional[str]) -> str:
    if not api_key:
        return "anonymous"
    return hashlib.sha256(api_key.encode("utf-8")).hexdigest()[:12]
</file>

<file path="docs/CONTRATO_API_PUBLICA_V1.md">
# CONTRATO_API_PUBLICA_V1 – Endpoint /audio

Este documento define el contrato público de la API de voz del Bot Neutro
para la versión v1. Esta API está pensada para ser consumida por:

Este contrato describe el comportamiento **actual** del endpoint `/audio`:
no introduce cambios nuevos, solo congela como oficial lo que ya está
implementado y probado.

- La app Munay (primer cliente oficial).
- Otros proyectos propios del autor.
- Clientes externos (empresas, integradores n8n/Make, etc.).

## Visión general de `/audio`

- Método: `POST`
- Path: `/audio`
- Auth: header `X-API-Key` obligatorio.
- Formato: `multipart/form-data` con un solo campo de archivo.

## Headers

- `X-API-Key` (obligatorio)
  - Clave que identifica al cliente de la API (tenant).
  - En el estado actual del proyecto se asume una única key fija
    (`changeme` en desarrollo), pero el diseño está preparado para
    múltiples clientes y planes.

- `x-munay-llm-tier` (opcional, case-insensitive)
  - Valores aceptados: `freemium`, `premium`.
  - Default: `freemium` si falta o es inválido.
  - Controla la tier lógica del LLM (modelo económico vs modelo premium).

## Body (multipart/form-data)

- Campo: `audio_file` (obligatorio)
  - Tipo: archivo binario.
  - Content-Type recomendado: `audio/wav` (mono, 16 kHz o similar).
  - Tamaño máximo: depende de límites de despliegue (no fijados aún
    en este contrato, se documentarán cuando haya límites comerciales).

## Respuesta 200 OK (JSON)

```json
{
  "session_id": "uuid",
  "corr_id": "uuid",
  "transcript": "Texto transcrito del audio de entrada",
  "reply_text": "Texto de respuesta generado por el LLM (o stub)",
  "tts_url": "https://.../audio.wav",
  "usage": {
    "input_seconds": 1.0,
    "output_seconds": 1.5,
    "stt_ms": 100,
    "llm_ms": 200,
    "tts_ms": 150,
    "total_ms": 450,
    "provider_stt": "azure-stt",
    "provider_llm": "openai-llm|stub-llm",
    "provider_tts": "azure-tts"
  },
  "meta": null
}
```

Donde:

* `session_id`: identificador de sesión de audio.
* `corr_id`: identificador de correlación para logs/observabilidad.
* `transcript`: transcripción final entendida por el sistema.
* `reply_text`: respuesta textual final (LLM o stub).
* `tts_url`: URL (si hay audio de respuesta generado) o `null`.
* `usage.*`: métricas de tiempo y proveedores efectivos utilizados.
* `meta`: reservado para extensiones futuras (por ahora `null`).

## Errores

- `401 Unauthorized`
  - Cuando falta `X-API-Key` o no es válida.
- `400 Bad Request`
  - Cuando falta el campo `audio_file` o el formato es inválido.
  - Nota: un cliente puede mapear validaciones de formulario a 422 a nivel de UI, pero el backend responde 400 para audio
    ausente.
- `5xx`
  - Errores internos inesperados. El objetivo del diseño es que
    problemas externos (cuota del LLM, proveedor de voz) se traduzcan
    en degradación controlada (uso del stub) manteniendo `200 OK`
    siempre que sea posible.

## Multi-tenant y planes

- El diseño de la API asume que cada `X-API-Key` identifica a un cliente
  (tenant). El sistema puede, en el futuro, aplicar:
  - límites por cliente (QPS, segundos de audio, tokens),
  - planes Free / Pro / Enterprise.
- Aunque el código actual usa una sola key fija en desarrollo,
  este contrato se escribe ya pensando en:
  - Munay como primer cliente oficial,
  - otros proyectos propios del autor,
  - clientes externos.

## Ejemplos de uso (curl)

### Llamada estándar freemium

```bash
curl -X POST \
  -H "X-API-Key: changeme" \
  -H "x-munay-llm-tier: freemium" \
  -F "audio_file=@/ruta/a/audio.wav" \
  http://localhost:8000/audio
```

### Llamada con tier premium

```bash
curl -X POST \
  -H "X-API-Key: changeme" \
  -H "x-munay-llm-tier: Premium" \
  -F "audio_file=@/ruta/a/audio.wav" \
  http://localhost:8000/audio
```
</file>

<file path="docs/CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md">
# CONTRATO_CLIENTE_OFICIAL_MUNAY_V1 – Dashboard web mínimo para `/audio`

## 1. Rol del cliente oficial

- Actúa como **referente oficial** de cómo consumir la API Pública v1 (`/audio`).
- Es el primer cliente oficial pensado para Munay y demos, sin atarse a una UI específica de la app móvil.
- Sirve como guía de implementación para otros clientes futuros que quieran replicar el consumo.

## 2. Flujo básico de una llamada

1. El usuario abre el dashboard web.
2. Selecciona o graba un archivo de audio local.
3. El dashboard:
   - Lee `X-API-Key` desde configuración (no debe aparecer hardcodeada en la UI).
   - Permite elegir `freemium` o `premium` como tier lógico (combo/toggle que alimenta `x-munay-llm-tier`).
   - Envía `POST /audio` con `multipart/form-data` incluyendo `audio_file` y los headers requeridos.
4. Recibe JSON con, al menos, `transcript`, `reply_text`, `usage.*` y `corr_id`.
5. Renderiza en pantalla:
   - Texto transcrito (`transcript`).
   - Respuesta del modelo (`reply_text`).
   - Métricas clave (`usage.total_ms`, `usage.provider_llm`).

## 3. Datos mínimos que el dashboard DEBE manejar

### Inputs

- `audio_file`: archivo subido o grabado por el usuario.
- Selector de tier: `freemium` (default) o `premium`.

### Headers

- `X-API-Key`: obtenido desde la configuración/env del frontend.
- `x-munay-llm-tier`: derivado de la selección de tier; default `freemium`.

### Outputs (renderizados en UI)

- `transcript`
- `reply_text`
- `usage.total_ms`
- `usage.provider_llm`
- `corr_id` (visible o accesible para debug/logs avanzados)

## 4. Estados de UI

- **Estado inicial**
  - Botón “Subir audio” o “Grabar audio”.
  - Campo de selección de tier (combo o toggle simple).
  - Zona vacía para resultados.

- **Estado “enviando”**
  - Indicador de carga y botones deshabilitados mientras se procesa.

- **Estado “OK” (200)**
  - Mostrar `transcript` en texto visible.
  - Mostrar `reply_text` en bloque separado.
  - Mostrar `usage.total_ms`, `usage.provider_llm`, `corr_id`.
  - Si `provider_llm` contiene `stub`, mostrar indicación sutil: “Modo stub activo (respuesta de prueba)”.

- **Estado de error 401**
  - Mensaje claro: “API Key inválida o ausente”.

- **Estado de error 400**
  - Mensaje: “Archivo de audio faltante o formato inválido”.
  - Nota: las validaciones de formulario del frontend pueden usar códigos 422 internos, pero el backend devuelve 400 cuando el
    audio falta en la petición.

- **Errores de red / 5xx**
  - Mensaje genérico: “Error de servidor o red. Intenta de nuevo más tarde”.

## 5. Configuración esperada

- El dashboard debe poder configurarse mediante variables de entorno o archivo de config:
  - `API_BASE_URL` (por defecto `http://127.0.0.1:8000`).
  - `X-API-Key`.
  - Valor por defecto de tier (`freemium`).
- Evitar hardcodear la API key en el UI; usar configuración separada.

## 6. Observabilidad mínima desde el cliente

- El dashboard debe loguear (consola o panel) para cada llamada:
  - `corr_id`.
  - `usage.total_ms`.
  - `usage.provider_llm`.
- Estos datos deben estar disponibles para correlacionar con logs del backend.
</file>

<file path="docs/CONTRATO_NEUTRO_CONTRIBUCION.md">
# CONTRATO_NEUTRO_CONTRIBUCION

Documento de referencia oficial para cualquier persona (humana o IA) que abra un Pull Request en este repositorio.

## Checklist previo a abrir un PR
1. El PR cita explícitamente el/los contrato(s) habilitante(s) en su descripción.
2. `docs/HISTORIAL_PR.md` está actualizado si se tocaron contratos o el NORTE.
3. `pytest -q` y `pytest --cov=src --cov-fail-under=80` se ejecutaron (local o CI) y están en verde.
4. El PR tiene **una sola intención**; no mezcla temas.
5. La descripción del PR incluye TIPO (DESCUBRIR/DECIDIR/CAMBIAR/BLOQUEO) y referencia a secciones de contrato/ADR relevantes.

6. Verificación de realidad del NORTE:
   [ ] La orden/PR cita NORTE_VERSION_ACTUAL exactamente como aparece en `docs/02_ESTADO_Y_NORTE.md`.
   [ ] No se mencionan secciones o versiones de NORTE que no existan.

7. CI REAL vs futuro:
   [ ] Los checks de CI en la orden/PR corresponden a workflows existentes en `.github/workflows`, salvo que esta misma orden los cree o modifique.

8. Limpieza de artefactos IA:
   [ ] El texto no contiene patrones tipo "contentReference[", "oaicite:", "<<ImageDisplayed>>" salvo que sean ejemplos explícitos.
</file>

<file path="docs/CONTRATO_NEUTRO_SESIONES_STORAGE_V1.md">
# CONTRATO_NEUTRO_SESIONES_STORAGE_V1

## A) Meta
**Propósito.** Definir el contrato formal para el almacenamiento, retención y acceso de sesiones de audio del endpoint `/audio`, cumpliendo la privacidad y el NORTE.

**Alcance.** Una “sesión” es el registro lógico asociado a una ejecución de `/audio`, incluyendo identificadores, timestamps, estado y métricas de uso. Este contrato aplica a cualquier repositorio/almacenamiento que guarde sesiones y a cualquier futura lectura de las mismas.

**Fuera de alcance.** Implementación técnica, proveedores específicos, UI/cliente, endpoints de lectura/listado y migraciones de código.

**Referencias.**
Estas referencias deben existir en el repositorio y permanecer alineadas. Si alguna referencia no existe o cambió de nombre, este contrato debe corregirse (PR correctivo inmediato) antes de considerarse “cumplido”.
- `docs/CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md`
- `docs/CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`
- `docs/CONTRATO_NEUTRO_AUDIO_STATS_V1.md`
- `docs/CONTRATO_NEUTRO_HEADERS.md`

---

## B) Principios y garantías
- **Privacy-first:** la sesión solo persiste el mínimo necesario; los campos sensibles son opcionales y restringidos.
- **No PII por defecto:** cualquier metadato cliente debe estar sanitizado y libre de PII explícita.
- **`X-API-Key` nunca se persiste:** `api_key_id` siempre se deriva server-side como `sha256(X-API-Key)` en hex truncado a 12 chars.
- **`corr_id` obligatorio:** toda sesión debe incluir `corr_id` para trazabilidad end-to-end.

---

## C) Modelo de datos (contractual)
**Identificadores**
- `session_id` (string, requerido): identificador de la sesión. Mapea al `id` de `audio_session` en `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`.
- `corr_id` (string, requerido): correlation id recibido en el request.
- `api_key_id` (string, requerido): derivado, nunca provisto por el cliente.

**Timestamps**
- `created_at` (timestamp, requerido).
- `expires_at` (timestamp, requerido).

**Estado de sesión**
- `status` (string, opcional): `created` | `processed` | `failed` | `purged`.

**Contenido permitido (opcional y condicionado por privacidad)**
- `transcript` (string, opcional): **sensible**. **DEFAULT: NO se persiste**. Solo puede persistirse en L2 con configuración explícita habilitada (sin especificar nombre en este contrato) y **MUST** cumplir TTL máximo sensible (ver Retención).
- `reply_text` (string, opcional): **sensible**. **DEFAULT: NO se persiste**. Solo puede persistirse en L2 con configuración explícita habilitada (sin especificar nombre en este contrato) y **MUST** cumplir TTL máximo sensible (ver Retención).
- `usage` (objeto, requerido):
  - `input_seconds` (number)
  - `output_seconds` (number)
  - `stt_ms` (int)
  - `llm_ms` (int)
  - `tts_ms` (int)
  - `total_ms` (int)
  - `providers` (objeto): `stt`, `llm`, `tts` (string).
- `client_meta` (objeto, opcional): metadatos de cliente **sin PII**. Si se detecta PII, **MUST** descartarse o sanitizarse. Equivale a un subconjunto sanitizado de `meta_tags` definido en `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`.

**Contenido prohibido**
- `audio_bytes` persistido (por defecto **NO**).
- Secretos, API keys, tokens o credenciales.
- PII explícita (ejemplos: nombre + apellido, email, teléfono, dirección, documento, salud/finanzas).

**Nullability**
- Campos requeridos: `session_id`, `corr_id`, `api_key_id`, `created_at`, `expires_at`, `usage`.
- Campos opcionales: `status`, `transcript`, `reply_text`, `client_meta`.

---

## D) Retención y expiración (TTL)
- `expires_at` **MUST** existir en cada sesión nueva.
- Retención configurable por ENV (a implementar en L2):
  - `AUDIO_SESSION_RETENTION_DAYS` (entero, default 30).
  - `AUDIO_SESSION_PURGE_ENABLED` (1/0).
- Si `AUDIO_SESSION_RETENTION_DAYS=0` → `expires_at = created_at` (expiración inmediata) y la sesión **no** debe contarse como retenida.
- Para campos sensibles (`transcript`, `reply_text`) el TTL máximo **MUST** ser ≤ 1 día.
- Si `transcript` y/o `reply_text` se persisten (configuración explícita habilitada), `expires_at` **MUST** calcularse como `min(created_at + 1 día, created_at + AUDIO_SESSION_RETENTION_DAYS días)`.
- **Purga:** proceso interno, sin endpoint público. Debe eliminar sesiones con `expires_at <= now` y reportar métricas (declarativo).
- **Legacy:** sesiones sin `expires_at` se consideran expiradas para evitar retención indefinida (ver política de privacidad).
- **Purga deshabilitada:** si `AUDIO_SESSION_PURGE_ENABLED=0`, no hay purga automática, pero `expires_at` sigue siendo obligatorio y **no** se habilitan lecturas/listados.

---

## E) Control de acceso y lectura
- **Bloqueo vigente:** no se exponen endpoints de lectura/listado hasta cumplir el contrato y la política de privacidad.
- Toda lectura futura debe cumplir:
  - Autenticación por `X-API-Key`.
  - Autorización estricta por `api_key_id` derivado (solo dueño).
  - Auditoría con logs correlados por `corr_id`.
- Semántica contractual futura:
  - Si se implementa `GET /audio/sessions/{id}`, **MUST** filtrar por `api_key_id` derivado del request.
  - `transcript`/`reply_text` nunca se exponen a terceros ni a otros tenants.

---

## F) Observabilidad (declarativa)
- Métricas esperadas (nombres sugeridos):
  - `audio_sessions_current` (gauge)
  - `audio_sessions_purged_total` (counter)
  - `errors_total{route=...}` (agregado)
- Logging mínimo para auditoría: `event`, `corr_id`, `api_key_id`, `session_id` (cuando aplique).
- **Nota:** este contrato **no** implementa métricas/logs; solo define el requerimiento.

---

## G) Seguridad
- `api_key_id` se deriva **siempre** desde `X-API-Key` en runtime; nunca se acepta del cliente.
- `client_meta` debe sanitizarse y excluir PII.
- Separación multi-tenant estricta por `api_key_id`.

---

## H) Compatibilidad y migración
- **Estado actual:** almacenamiento persistente local (archivo JSON) con TTL y purga interna.
- **Futuro:** repositorio enchufable (interface) sin romper este contrato.
- **Migración:** cualquier migración futura debe preservar los campos obligatorios, la derivación de `api_key_id` y las reglas de retención/acceso.

---

## I) Checklist de cumplimiento
Antes de habilitar endpoints de lectura/listado, una implementación L2 debe cumplir:
1. `expires_at` obligatorio y cálculo por `AUDIO_SESSION_RETENTION_DAYS`.
2. Purga interna conforme a `AUDIO_SESSION_PURGE_ENABLED`.
3. `api_key_id` derivado desde `X-API-Key` (nunca aceptado del cliente).
4. Aislamiento multi-tenant por `api_key_id` en toda lectura.
5. Logs mínimos con `corr_id` y `api_key_id`.
6. Métricas declaradas para sesiones actuales y purgas.
7. No persistir secretos ni audio bytes por defecto.
8. Por defecto no persistir `transcript`/`reply_text`.
9. Si se habilita persistencia sensible: flags explícitos, TTL máximo 1 día y auditoría.
10. Cumplimiento explícito de `CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md`.
</file>

<file path="docs/GOBERNANZA/KAIZEN_GUARDRAILS.md">
# KAIZEN_GUARDRAILS
## ¿Qué es una orden verificable?
- Usa la plantilla oficial (`docs/PLANTILLA_ORDEN_EJECUCION_KAIZEN.md`) y conserva todas las secciones obligatorias.
- Declara explícitamente qué quedó IMPLEMENTADO y qué quedó NO IMPLEMENTADO, con su porqué.
- Incluye evidencia rastreable (comandos, tests, rutas de archivos) para cada recomendación.

## Criterios de aceptación mínimos
- Al menos un bloque `diff --git` describiendo los parches solicitados.
- DoD explícito con comandos mínimos (pytest + coverage) y evidencia esperada.
- Secciones presentes: Metadata, Objetivo, Alcance, Parches, DoD, Comandos de verificación, CI, Riesgos, NO IMPLEMENTADO.
- CI_REAL solo menciona workflows existentes; cualquier hipótesis va en CI_FUTURO.

## NORTE-first (nuevo estándar)
- Toda orden CAMBIAR debe justificar “por qué HOY” (bug reproducible hoy / contrato hoy / desbloqueo hoy).
- Queda prohibido el “futurismo”: hardening/performance/escala “por si acaso” sin evidencia de problema actual.
- Si una mejora es “buena idea” pero no desbloquea el objetivo actual, se mueve a NO IMPLEMENTADO con su desbloqueo.

## Regla anti-bucle
- Máximo 1 ronda de ajustes por orden (una sola iteración).
- Si algo no es bloqueante para el objetivo operativo, NO se corrige en esa orden: se documenta en NO IMPLEMENTADO.

## Reglas
### Regla 1 — Diffs obligatorios
Toda orden CAMBIAR debe incluir al menos 1 bloque `diff --git`.
### Regla 2 — DoD y comandos obligatorios
Debe declarar DoD y comandos mínimos (pytest + coverage).
### Regla 3 — Transparencia
Toda recomendación debe quedar en IMPLEMENTADO o NO IMPLEMENTADO.
### Regla 4 — No inventar
CI_REAL solo enumera workflows existentes. Si no se verifica, va en CI_FUTURO.
### Regla 5 — Evidencia
Cada cambio debe enlazar evidencia: tests/paths/comandos ejecutados.

## DoD (Definition of Done) — obligatorio
- [ ] `docs/PLANTILLA_ORDEN_EJECUCION_KAIZEN.md` incluye sección “Filtro NORTE-first”.
- [ ] `docs/GOBERNANZA/KAIZEN_GUARDRAILS.md` incluye reglas “NORTE-first”, “anti-bucle”.
- [ ] No se toca código runtime.
- [ ] PR docs-only pasa checks existentes.

## Comandos de verificación — obligatorio
- pytest -q
- pytest --cov=src --cov-fail-under=80

## CI
[CI_REAL] (si aplica)
- (listar SOLO workflows existentes en .github/workflows)

[CI_FUTURO] (no bloqueante)
- Validación automática del “Filtro NORTE-first” (si algún día se implementa en scripts).

## Riesgos y mitigaciones
- Riesgo: “NORTE-first” se interprete como “bajar calidad”.
- Mitigación: Mantener DoD + contracts-first; solo se elimina trabajo no requerido hoy.

## NO IMPLEMENTADO (y por qué)
- Integrar la regla NORTE-first en `scripts/kaizen_validate_order.py`
- Por qué: No es necesario hoy para avanzar; la gobernanza documental basta para el siguiente milestone.
- Riesgo aceptado: Se depende de disciplina humana en el corto plazo.
- Qué lo desbloquea: Cuando haya 3+ órdenes seguidas con desvíos o bucles por futurismo.

## Nota operacional (para Codex / ejecución)
- Esta orden es docs-only.
- No proponer mejoras “por si acaso”.
- Si aparece una idea de hardening/perf: moverla a NO IMPLEMENTADO automáticamente.
- Resultado esperado: desde la próxima orden CAMBIAR, cualquier sugerencia tipo “robustecer parse” o “optimizar por escala futura” queda automáticamente bloqueada por el Filtro NORTE-first a menos que haya bug reproducible hoy o contrato hoy que lo exija.
</file>

<file path="docs/ORDEN_KAIZEN_L1_AUDITORIA_20251217.md">
# ORDEN_KAIZEN_L1_AUDITORIA_20251217 – Auditoría global y sincronización contratos-código

## Resumen ejecutivo
- Alcance L1 (gobernanza): solo documentación y verificación; no se tocan flujos funcionales.
- Se auditaron el backend `bot-neutro` y el cliente `clients/munay-dashboard` contra los contratos vigentes.
- Hallazgos clave: en el momento de la auditoría el README afirmaba que `/audio` estaba stub y respondía 501, pero el código actual define un pipeline completo; se marca el README como desfasado y se corrige en `HISTORIAL_PR` (“Correcciones menores tras auditoría L1”). El rate limit se aplica solo a `/audio` con API key presente. El storage de sesiones es exclusivamente en memoria y sin políticas de retención/listado. El cliente oficial cumple el flujo básico pero depende de códigos 400/401 y no del 422 esperado en contrato.
- Evidencia: `README.md` indicaba stub 501; `src/bot_neutro/api.py` implementa `post_audio` con `AudioPipeline.process` y mapeos de error; `tests/test_api_audio.py` cubre rutas de éxito/error y pipeline; `clients/munay-dashboard/src/api/client.ts` consume `/audio` con headers/tier.

## Mapa de carpetas y responsabilidades
- `src/bot_neutro/`: API FastAPI (`/audio`, healthz/readyz/version/metrics), pipeline de audio y almacenamiento en memoria.
- `src/bot_neutro/middleware/`: middlewares de observabilidad y protección (correlación, logging JSON, rate limit, latencia).
- `src/bot_neutro/providers/`: interfaces y providers enchufables (stub por defecto, Azure opt-in para STT/TTS, OpenAI LLM opt-in con fallback a stub).
- `docs/`: contratos y runbooks; incluye contratos de audio, storage, rate limit y cliente oficial.
- `clients/munay-dashboard/`: dashboard React/Vite oficial para `/audio`, con configuración por variables `VITE_*` y componentes de upload/resultados.
- `tests/`: validan contrato `/audio`, storage in-memory y comportamiento de middlewares.

## Inventario de middlewares, providers y endpoints
### Middlewares (FastAPI)
- `RequestLatencyMiddleware`: mide latencia por ruta y alimenta histogramas en memoria.
- `CorrelationIdMiddleware`: asegura header `X-Correlation-Id` en request/response y lo deja en `request.state`.
- `RateLimitMiddleware`: controla `/audio` cuando `RATE_LIMIT_ENABLED=1`, con ventana configurable y allowlist (`/metrics`, `/healthz`, `/readyz`, `/version`).
- `JSONLoggingMiddleware`: emite logs estructurados por petición (método, path, status, corr_id).

### Providers y factory
- STT: `StubSTTProvider` (default); `AzureSTTProvider` opt-in con fallback al stub y fail-fast si faltan credenciales.
- TTS: `StubTTSProvider` (default); `AzureTTSProvider` opt-in con fallback al stub.
- LLM: `StubLLMProvider` (default); `OpenAILLMProvider` opt-in, selecciona modelo por tier (`freemium`/`premium`) y hace fallback a stub en errores.
- Factory selecciona providers por ENV (`AUDIO_STT_PROVIDER`, `AUDIO_TTS_PROVIDER`, `LLM_PROVIDER`).

### Endpoints activos
- `GET /healthz`, `/readyz`, `/version`: respuestas JSON simples con `X-Outcome` preset.
- `GET /metrics`: expone métricas Prometheus (latencia por ruta, rate-limit hits, lecturas/escrituras de memoria, requests/errors totales).
- `POST /audio`: al momento de la auditoría, README declaraba que estaba stub (501), pero el código en `src/bot_neutro/api.py` implementa un pipeline completo (multipart con archivo de audio y metadatos/headers de cliente). Se marca este desfase como hallazgo L1 y se corrige en este PR. Evidencia: `README.md` (sección API) vs. `src/bot_neutro/api.py::post_audio` y pruebas `tests/test_api_audio.py`.

## Flujo `/audio` según código
1. Middleware de correlación y rate limit (si habilitado) se ejecutan antes del handler.
2. Validaciones HTTP iniciales: se rechaza `x-munay-context` inválido y audio vacío; se genera `corr_id` cuando no viene en el request.
3. `AudioPipeline.process` opera sobre el multipart (audio + metadatos) y devuelve `AudioResponseContext` con usage y providers; el código define mapeos de errores a HTTP 4xx/5xx.
4. Al momento de la auditoría el README indicaba stub 501; la presencia de la implementación en `src/bot_neutro/api.py` y tests de `/audio` sugiere que el README estaba desfasado (ya corregido en este PR). Evidencia: `src/bot_neutro/api.py` usa `AudioPipeline.process`; `tests/test_api_audio.py` cubre respuestas 200/400/401/429; `README.md` exponía stub 501.

## Cuadro “Contrato ↔ Código” (estado al 2025-12-17)
| Contrato | Estado | Delta observado |
| --- | --- | --- |
| `CONTRATO_NEUTRO_AUDIO_PIPELINE.md` | **DESFASADO parcial** | Código usa `LLM_PROVIDER` en lugar de `AUDIO_LLM_PROVIDER`; no hay caso `storage_error` en pipeline; validaciones extra de `x-munay-context` no están descritas; al momento de la auditoría el README declaraba stub 501 mientras el código implementa pipeline (corregido en `HISTORIAL_PR`). Evidencia: `src/bot_neutro/providers/factory.py` selecciona `LLM_PROVIDER`; `src/bot_neutro/audio_pipeline.py` no define `storage_error`; validación de `x-munay-context` en `src/bot_neutro/api.py`; README declaraba stub. |
| `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md` | **DESFASADO** | Implementación solo in-memory sin índices ni persistencia; `request_duration_seconds` siempre `None`; no hay políticas de retención ni control de lectura por usuario/API key antes de exponer endpoints. Evidencia: `src/bot_neutro/audio_storage_inmemory.py` guarda en memoria y deja `request_duration_seconds=None`. |
| `CONTRATO_NEUTRO_RATE_LIMIT.md` | **DESFASADO** | Rate limit solo se aplica a `/audio` y solo cuando hay `X-API-Key`; contrato menciona más rutas. No hay logging específico de rate limit, aunque sí métrica `sensei_rate_limit_hits_total` y headers esperados. Evidencia: `src/bot_neutro/middleware/rate_limit.py` filtra por path `/audio` y requiere API key; la misma implementación expone headers/métrica. |
| `CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md` | **OK con nota** | Dashboard permite seleccionar tier, envía `X-API-Key` y renderiza transcript/reply/usage/provider_llm/corr_id. Maneja errores 401 y 400; las validaciones 422 son internas de la UI y no del backend (el backend devuelve 400 para audio faltante). Evidencia: `clients/munay-dashboard/src/api/client.ts` y `clients/munay-dashboard/src/components/AudioUploader.tsx` manejan tier y headers; backend `tests/test_api_audio.py::test_audio_missing_file` retorna 400. |
| `CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md` | **OK** | La estructura, variables `VITE_*` y comandos documentados coinciden con el código del dashboard (config, api/client.ts, componentes). Evidencia: `clients/munay-dashboard/vite.config.ts`, `.env.example` y estructura de `src/` alinean con el contrato. |
| `UX_CLIENTE_OFICIAL_MUNAY_V1.md` | **OK con nota** | La UI muestra upload, selector de tier, resultados y badge “Modo stub activo”; no incluye opción de grabar audio (permitido como iteración futura). Evidencia: componentes `clients/munay-dashboard/src/components/AudioUploader.tsx`/`clients/munay-dashboard/src/components/ResultPanel.tsx` muestran upload y tier, sin control de grabación. |

## Privacidad y seguridad (hallazgos)
- El storage es in-memory sin autenticación ni autorización; cualquier endpoint futuro de lectura deberá definir quién puede listar por `user_external_id` o `api_key_id` y cómo anonimizar datos.
- No existen políticas de retención, eliminación ni anonimización de sesiones; los objetos permanecen en memoria hasta reinicio.
- Los providers opt-in (Azure/OpenAI) dependen de credenciales en entorno; no hay auditoría ni cifrado en repositorio.

## Zonas oscuras / TODOs identificados
- Control de lectura de sesiones: falta contrato de quién puede acceder a `list_by_user`/`list_by_api_key` y cómo exponer endpoints seguros.
- Retención y límites de almacenamiento: no hay expiración ni métricas de tamaño de storage in-memory.
- LLM tiers y costos: no existe política por API key para `freemium`/`premium`; el backend acepta el header pero no valida planes ni cuotas.
- Rate limit: cobertura solo para `/audio`; faltan logs estructurados de rechazos y definición para otras rutas futuras.
- Observabilidad: `/metrics` no expone histograma por provider ni latencias separadas por etapa; solo per-route.

Recomendación: emitir órdenes futuras para mantener README y contratos alineados de forma continua, definir la política de sesiones (retención, lectura segura) y formalizar la política de tiers/planes por API key, incluyendo la resolución definitiva entre 400/422 para validaciones.

## Notas sobre pruebas ejecutadas
- Este documento no afirma ejecución de tests; el estado de tests/cobertura se verifica por CI (`.github/workflows/ci_tests.yml`).

## Evidencias consultadas
- Contratos: `CONTRATO_NEUTRO_AUDIO_PIPELINE.md`, `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`, `CONTRATO_NEUTRO_RATE_LIMIT.md`, `CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md`, `CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md`, `UX_CLIENTE_OFICIAL_MUNAY_V1.md`.
- Repositorio: `README.md`, `docs/HISTORIAL_PR.md`, `src/bot_neutro/api.py`, `src/bot_neutro/audio_pipeline.py`, `src/bot_neutro/middleware/`, `src/bot_neutro/providers/`, `clients/munay-dashboard/` (estructura y componentes principales), `tests/` (cobertura de `/audio` y métricas).
</file>

<file path="docs/RUNBOOK_AZURE_SPEECH.md">
# RUNBOOK_AZURE_SPEECH

Guía rápida para habilitar y probar Azure Speech en Bot Neutro.

## Configuración de variables de entorno

Usa el script `set_env_azure_speech.ps1` (o un `.env` equivalente) para definir sin commitear valores sensibles:

- `AUDIO_STT_PROVIDER`: `azure` para activar STT real (default `stub`).
- `AUDIO_TTS_PROVIDER`: `azure` para activar TTS real (default `stub`).
- `AZURE_SPEECH_KEY`: clave de Azure Speech.
- `AZURE_SPEECH_REGION`: región de Azure Speech (ej. `eastus`).
- `AZURE_SPEECH_STT_LANGUAGE_DEFAULT`: locale por defecto para STT (ej. `es-ES`).
- `AZURE_SPEECH_TTS_VOICE_DEFAULT`: voz por defecto para TTS (ej. `es-ES-AlonsoNeural`).
- `AZURE_SPEECH_TEST_WAV_PATH`: ruta local a un WAV válido para la prueba de integración.

Para forzar modo stub (y que cualquier prueba Azure quede `skipped`), limpia las ENV antes de ejecutar tests:

```powershell
Remove-Item Env:AUDIO_STT_PROVIDER -ErrorAction SilentlyContinue
Remove-Item Env:AUDIO_TTS_PROVIDER -ErrorAction SilentlyContinue
Remove-Item Env:AZURE_SPEECH_KEY -ErrorAction SilentlyContinue
Remove-Item Env:AZURE_SPEECH_REGION -ErrorAction SilentlyContinue
Remove-Item Env:AZURE_SPEECH_STT_LANGUAGE_DEFAULT -ErrorAction SilentlyContinue
Remove-Item Env:AZURE_SPEECH_TTS_VOICE_DEFAULT -ErrorAction SilentlyContinue
Remove-Item Env:AZURE_SPEECH_TEST_WAV_PATH -ErrorAction SilentlyContinue
```

## Ejecución de pruebas

Las pruebas unitarias siguen usando el modo stub y no requieren Azure:

```bash
python -m pytest -q
python -m pytest --cov=src --cov-fail-under=80
```

> `--cov` se corre siempre en modo stub: no requiere SDK Azure ni internet.

Prueba de integración opcional (solo si se configuraron las variables anteriores y existe el WAV real):

```bash
python -m pytest -m azure_integration -q
```

## Interpretación de resultados y logs

- En modo stub, los providers siguen reportando `stub-stt`/`stub-tts` como `provider_id`.
- En modo Azure, ante fallos el provider degrada al stub y el `provider_id` queda como `azure-stt|stub-stt` o `azure-tts|stub-tts`.
- Cuando Azure falla, se emiten logs con `azure_stt_error`/`azure_tts_error` (y variantes `*_canceled`/`*_no_match`) describiendo la razón y detalles de cancelación.
</file>

<file path="src/bot_neutro/middleware/rate_limit.py">
import os
import time
from threading import Lock
from typing import Callable, Dict, Iterable, Tuple

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import JSONResponse, Response

from bot_neutro.metrics_runtime import METRICS
from bot_neutro.security_ids import derive_api_key_id

ALLOWLIST: Iterable[str] = {"/metrics", "/healthz", "/readyz", "/version"}


def _is_enabled() -> bool:
    return os.getenv("RATE_LIMIT_ENABLED", "0") == "1"


class RateLimitMiddleware(BaseHTTPMiddleware):
    """Stub middleware to hook rate limiting behavior."""

    def __init__(self, app, allowlist: Iterable[str] | None = None) -> None:
        super().__init__(app)
        self.allowlist = set(allowlist or ALLOWLIST)
        self._state: Dict[Tuple[str, str], Dict[str, float | int]] = {}
        self._lock = Lock()

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        path = request.url.path

        if not _is_enabled() or path in self.allowlist:
            return await call_next(request)

        if path != "/audio":
            return await call_next(request)

        api_key = request.headers.get("X-API-Key")
        if not api_key:
            return await call_next(request)

        window_seconds = int(os.getenv("RATE_LIMIT_AUDIO_WINDOW_SECONDS", "60"))
        max_requests = int(os.getenv("RATE_LIMIT_AUDIO_MAX_REQUESTS", "60"))
        now = time.time()
        key = (path, derive_api_key_id(api_key))

        with self._lock:
            entry = self._state.get(key)
            if entry is None or now - entry["window_start"] >= window_seconds:
                entry = {"window_start": now, "count": 0}
                self._state[key] = entry

            if entry["count"] >= max_requests:
                retry_after = max(0, int(window_seconds - (now - entry["window_start"])))
                response = JSONResponse(
                    {"detail": "rate limit exceeded"}, status_code=429
                )
                response.headers["X-Outcome"] = "error"
                response.headers["X-Outcome-Detail"] = "rate_limit"
                correlation_id = getattr(request.state, "correlation_id", None)
                if correlation_id:
                    response.headers["X-Correlation-Id"] = correlation_id
                response.headers["Retry-After"] = str(retry_after)
                METRICS.inc_rate_limit_hit()
                return response

            entry["count"] += 1

        return await call_next(request)
</file>

<file path="src/bot_neutro/providers/__init__.py">
from .interfaces import LLMProvider, STTProvider, STTResult, TTSProvider, TTSResult
from .stub import StubLLMProvider, StubSTTProvider, StubTTSProvider
from .factory import build_llm_provider, build_stt_provider, build_tts_provider, get_llm_provider
from .openai_llm import OpenAILLMProvider

__all__ = [
    "LLMProvider",
    "STTProvider",
    "TTSProvider",
    "STTResult",
    "TTSResult",
    "StubLLMProvider",
    "StubSTTProvider",
    "StubTTSProvider",
    "build_llm_provider",
    "build_stt_provider",
    "build_tts_provider",
    "get_llm_provider",
    "OpenAILLMProvider",
]
</file>

<file path="src/bot_neutro/providers/stub.py">
from .interfaces import LLMProvider, STTProvider, STTResult, TTSProvider, TTSResult


class StubSTTProvider(STTProvider):
    provider_id = "stub-stt"
    latency_ms = 100
    input_seconds = 1.0

    def transcribe(self, audio_bytes: bytes, locale: str) -> STTResult:  # pragma: no cover - simple stub
        return STTResult(text="stub transcript", provider_id=self.provider_id, raw_transcript={"locale": locale})


class StubLLMProvider(LLMProvider):
    provider_id = "stub-llm"
    latency_ms = 200

    def generate_reply(self, transcript: str, context: dict) -> str:  # pragma: no cover - simple stub
        return "stub reply text"


class StubTTSProvider(TTSProvider):
    provider_id = "stub-tts"
    latency_ms = 150
    output_seconds = 1.5
    audio_url = "https://example.com/audio/stub.wav"
    audio_mime_type = "audio/wav"

    def synthesize(self, text: str, locale: str, voice: str | None = None) -> TTSResult:  # pragma: no cover - simple stub
        return TTSResult(
            audio_bytes=b"stub-bytes",
            audio_mime_type=self.audio_mime_type,
            provider_id=self.provider_id,
            audio_url=self.audio_url,
        )


__all__ = ["StubSTTProvider", "StubTTSProvider", "StubLLMProvider"]
</file>

<file path="docs/BOOTSTRAP_SKB_HILO.md">
# BOOTSTRAP_SKB_HILO

## Propósito
Este archivo define el mensaje semilla canónico que se debe pegar como primer mensaje en cualquier hilo nuevo donde SKB interactúe con el repositorio **Opobue/bot-neutro**. El objetivo es forzar arranques consistentes en modo memoria cero, utilizando la repo como única fuente de verdad.

## Mensaje semilla para hilos nuevos
Pega el siguiente bloque como primer mensaje. SKB debe ejecutarlo literalmente.

```
Repositorio: Opobue/bot-neutro
Asume memoria cero: todo el contexto debe reconstruirse exclusivamente desde esta repo.
Fuente de verdad: docs/02_ESTADO_Y_NORTE.md, docs/HISTORIAL_PR.md, contratos docs/CONTRATO_* y docs/MUNAY_*, docs/CONTRATO_SKB_GOBERNANZA.md, docs/MUNAY_GOB_GLOBAL.md, ADRs en docs/adr/
Instrucciones para SKB:
1) Lee completo el NORTE (docs/02_ESTADO_Y_NORTE.md).
2) Lee completo el HISTORIAL_PR (docs/HISTORIAL_PR.md). La última entrada es la última orden aplicada.
3) Responde primero con TIPO=DESCUBRIR. Debe incluir diagnóstico del estado actual y propuesta de siguiente ORDEN KAIZEN (L1/L2). No apliques cambios todavía.
```

## Protocolo de arranque de SKB (interno)
Cuando SKB reciba el mensaje anterior, debe:

1. Confirmar que el repositorio activo es **Opobue/bot-neutro**.
2. Leer `docs/02_ESTADO_Y_NORTE.md`, `docs/HISTORIAL_PR.md`, los contratos `docs/CONTRATO_*`, `docs/MUNAY_*` y ADRs disponibles.
3. Declarar explícitamente cuál es la última entrada de `docs/HISTORIAL_PR.md` y el alcance que habilita.
4. Citar exactamente la versión del NORTE encontrada y declarar que no se inventarán secciones ni versiones.
5. Mapear brevemente los contratos clave relevantes para el pedido inicial.
6. Emitir una respuesta TIPO=DESCUBRIR con diagnóstico y propuesta de siguiente ORDEN KAIZEN (L1 o L2), referenciando el NORTE leído y advirtiendo que cualquier mención de NORTE/SLOs/CI fuera de lo observado debe tratarse como BLOQUEO.
7. Si cambia la gobernanza o el NORTE, reflejar los ajustes en este bootstrap y registrar el cambio en `docs/HISTORIAL_PR.md`.
</file>

<file path="docs/CONFIG/ENV_VARS.md">
# ENV_VARS – Bot Neutro / Munay

Este documento es la fuente de verdad de variables de entorno soportadas por el runtime.

## Audio sessions (storage persistente)

### AUDIO_SESSION_RETENTION_DAYS
- Tipo: int
- Default: 30
- Regla: si el valor no es parseable → fallback 30. Si es < 0 → clamp a 0. Si es > 30 → clamp a 30.
- Efecto: `expires_at = created_at + retention_days` (si retención 0, expira inmediato).

### AUDIO_SESSION_PURGE_ENABLED
- Tipo: flag (string)
- Default: "1"
- Regla: si es "0" → deshabilita purga automática; cualquier otro valor → habilita.
- Efecto: al crear o listar, el repo elimina sesiones con `expires_at <= now`.

### AUDIO_SESSION_PERSIST_TRANSCRIPT
- Tipo: flag (string)
- Default: "0"
- Regla: si es "1" → persiste `transcript`; por defecto se omite.
- Efecto: cuando está habilitado, `expires_at = min(created_at + 1 día, created_at + AUDIO_SESSION_RETENTION_DAYS)`.

### AUDIO_SESSION_PERSIST_REPLY_TEXT
- Tipo: flag (string)
- Default: "0"
- Regla: si es "1" → persiste `reply_text`; por defecto se omite.
- Efecto: cuando está habilitado, `expires_at = min(created_at + 1 día, created_at + AUDIO_SESSION_RETENTION_DAYS)`.

### AUDIO_SESSION_STORAGE_PATH
- Tipo: string (path)
- Default: `/tmp/bot_neutro_audio_sessions.json`
- Efecto: path del archivo JSON donde se persisten las sesiones.

### AUDIO_STATS_MAX_SESSIONS
- Tipo: int
- Default: 20000
- Regla: si el valor no es parseable → fallback 20000. Si es < 0 → clamp a 0.
- Efecto: límite superior de sesiones a inspeccionar en `/audio/stats` para calcular agregados por tenant.

## Notas de privacidad
- No existen endpoints HTTP de lectura/listado de sesiones mientras rige `CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md`.
</file>

<file path="docs/CONTRATO_NEUTRO_LLM.md">
# Contrato Neutro de LLM

Define el rol y expectativas del componente de lenguaje dentro del Bot Neutro, manteniendo independencia del proveedor.

## Rol en el pipeline
- **Input**: mensajes de usuario y contexto en texto plano (incluida la transcripción de audio cuando aplica).
- **Proceso**: generación de respuesta y posibles instrucciones para acciones externas.
- **Output**: texto final para el usuario y, opcionalmente, instrucciones estructuradas para `/actions`.

## Neutralidad de proveedor
- El contrato no fija proveedor (OpenAI, Azure, etc.); solo define la forma de entrada y salida.
- Las integraciones específicas deben respetar los headers y métricas del resto del sistema.

## Expectativas mínimas
- **Latencia**: alineada a los SLOs generales (p95 ≈ 1500 ms para audio incluye etapa LLM). Requests que excedan deben registrarse en métricas de latencia.
- **Errores**: se propagan como `X-Outcome=error` en la capa API y se registran en `errors_total`.
- **Trazabilidad**: uso de `X-Correlation-Id` para enlazar logs y métricas.

## Compatibilidad con tests actuales
- El manejo de errores y su registro en métricas concuerda con las aserciones de la suite de observabilidad.
- No modifica firmas de endpoints ni lógica de runtime, por lo que las pruebas de `/audio` y métricas permanecen válidas.
- La neutralidad de proveedor evita cambios en mocks o configuraciones verificadas por `pytest -q`.

## Contrato operativo neutral
- Interfaz propuesta: `generate_reply(transcript: str, context: dict) -> str`.
- Atributos esperados alineados a otros providers: `provider_id: str` y `latency_ms: int` (opcional pero recomendado para métricas homogéneas).
- El stub LLM debe ser determinista y libre de dependencias externas para que los tests base y coverage funcionen sin red ni SDKs.
- Integraciones reales (Azure OpenAI, OpenAI, SenseiKaizen/Munay) se habilitarán como opt-in, sin modificar el contrato ni exigir variables de entorno en CI.

## Selección de proveedor por entorno
- La variable `LLM_PROVIDER` define qué implementación concreta se usa:
  - `""`, `stub` o valor ausente → `StubLLMProvider` (modo determinista por defecto).
  - `openai` → `OpenAILLMProvider` con fallback al stub si hay errores.
  - Futuros proveedores: `azure_openai`, `local_llm`, etc., se agregarán sin romper el contrato.
- El contrato de interfaz **no cambia**: `generate_reply(transcript: str, context: dict) -> str`.

## Uso recomendado de `context`
- Clave sugerida: `context["llm_tier"]` ∈ {`"freemium"`, `"premium"`} para elegir el modelo dentro del provider.
- La capa que construye el contexto (HTTP o lógica de negocio derivada de API key) es responsable de normalizar y validar; cualquier valor ausente o inválido debe convertirse en `"freemium"` antes de invocar al provider.
- El resto de metadata de negocio (usuario, tags, etc.) viaja en `context` pero no altera la firma.
</file>

<file path="docs/MATRIZ_CUMPLIMIENTO_CONTRATOS.md">
# Matriz de Cumplimiento de Contratos

| Contrato | Código (archivo(s)/módulo(s)) | Estado | Evidencia (tests/paths) |
| --- | --- | --- | --- |
| CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md | `src/bot_neutro/audio_storage.py` | OK | `tests/test_audio_storage_privacidad.py`, `tests/test_audio_contract.py`, `tests/test_audio_pipeline_orchestrator.py` |
| CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md | `src/bot_neutro/audio_storage.py` | OK (enforcement de storage; sin endpoints de lectura aún) | `tests/test_audio_storage_privacidad.py` |
| CONTRATOS_NEUTRO_AUDIO_PIPELINE/NEUTRO_AUDIO | `/audio` handler y pipeline en `src/bot_neutro/api.py`, `src/bot_neutro/audio_pipeline.py` | OK | `tests/test_audio_contract.py`, `tests/test_audio_pipeline_orchestrator.py`, `tests/test_metrics_observability.py` |
| CONTRATO_NEUTRO_AUDIO_STATS_V1.md | `/audio/stats` en `src/bot_neutro/api.py` | OK | `tests/test_audio_stats_contract.py` |
</file>

<file path="docs/MUNAY_GOB_GLOBAL.md">
# MUNAY_GOB_GLOBAL

## Propósito
Establecer un germen de gobernanza global aplicable a todas las repos y servicios Munay (apps, bots, backends, dashboards). Este documento actúa como capa superior de principios innegociables que cada repo debe adoptar y adaptar mediante contratos locales y ADRs.

## Principios globales innegociables
- Contracts-first: decisiones documentadas en contratos (`docs/CONTRATO_*` locales), luego HISTORIAL_PR, después ADRs y finalmente código.
- Protocolo D→D→C obligatorio: toda entrega pasa por DESCUBRIR → DECIDIR → CAMBIAR, con BLOQUEO explícito cuando aplique.
- CI obligatorio con pruebas y cobertura mínima acordada por producto; no se aceptan merges con CI en rojo.
- No mezclar temas en una misma orden o PR; cada cambio debe tener intención única y trazable.
- Uso de un historial vivo (HISTORIAL_PR o equivalente) que registre órdenes/contratos aplicados antes de modificar código.
- SLOs y observabilidad mínima declarados por producto y validados continuamente; la ausencia de señales es un bloqueo.
- Seguridad y cumplimiento como primera clase: manejo de secretos, permisos y dependencias auditables.

### Anti-alucinación y realidad del stack
- Ninguna orden puede referenciar versiones, secciones o SLOs inexistentes en los contratos reales del repositorio.
- Toda mención a CI debe anclarse a workflows existentes; los checks aspiracionales se documentan como futuros y no bloquean salvo que la orden cree dichos workflows.
- Cada repo Munay debe contar con un mecanismo local (contrato o script) para detectar tokens de IA ajenos en `docs/` antes de merge.
- Cada repo debe declarar qué archivos ejercen la función de gobernanza local (en Bot Neutro: `docs/CONTRATO_SKB_GOBERNANZA.md` y `docs/02_ESTADO_Y_NORTE.md`) y heredar explícitamente esta política anti-alucinación en su contrato local.

## Relación con esta repo (Bot Neutro)
- Esta repo adhiere a `MUNAY_GOB_GLOBAL.md` como capa superior de principios.
- La gobernanza local se especifica en `docs/CONTRATO_SKB_GOBERNANZA.md` y en `docs/02_ESTADO_Y_NORTE.md`, que concretan cómo aplicar estos principios en Bot Neutro.
- En caso de conflicto, el principio global se respeta y se documenta la adaptación local vía contrato o ADR.

## Extensión futura
- Incluir lineamientos específicos para otras repos Munay (app móvil, dashboards, data pipelines) conforme se creen.
- Definir criterios formales de cumplimiento Munay (checklist mínima, CI requerida, SLOs por dominio).
- Documentar interoperabilidad entre repos (contratos compartidos, versiones, compatibilidad).
- Toda repo Munay debe definir un archivo de gobernanza local (por ejemplo `MUNAY_GOB_LOCAL.md` o equivalente) que explicite cómo implementa los principios de este documento; en Bot Neutro este rol lo cumplen `docs/CONTRATO_SKB_GOBERNANZA.md` y `docs/02_ESTADO_Y_NORTE.md`.
</file>

<file path="docs/RUNBOOK_LLM.md">
# RUNBOOK — LLM (stub vs OpenAI opt-in)

Guía para operar el LLM del Bot Neutro en modo determinista (stub) o activando OpenAI de forma opt-in.

## Variables de entorno
- `LLM_PROVIDER`: `stub` (default) o `openai`.
- `OPENAI_API_KEY`: clave de OpenAI (obligatoria en modo OpenAI).
- `OPENAI_BASE_URL`: URL opcional para proxys/gateways compatibles.
- `OPENAI_MODEL_FREEMIUM`: modelo base (ej. `gpt-4.1-mini`).
- `OPENAI_MODEL_PREMIUM`: modelo premium (ej. `gpt-4.1`). Si falta, se reutiliza el freemium.
- `OPENAI_TIMEOUT_SECONDS`: (opcional) timeout en segundos para la llamada al LLM.

## Ejemplos de configuración (PowerShell)

Activar OpenAI:
```powershell
$env:LLM_PROVIDER = "openai"
$env:OPENAI_API_KEY = "<TU_API_KEY_OPENAI>"
$env:OPENAI_MODEL_FREEMIUM = "gpt-4.1-mini"
$env:OPENAI_MODEL_PREMIUM = "gpt-4.1"
# Opcional
$env:OPENAI_BASE_URL = "https://mi-gateway-openai"
$env:OPENAI_TIMEOUT_SECONDS = "30"
```

Volver a modo stub (seguro para CI):
```powershell
Remove-Item Env:LLM_PROVIDER, Env:OPENAI_API_KEY, Env:OPENAI_BASE_URL, Env:OPENAI_MODEL_FREEMIUM, Env:OPENAI_MODEL_PREMIUM, Env:OPENAI_TIMEOUT_SECONDS -ErrorAction SilentlyContinue
```

## Prueba de integración real con OpenAI (llm_integration)
1. Configura el entorno:

   ```powershell
   $env:LLM_PROVIDER = "openai"
   $env:OPENAI_API_KEY = "<TU_API_KEY_OPENAI>"
   $env:OPENAI_MODEL_FREEMIUM = "gpt-4.1-mini"
   $env:OPENAI_LLM_TEST_ENABLED = "1"
   ```

2. (Opcional) Verifica `/audio` en local con OpenAI activo si quieres confirmar el wiring completo.
3. Ejecuta la prueba dedicada:

   ```powershell
   python -m pytest -m llm_integration -q
   ```

4. Resultado esperado:

   - `1 passed` cuando OpenAI responde correctamente.
   - `0 tests ran` o `skipped` si `OPENAI_LLM_TEST_ENABLED` no está en `"1"` o faltan credenciales.

## Probar `/audio` en local (OpenAI activo)
1. Levanta la API:
   ```powershell
   uvicorn bot_neutro.api:app --reload
   ```
2. Llama al endpoint con un audio claro (ejemplo en PowerShell con `curl.exe`):
   ```powershell
   curl.exe -X POST "http://127.0.0.1:8000/audio" -H "x-api-key: changeme" -F "audio_file=@C:\ruta\a\audio.wav;type=audio/wav"
   ```
3. En la respuesta, valida:
   - `reply_text` distinto de `"stub reply text"`.
   - `usage.provider_llm` mostrando `openai-llm` (o `openai-llm|stub-llm` si se usó fallback).

## Notas
- Los tests unitarios y de cobertura (`pytest -q`, `pytest --cov=src --cov-fail-under=80`) se ejecutan siempre en modo stub sin depender de OpenAI ni de red.
- Si `LLM_PROVIDER` tiene un valor desconocido, el sistema registra un warning y cae a `StubLLMProvider`.
- La selección de modelo freemium/premium se controla vía `context["llm_tier"]`; si no se envía, se asume `"freemium"`.

- Manejo de errores de cuota / rate limit:
  - Si la cuenta de OpenAI no tiene crédito o excede su cuota, el SDK puede devolver HTTP 429 con código `insufficient_quota`.
  - En ese caso, el provider captura la excepción, registra un warning `openai_llm_error` y usa el stub como fallback.
  - El cliente sigue recibiendo `200 OK` con `reply_text` generado por el stub y `usage.provider_llm = "openai-llm|stub-llm"` (o similar).
  - Esto es intencional: el Bot Neutro nunca se cae por temas de facturación externa; simplemente degrada a modo stub.

- Patrón de operación recomendado:
  - Mantener `OPENAI_MODEL_FREEMIUM` apuntando a un modelo económico (ej. `gpt-4.1-mini`) para la mayoría de llamadas.
  - Reservar `OPENAI_MODEL_PREMIUM` (ej. `gpt-4.1`) para casos en que el cliente envía `x-munay-llm-tier: Premium`.
  - Validar periódicamente en el panel de OpenAI que exista crédito suficiente antes de pruebas intensivas.

- Estado actual del milestone:
  - El pipeline `/audio` funciona en modo stub sin depender de OpenAI.
  - La integración real OpenAI está verificada hasta el punto de manejo de errores de cuota; las respuestas “full LLM” dependen únicamente de que haya crédito disponible en la cuenta.
</file>

<file path="src/bot_neutro/providers/factory.py">
import logging
import os

from .azure import AzureSTTProvider, AzureTTSProvider
from .interfaces import LLMProvider, STTProvider, TTSProvider
from .openai_llm import OpenAILLMProvider
from .stub import StubLLMProvider, StubSTTProvider, StubTTSProvider

logger = logging.getLogger(__name__)


def build_stt_provider() -> STTProvider:
    provider_name = os.getenv("AUDIO_STT_PROVIDER", "stub").lower()
    if provider_name == "azure":
        fallback = StubSTTProvider()
        return AzureSTTProvider.from_env(fallback=fallback)
    return StubSTTProvider()


def build_tts_provider() -> TTSProvider:
    provider_name = os.getenv("AUDIO_TTS_PROVIDER", "stub").lower()
    if provider_name == "azure":
        fallback = StubTTSProvider()
        return AzureTTSProvider.from_env(fallback=fallback)
    return StubTTSProvider()


def get_llm_provider() -> LLMProvider:
    name = os.getenv("LLM_PROVIDER", "stub").lower()
    if name in {"", "stub"}:
        return StubLLMProvider()
    if name == "openai":
        fallback = StubLLMProvider()
        return OpenAILLMProvider.from_env(fallback=fallback)

    logger.warning("llm_provider_unknown", extra={"provider": name})
    return StubLLMProvider()


def build_llm_provider() -> LLMProvider:
    return get_llm_provider()


__all__ = ["build_stt_provider", "build_tts_provider", "build_llm_provider", "get_llm_provider"]
</file>

<file path="src/bot_neutro/providers/interfaces.py">
from dataclasses import dataclass
from typing import Optional


@dataclass
class STTResult:
    text: str
    provider_id: str
    raw_transcript: Optional[dict] = None


@dataclass
class TTSResult:
    audio_bytes: bytes
    audio_mime_type: str
    provider_id: str
    audio_url: Optional[str] = None


class STTProvider:
    provider_id: str = "stt"
    latency_ms: int = 0

    def transcribe(self, audio_bytes: bytes, locale: str) -> STTResult:
        raise NotImplementedError


class TTSProvider:
    provider_id: str = "tts"
    latency_ms: int = 0

    def synthesize(self, text: str, locale: str, voice: Optional[str] = None) -> TTSResult:
        raise NotImplementedError


class LLMProvider:
    provider_id: str = "llm"
    latency_ms: int = 0

    def generate_reply(self, transcript: str, context: dict) -> str:
        raise NotImplementedError
</file>

<file path="docs/CONTRATO_NEUTRO_AUDIO_PIPELINE.md">
# Contrato Neutro de Audio Pipeline

## Descripción general

La interfaz `/audio` del Bot Neutro conecta el pipeline de procesamiento de audio (STT → LLM → TTS) con los consumidores externos. Este contrato detalla los tipos lógicos, la interfaz esperada y el mapeo de errores a respuestas HTTP.

### Providers enchufables (STT/TTS/LLM)

El pipeline es multi-provider. Se definen interfaces mínimas para cada etapa y se seleccionan implementaciones mediante variables de entorno. El modo por defecto es el **stub** (sin dependencia externa) para asegurar backwards compatibility y costo cero.

```python
from dataclasses import dataclass
from typing import Optional


@dataclass
class STTResult:
    text: str
    provider_id: str
    raw_transcript: Optional[dict] = None


@dataclass
class TTSResult:
    audio_bytes: bytes
    audio_mime_type: str  # ej. "audio/wav"
    provider_id: str      # "azure", "stub", etc.
    audio_url: Optional[str] = None


class STTProvider:
    def transcribe(self, audio_bytes: bytes, locale: str) -> STTResult:
        raise NotImplementedError


class TTSProvider:
    def synthesize(self, text: str, locale: str, voice: Optional[str] = None) -> TTSResult:
        raise NotImplementedError


class LLMProvider:
    def generate_reply(self, transcript: str, context: dict) -> str:
        raise NotImplementedError
```

Interfaces y provider factory:

- `AUDIO_STT_PROVIDER` ∈ {`stub`, `azure`} (default: `stub`).
- `AUDIO_TTS_PROVIDER` ∈ {`stub`, `azure`} (default: `stub`).
- `AUDIO_LLM_PROVIDER` ∈ {`stub`} (por ahora solo stub).

Selección por entorno (fallback a stub cuando no se declara):

```python
from bot_neutro.providers.factory import (
    build_llm_provider,
    build_stt_provider,
    build_tts_provider,
)

stt_provider = build_stt_provider()  # stub si no hay ENV
tts_provider = build_tts_provider()  # stub si no hay ENV
llm_provider = build_llm_provider()  # stub
```

### Variables de entorno Azure Speech (runtime real con fallback)

Los providers `azure` leen configuración únicamente desde ENV y fallan explícitamente si faltan credenciales críticas. Las llamadas
reales al SDK de Azure se ejecutan de manera perezosa y, ante errores de red/timeout/5xx, hacen **fallback transparente al stub**
cuando este existe:

- `AZURE_SPEECH_KEY`
- `AZURE_SPEECH_REGION`
- `AZURE_SPEECH_STT_LANGUAGE_DEFAULT` (ej. `es-ES`)
- `AZURE_SPEECH_TTS_VOICE_DEFAULT` (ej. `es-ES-AlonsoNeural`)

Si se elige `AUDIO_STT_PROVIDER=azure` o `AUDIO_TTS_PROVIDER=azure` sin `AZURE_SPEECH_KEY`/`AZURE_SPEECH_REGION`, la app debe levantar un error de configuración al iniciar (fail-fast). Cuando Azure está activo y falla en tiempo de ejecución, el provider degrade al stub y la métrica `provider_*` reflejará el fallback (`azure-stt|stub-stt`, `azure-tts|stub-tts`). El modo por defecto sigue siendo 100% stub y es el único ejercitado en CI.

## Tipos lógicos

```python
class AudioRequestContext(TypedDict):
    corr_id: str
    api_key_id: str
    raw_audio: bytes
    mime_type: str
    language_hint: str | None
    client_metadata: dict[str, str] | None

class UsageMetrics(TypedDict):
    input_seconds: float
    output_seconds: float
    stt_ms: int
    llm_ms: int
    tts_ms: int
    total_ms: int
    provider_stt: str
    provider_llm: str
    provider_tts: str

class AudioResponseContext(TypedDict):
    transcript: str
    reply_text: str
    tts_url: str | None
    usage: UsageMetrics
    session_id: str | None
    corr_id: str | None
    meta: dict[str, str] | None

class PipelineError(TypedDict):
    code: str
    message: str
    details: dict[str, str] | None
```

`provider_stt` y `provider_tts` provienen del resultado de cada etapa y pueden incluir fallback explícito (por ejemplo `azure-stt|stub-stt`).

## Interfaz

```python
class AudioPipeline(Protocol):
    def process(self, ctx: AudioRequestContext) -> AudioResponseContext | PipelineError:
        ...

# Implementación actual
- El orquestador `AudioPipeline` se instancia con providers enchufables (STT/TTS/LLM) seleccionados por ENV.
- El modo por defecto usa `StubSTTProvider`/`StubLLMProvider`/`StubTTSProvider`, preservando el comportamiento previo.
- `AzureSTTProvider` y `AzureTTSProvider` ejecutan llamadas reales al SDK de Azure Speech cuando están configurados y degradan al stub en caso de fallos puntuales.
```

## Mapeo de errores a HTTP

| `PipelineError.code`       | HTTP status | `X-Outcome` | `X-Outcome-Detail`         |
| -------------------------- | ----------- | ----------- | -------------------------- |
| `bad_request`              | 400         | `error`     | `audio.bad_request`        |
| `unsupported_media_type`   | 415         | `error`     | `audio.unsupported_media_type` |
| `unauthorized`             | 401         | `error`     | `auth.unauthorized`        |
| `stt_error`                | 502         | `error`     | `audio.stt_error`          |
| `llm_error`                | 502         | `error`     | `audio.llm_error`          |
| `tts_error`                | 502         | `error`     | `audio.tts_error`          |
| `provider_timeout`         | 504         | `error`     | `audio.provider_timeout`   |
| `storage_error`            | 503         | `error`     | `audio.storage_error`      |
| `internal_error`           | 500         | `error`     | `audio.internal_error`     |

## Semántica de respuestas

En el endpoint `/audio`, la `AudioPipeline` se serializa a HTTP con los siguientes criterios:

- Respuestas exitosas:
  - `200 OK`
  - `X-Outcome: success`
  - `X-Outcome-Detail: audio_processed`

  `audio_processed` indica que el audio fue aceptado, procesado por el stub (STT → LLM → TTS) y que la respuesta incluye `session_id`, `corr_id`, `tts_url`, `usage` y `meta` según se describe en este contrato.

- Respuestas de error (`4xx` / `5xx`):

  - `X-Outcome: error`
  - `X-Outcome-Detail` debe ser uno de los códigos de la tabla anterior
    (`audio.bad_request`, `audio.unsupported_media_type`,
    `auth.unauthorized`, `audio.stt_error`, `audio.llm_error`,
    `audio.tts_error`, `audio.provider_timeout`, `audio.storage_error`,
    `audio.internal_error`, etc.).

Otros endpoints del Bot Neutro pueden usar `X-Outcome: ok` en 2xx si así se define en sus respectivos contratos, pero para `/audio` el valor canónico en éxito es `success` con `X-Outcome-Detail: audio_processed`.

### Ejemplo de respuesta exitosa

```json
{
  "session_id": "uuid-de-la-sesion",
  "corr_id": "corr-id-correlacion",
  "transcript": "texto reconocido",
  "reply_text": "respuesta generada",
  "tts_url": "https://.../tts.wav",
  "usage": {
    "input_seconds": 1.0,
    "output_seconds": 1.5,
    "stt_ms": 123,
    "llm_ms": 456,
    "tts_ms": 200,
    "total_ms": 779,
    "provider_stt": "stub-stt",
    "provider_llm": "stub-llm",
    "provider_tts": "stub-tts"
  },
  "meta": {
    "context": "diario_emocional"
  }
}
```

### Campos de `AudioResponseContext`

- `transcript: str`: transcripción STT del audio de entrada.
- `reply_text: str`: texto de respuesta generado por el LLM.
- `tts_url: str | None`: URL pública donde el cliente puede obtener el audio TTS.
- `usage: UsageMetrics`: métricas de uso incluyendo `input_seconds` (audio de entrada) y `output_seconds` (audio TTS), latencias en ms y proveedores de cada etapa.
- `session_id: str | None`: identificador de sesión de audio en el storage neutro.
- `corr_id: str | None`: correlación compartida con la capa HTTP.
- `meta: dict[str, str] | None`: etiquetas de contexto (por ejemplo, `context: diario_emocional`).

El contrato no garantiza entrega inline de bytes (`tts_audio_bytes`); el campo canónico para la reproducción del TTS es `tts_url`.
</file>

<file path="docs/CONTRATO_SKB_GOBERNANZA.md">
# CONTRATO_SKB_GOBERNANZA

Este contrato convierte la gobernanza SKB en un requisito operativo para cualquier contribución (humana o IA) en este repositorio.

## Protocolo D→D→C (DESCUBRIR → DECIDIR → CAMBIAR)
- **DESCUBRIR (D1):** Identificar brechas, riesgos o necesidades. No se cambia nada.
- **DECIDIR (D2):** Seleccionar la solución o contrato habilitante. No se modifica código de negocio hasta formalizar la decisión.
- **CAMBIAR (C):** Ejecutar la implementación autorizada por contratos/ADRs.
- **BLOQUEO:** Si no es posible avanzar, se debe emitir bloqueos explícitos.

### Cabecera obligatoria en cada respuesta
```
TIPO={DESCUBRIR|DECIDIR|CAMBIAR|BLOQUEO} · OBJ={{1 frase}} · ALCANCE={{resumen corto}}
```

### Formato de BLOQUEO
```
BLOQUEO:{causa}·Evidencia:{arch:línea}·Propuesta/Sig.paso:{acción mínima}
```

## Contracts-First y ADRs
- Ningún cambio de código de negocio puede ocurrir sin citar contrato(s) habilitantes (ejemplo: `CONTRATO_NEUTRO_AUDIO_PIPELINE.md §Semántica`).
- Cualquier cambio de arquitectura, seguridad o SLO/SLA requiere un ADR en `docs/adr/` siguiendo `ADR_TEMPLATE.md`.
- Si cambian los comandos de pruebas/cobertura, esta sección debe actualizarse en el mismo PR y registrarse en `docs/HISTORIAL_PR.md`.

## Hilos nuevos y memoria cero
- En hilos nuevos, SKB debe asumir **memoria cero** y reconstruir el contexto exclusivamente desde el repositorio: `docs/02_ESTADO_Y_NORTE.md`, `docs/HISTORIAL_PR.md`, contratos `docs/CONTRATO_*`, contratos `docs/MUNAY_*` y ADRs.

## Protocolo de arranque obligatorio
- Antes de cualquier respuesta TIPO=CAMBIAR debe existir al menos una respuesta TIPO=DESCUBRIR en el hilo.
- Esa respuesta DESCUBRIR debe citar explícitamente el NORTE y el HISTORIAL, identificando cuál es la última entrada de `docs/HISTORIAL_PR.md` y el alcance que habilita.
- Está prohibido saltar directamente a CAMBIAR en hilos nuevos o sin haber acreditado lectura del NORTE + HISTORIAL.

### NORTE_version_no_inventada
- Cada ORDEN KAIZEN debe incluir el campo:
  - `NORTE_VERSION_ACTUAL = vX.Y` (copiado literalmente de la primera línea de `docs/02_ESTADO_Y_NORTE.md`).
- Si el valor declarado no coincide con el valor real del archivo, la orden es inválida y debió emitirse un BLOQUEO.

### CI_REAL vs CI_FUTURO
- `CI_REAL`: workflows existentes en `.github/workflows/**`.
- `CI_FUTURO`: checks deseados sin workflow implementado.
- Ninguna orden puede usar checks de `CI_FUTURO` como criterio obligatorio de Definition of Done, salvo que incluya en su alcance la creación o modificación de esos workflows.

### Niveles L1 / L2 / L3
- **L1:** cambios puros de gobernanza/contratos (NORTE, HISTORIAL, contratos, ADRs, plantillas). No tocan código de runtime ni tests. Ejemplo: ajustar `CONTRATO_SKB_GOBERNANZA.md` o actualizar `docs/PLANTILLA_ORDEN_EJECUCION_KAIZEN.md`.
- **L2:** cambios de funcionalidad que pueden tocar contratos y código, siempre sobre un único tema y actualizando el contrato habilitante en el mismo PR. Ejemplo: modificar `/audio` y actualizar el contrato correspondiente.
- **L3:** refactors internos sin cambios de contratos externos ni comportamiento observable (estructura o deuda técnica). Ejemplo: reorganizar módulos internos manteniendo firmas públicas.

### Referencia obligatoria al último DESCUBRIR
- Toda orden L2/L3 debe referenciar explícitamente la última respuesta TIPO=DESCUBRIR del hilo (fecha/hora o identificador) y declarar que no existen cambios en NORTE/HISTORIAL posteriores a ese diagnóstico.
- Si hay cambios en NORTE o HISTORIAL después del último DESCUBRIR, SKB debe emitir TIPO=BLOQUEO y solicitar un nuevo DESCUBRIR antes de aceptar la orden.

### Catálogo de artefactos de IA prohibidos
Las órdenes deben mantenerse libres de tokens de sistemas de IA ajenos. Patrones como los siguientes invalidan la orden y requieren corrección antes de un PR:
- `contentReference[`.
- `oaicite:`.
- `<<ImageDisplayed>>`.
- Cualquier otro token de sistema de IA que no sea parte explícita del diseño.

## Bloqueos automáticos
El siguiente catálogo de bloqueos es obligatorio. Cada bloqueo debe emitirse en formato `BLOQUEO:{causa}·Evidencia:{arch:línea}·Propuesta/Sig.paso:{acción mínima}`.

- `repo_inaccesible`: no se puede leer el repositorio. Ejemplo: `BLOQUEO:repo_inaccesible·Evidencia:git/clone·Propuesta/Sig.paso:reintentar o proveer acceso`.
- `norte_inexistente`: falta `docs/02_ESTADO_Y_NORTE.md`. Ejemplo: `BLOQUEO:norte_inexistente·Evidencia:docs/02_ESTADO_Y_NORTE.md·Propuesta/Sig.paso:crear/restaurar NORTE antes de continuar`.
- `historial_inexistente`: falta `docs/HISTORIAL_PR.md`. Ejemplo: `BLOQUEO:historial_inexistente·Evidencia:docs/HISTORIAL_PR.md·Propuesta/Sig.paso:crear historial para registrar órdenes`.
- `ci_rota_validate_norte`: el workflow `validate_norte.yml` falla de forma persistente en la rama `main`. Ejemplo: `BLOQUEO:ci_rota_validate_norte·Evidencia:.github/workflows/validate_norte.yml·Propuesta/Sig.paso:reparar validaciones del NORTE antes de nuevos cambios`.
- `ci_rota_tests`: el workflow `ci_tests.yml` falla de forma persistente en la rama `main`. Ejemplo: `BLOQUEO:ci_rota_tests·Evidencia:.github/workflows/ci_tests.yml·Propuesta/Sig.paso:corregir tests/cobertura antes de seguir`.

## HISTORIAL_PR obligatorio
- Cambios en `docs/CONTRATO_*`, `docs/MUNAY_*`, `docs/02_ESTADO_Y_NORTE.md` o `docs/adr/*` requieren una nueva entrada en `docs/HISTORIAL_PR.md`.

## Órdenes multi-tema
- Si una petición inicial mezcla múltiples temas (por ejemplo audio + rate-limit + UI), SKB debe responder con TIPO=BLOQUEO por mezcla de fases/alcances y proponer la partición en varias ORDEN KAIZEN atómicas.

## Pruebas y cobertura mínimas
Todo cambio de código debe validar como mínimo:
- `pytest -q`
- `pytest --cov=src --cov-fail-under=80`

## Prohibiciones
- Silenciar warnings o errores en CI o en código.
- Mezclar temas en una misma orden o PR.
- Cambiar contratos sin actualizar la documentación de ADRs y `docs/HISTORIAL_PR.md`.

## Relación con MUNAY_GOB_GLOBAL
Esta gobernanza SKB implementa localmente los principios globales definidos en `docs/MUNAY_GOB_GLOBAL.md`, adaptándolos a la operación de esta repo.
</file>

<file path="docs/PLANTILLA_ORDEN_EJECUCION_KAIZEN.md">
# PLANTILLA — ORDEN DE EJECUCIÓN KAIZEN

## Regla de transparencia (obligatoria)
- Todo lo recomendado debe quedar como: IMPLEMENTADO (con diff + evidencia) o NO IMPLEMENTADO (con por qué).
- Prohibido omitir recomendaciones “porque no entraron”.

## Metadata (obligatoria)
NORTE_VERSION_ACTUAL = (copiar exactamente desde docs/02_ESTADO_Y_NORTE.md)
Nivel = {L1|L2|L3}
TIPO = {DESCUBRIR|DECIDIR|CAMBIAR|BLOQUEO}
Basado en = (hilo/ID o PR/Issue + fecha)
Objetivo operativo = (1 frase: “qué cambia observablemente”)
Contratos impactados = (lista de docs/CONTRATO_*.md o “N/A”)

## Filtro NORTE-first (obligatorio)
MOTIVO DEL CAMBIO (HOY) = (bug reproducible hoy / requisito contractual hoy / desbloqueo de milestone hoy)
COSTO DE NO HACERLO (HOY) = (qué se rompe o qué se bloquea si NO se hace ya)
PRUEBA DE EXISTENCIA DEL PROBLEMA (HOY) = (comando/log/escenario mínimo reproducible) o “N/A si es contrato nuevo”
DECISIÓN = {HACER AHORA | NO HACER AHORA}
Si DECISIÓN=NO HACER AHORA: mover a “NO IMPLEMENTADO” con razón y desbloqueo.

## Anti-futurismo (regla)
- Prohibido proponer hardening/perf/escala/robustez “por si acaso” si no existe bug reproducible hoy o requisito de contrato hoy.
- Prohibido abrir sub-objetivos nuevos dentro de una orden sin pasar el Filtro NORTE-first.

## Objetivo de esta orden:
(una línea, accionable)

## Alcance / Fuera de alcance:
- IN:
- OUT:

## Parches (DIFF) — obligatorios
- Archivo X:
* diff --git ...
*

## DoD (Definition of Done) — obligatorio
- [ ] tests pasan
- [ ] coverage se mantiene
- [ ] contratos no se rompen
- [ ] docs actualizadas

## Comandos de verificación — obligatorio
- pytest -q
- pytest --cov=src --cov-fail-under=80
- (si aplica) ruff check .
- (si aplica) ruff format --check .

## CI
[CI_REAL] (si aplica)
- (listar SOLO workflows existentes en .github/workflows)
Regla: CI_REAL solo puede contener checks que existan hoy. Si no existe workflow, va a CI_FUTURO.

[CI_FUTURO] (no bloqueante)
- (ideas/roadmap, no criterio de DoD)

## Riesgos y mitigaciones
- Riesgo:
- Mitigación:

## NO IMPLEMENTADO (y por qué)
- Item:
- Por qué:
- Riesgo aceptado:
- Qué lo desbloquea:
</file>

<file path="src/bot_neutro/metrics_runtime.py">
from threading import Lock
from typing import Dict, List


class InMemoryMetrics:
    def __init__(self) -> None:
        self._lock = Lock()
        self._requests_total: Dict[str, int] = {}
        self._errors_total: Dict[str, int] = {"/audio": 0, "/metrics": 0}
        self._llm_tier_denied_total: Dict[tuple[str, str, str], int] = {}
        self._rate_limit_hits_total: int = 0
        self._mem_reads_total: int = 0
        self._mem_writes_total: int = 0
        self._audio_sessions_purged_total: int = 0
        self._audio_sessions_current: int = 0

        self._latency_bucket_bounds: List[float] = [0.1, 0.5, 1.0, float("inf")]
        self._latency_buckets: Dict[str, Dict[float, int]] = {}
        self._latency_count: Dict[str, int] = {}
        self._latency_sum: Dict[str, float] = {}
        self._ensure_latency_route("/healthz")
        self._ensure_latency_route("/audio")

    def _ensure_latency_route(self, route: str) -> None:
        if route not in self._latency_buckets:
            self._latency_buckets[route] = {bound: 0 for bound in self._latency_bucket_bounds}
            self._latency_count[route] = 0
            self._latency_sum[route] = 0.0

    def inc_request(self, route: str) -> None:
        with self._lock:
            self._requests_total[route] = self._requests_total.get(route, 0) + 1

    def inc_error(self, route: str) -> None:
        with self._lock:
            self._errors_total[route] = self._errors_total.get(route, 0) + 1

    def inc_llm_tier_denied_total(self, route: str, requested_tier: str, authorized_tier: str) -> None:
        with self._lock:
            key = (route, requested_tier, authorized_tier)
            self._llm_tier_denied_total[key] = self._llm_tier_denied_total.get(key, 0) + 1

    def inc_rate_limit_hit(self) -> None:
        with self._lock:
            self._rate_limit_hits_total += 1

    def inc_mem_read(self) -> None:
        with self._lock:
            self._mem_reads_total += 1

    def inc_mem_write(self) -> None:
        with self._lock:
            self._mem_writes_total += 1

    def inc_audio_sessions_purged(self, count: int) -> None:
        with self._lock:
            self._audio_sessions_purged_total += count

    def set_audio_sessions_current(self, count: int) -> None:
        with self._lock:
            self._audio_sessions_current = count

    def observe_latency(self, route: str, duration_seconds: float) -> None:
        with self._lock:
            self._ensure_latency_route(route)
            self._latency_count[route] += 1
            self._latency_sum[route] += duration_seconds

            for bound in self._latency_bucket_bounds:
                if duration_seconds <= bound:
                    self._latency_buckets[route][bound] += 1

    def snapshot(self) -> Dict[str, object]:
        with self._lock:
            requests_total = dict(self._requests_total)
            errors_total = dict(self._errors_total)
            for route in ("/audio", "/metrics"):
                errors_total.setdefault(route, 0)

            latency_snapshot: Dict[str, Dict[str, Dict[float, int] | float | int]] = {}
            for route, buckets in self._latency_buckets.items():
                latency_snapshot[route] = {
                    "buckets": dict(buckets),
                    "count": self._latency_count.get(route, 0),
                    "sum": self._latency_sum.get(route, 0.0),
                }

            llm_tier_denied_snapshot = [
                {
                    "route": route,
                    "requested_tier": requested_tier,
                    "authorized_tier": authorized_tier,
                    "value": value,
                }
                for (route, requested_tier, authorized_tier), value in self._llm_tier_denied_total.items()
            ]

            return {
                "requests_total": requests_total,
                "errors_total": errors_total,
                "llm_tier_denied_total": llm_tier_denied_snapshot,
                "rate_limit_hits_total": self._rate_limit_hits_total,
                "mem_reads_total": self._mem_reads_total,
                "mem_writes_total": self._mem_writes_total,
                "audio_sessions_purged_total": self._audio_sessions_purged_total,
                "audio_sessions_current": self._audio_sessions_current,
                "latency": latency_snapshot,
                "latency_bucket_bounds": list(self._latency_bucket_bounds),
            }


METRICS = InMemoryMetrics()


__all__ = ["InMemoryMetrics", "METRICS"]
</file>

<file path="src/bot_neutro/providers/azure.py">
"""Azure Speech providers with stub-friendly fallbacks.

Estas implementaciones siguen siendo opt-in: solo se activan cuando las
variables de entorno `AUDIO_STT_PROVIDER`/`AUDIO_TTS_PROVIDER` se fijan a
`azure` y existen las credenciales necesarias. Las importaciones del SDK de
Azure son perezosas para no impactar entornos sin la dependencia instalada
cuando se usa el modo stub.
"""

from __future__ import annotations

import os
import logging
from dataclasses import dataclass
from typing import Optional

from .interfaces import LLMProvider, STTProvider, STTResult, TTSProvider, TTSResult


logger = logging.getLogger("bot_neutro")


@dataclass
class AzureSpeechConfig:
    key: str
    region: str
    stt_language_default: str
    tts_voice_default: str


class AzureProviderError(RuntimeError):
    """Errores específicos de Azure que permiten diferenciar fallbacks."""


class AzureSTTProvider(STTProvider):
    provider_id = "azure-stt"
    latency_ms = 0
    input_seconds = 0.0

    def __init__(self, config: AzureSpeechConfig, fallback: Optional[STTProvider] = None) -> None:
        self._config = config
        self._fallback = fallback

    @staticmethod
    def _require_sdk():
        """Carga perezosa del SDK de Azure.

        Se invoca tanto en `from_env` (para fail-fast de dependencias) como en
        las llamadas reales. No se usa try/except alrededor de imports para no
        ocultar errores genuinos.
        """

        import azure.cognitiveservices.speech as speechsdk  # type: ignore

        return speechsdk

    @classmethod
    def from_env(cls, fallback: Optional[STTProvider] = None) -> "AzureSTTProvider":
        key = os.getenv("AZURE_SPEECH_KEY")
        region = os.getenv("AZURE_SPEECH_REGION")
        language_default = os.getenv("AZURE_SPEECH_STT_LANGUAGE_DEFAULT", "es-ES")
        voice_default = os.getenv("AZURE_SPEECH_TTS_VOICE_DEFAULT", "")

        if not key or not region:
            raise ValueError("Missing Azure Speech credentials: AZURE_SPEECH_KEY/AZURE_SPEECH_REGION")

        try:
            cls._require_sdk()
        except ImportError as exc:
            raise ValueError("Azure Speech SDK is required for Azure providers (pip install azure-cognitiveservices-speech)") from exc

        return cls(
            AzureSpeechConfig(
                key=key,
                region=region,
                stt_language_default=language_default,
                tts_voice_default=voice_default,
            ),
            fallback=fallback,
        )

    def _transcribe_with_sdk(self, audio_bytes: bytes, locale: str) -> STTResult:
        speechsdk = self._require_sdk()

        speech_config = speechsdk.SpeechConfig(subscription=self._config.key, region=self._config.region)
        speech_config.speech_recognition_language = locale or self._config.stt_language_default

        stream = speechsdk.audio.PushAudioInputStream()
        stream.write(audio_bytes)
        stream.close()

        audio_config = speechsdk.audio.AudioConfig(stream=stream)
        recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
        result = recognizer.recognize_once()

        if result.reason == speechsdk.ResultReason.RecognizedSpeech:
            raw_transcript = {
                "text": result.text,
                "reason": getattr(result.reason, "name", str(result.reason)),
            }
            return STTResult(text=result.text, provider_id=self.provider_id, raw_transcript=raw_transcript)

        if result.reason == speechsdk.ResultReason.NoMatch:
            logger.warning(
                "azure_stt_no_match",
                extra={
                    "provider_id": self.provider_id,
                    "locale": locale,
                    "reason": getattr(result.reason, "name", str(result.reason)),
                },
            )
            raise AzureProviderError("Azure STT returned NoMatch")

        if result.reason == speechsdk.ResultReason.Canceled:
            details = speechsdk.CancellationDetails.from_result(result)
            logger.warning(
                "azure_stt_canceled",
                extra={
                    "provider_id": self.provider_id,
                    "locale": locale,
                    "reason": getattr(details.reason, "name", str(details.reason)),
                    "error_details": getattr(details, "error_details", None),
                },
            )
            raise AzureProviderError(
                f"Azure STT canceled: {details.reason}; {details.error_details}"
            )

        raise AzureProviderError("Azure STT returned unknown result")

    def transcribe(self, audio_bytes: bytes, locale: str) -> STTResult:
        try:
            return self._transcribe_with_sdk(audio_bytes, locale)
        except Exception as exc:  # pragma: no cover - exercised via fallback tests
            logger.warning(
                "azure_stt_error",
                exc_info=exc,
                extra={
                    "provider_id": self.provider_id,
                    "locale": locale,
                    "exc_type": type(exc).__name__,
                },
            )
            if not self._fallback:
                raise

            fallback_result = self._fallback.transcribe(audio_bytes, locale)
            self.latency_ms = getattr(self._fallback, "latency_ms", self.latency_ms)
            self.input_seconds = getattr(self._fallback, "input_seconds", self.input_seconds)
            fallback_result.provider_id = f"{self.provider_id}|{fallback_result.provider_id}"
            return fallback_result


class AzureTTSProvider(TTSProvider):
    provider_id = "azure-tts"
    latency_ms = 0
    output_seconds = 0.0

    def __init__(self, config: AzureSpeechConfig, fallback: Optional[TTSProvider] = None) -> None:
        self._config = config
        self._fallback = fallback

    @staticmethod
    def _require_sdk():
        import azure.cognitiveservices.speech as speechsdk  # type: ignore

        return speechsdk

    @classmethod
    def from_env(cls, fallback: Optional[TTSProvider] = None) -> "AzureTTSProvider":
        key = os.getenv("AZURE_SPEECH_KEY")
        region = os.getenv("AZURE_SPEECH_REGION")
        language_default = os.getenv("AZURE_SPEECH_STT_LANGUAGE_DEFAULT", "es-ES")
        voice_default = os.getenv("AZURE_SPEECH_TTS_VOICE_DEFAULT", "es-ES-AlonsoNeural")

        if not key or not region:
            raise ValueError("Missing Azure Speech credentials: AZURE_SPEECH_KEY/AZURE_SPEECH_REGION")

        try:
            cls._require_sdk()
        except ImportError as exc:
            raise ValueError("Azure Speech SDK is required for Azure providers (pip install azure-cognitiveservices-speech)") from exc

        return cls(
            AzureSpeechConfig(
                key=key,
                region=region,
                stt_language_default=language_default,
                tts_voice_default=voice_default,
            ),
            fallback=fallback,
        )

    def _synthesize_with_sdk(self, text: str, locale: str, voice: str | None = None) -> TTSResult:
        speechsdk = self._require_sdk()

        speech_config = speechsdk.SpeechConfig(subscription=self._config.key, region=self._config.region)
        speech_config.speech_synthesis_language = locale or self._config.stt_language_default
        speech_config.speech_synthesis_voice_name = voice or self._config.tts_voice_default

        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
        result = synthesizer.speak_text_async(text).get()

        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            audio_bytes = bytes(result.audio_data)
            return TTSResult(
                audio_bytes=audio_bytes,
                audio_mime_type="audio/wav",
                provider_id=self.provider_id,
                audio_url=None,
            )

        if result.reason == speechsdk.ResultReason.Canceled:
            details = speechsdk.SpeechSynthesisCancellationDetails.from_result(result)
            logger.warning(
                "azure_tts_canceled",
                extra={
                    "provider_id": self.provider_id,
                    "locale": locale,
                    "voice": voice or self._config.tts_voice_default,
                    "reason": getattr(details.reason, "name", str(details.reason)),
                    "error_details": getattr(details, "error_details", None),
                },
            )
            raise AzureProviderError(
                f"Azure TTS canceled: {details.reason}; {details.error_details}"
            )

        raise AzureProviderError("Azure TTS returned unknown result")

    def synthesize(self, text: str, locale: str, voice: str | None = None) -> TTSResult:
        try:
            return self._synthesize_with_sdk(text, locale, voice)
        except Exception as exc:  # pragma: no cover - exercised via fallback tests
            logger.warning(
                "azure_tts_error",
                exc_info=exc,
                extra={
                    "provider_id": self.provider_id,
                    "locale": locale,
                    "voice": voice,
                    "exc_type": type(exc).__name__,
                },
            )
            if not self._fallback:
                raise

            fallback_result = self._fallback.synthesize(text, locale, voice)
            self.latency_ms = getattr(self._fallback, "latency_ms", self.latency_ms)
            self.output_seconds = getattr(self._fallback, "output_seconds", self.output_seconds)
            fallback_result.provider_id = f"{self.provider_id}|{fallback_result.provider_id}"
            return fallback_result


class AzureLLMProvider(LLMProvider):  # pragma: no cover - placeholder
    provider_id = "azure-llm"
    latency_ms = 0

    def generate_reply(self, transcript: str, context: dict) -> str:
        raise NotImplementedError("Azure LLM integration pending")


__all__ = ["AzureSTTProvider", "AzureTTSProvider", "AzureLLMProvider", "AzureSpeechConfig", "AzureProviderError"]
</file>

<file path="src/bot_neutro/audio_pipeline.py">
import uuid
from datetime import datetime
from typing import Dict, Optional, TypedDict, Union

from .audio_storage import (
    AudioSession,
    FileAudioSessionRepository,
    get_default_audio_session_repository,
)
from .providers.interfaces import (
    LLMProvider,
    STTProvider,
    STTResult,
    TTSProvider,
    TTSResult,
)
from .providers.stub import StubLLMProvider, StubSTTProvider, StubTTSProvider


class AudioRequestContext(TypedDict, total=False):
    corr_id: str
    api_key_id: str
    audio_bytes: bytes
    raw_audio: bytes
    mime_type: str
    language_hint: Optional[str]
    locale: Optional[str]
    user_external_id: Optional[str]
    client_meta: Optional[Dict[str, str]]
    client_metadata: Optional[Dict[str, str]]


class UsageMetrics(TypedDict):
    stt_ms: int
    llm_ms: int
    tts_ms: int
    total_ms: int
    provider_stt: str
    provider_llm: str
    provider_tts: str
    input_seconds: float
    output_seconds: float


class AudioResponseContext(TypedDict):
    transcript: str
    reply_text: str
    tts_url: Optional[str]
    usage: UsageMetrics
    session_id: Optional[str]
    corr_id: Optional[str]
    meta: Optional[Dict[str, str]]


class PipelineError(TypedDict):
    code: str
    message: str
    details: Optional[Dict[str, str]]


class AudioPipeline:
    def __init__(
        self,
        session_repo: FileAudioSessionRepository,
        stt_provider: STTProvider,
        tts_provider: TTSProvider,
        llm_provider: LLMProvider,
    ) -> None:
        self._repository = session_repo
        self._stt_provider = stt_provider
        self._tts_provider = tts_provider
        self._llm_provider = llm_provider

    def _error(self, code: str, message: str, details: Optional[Dict[str, str]] = None) -> PipelineError:
        return PipelineError(code=code, message=message, details=details)

    def _build_usage(
        self,
        stt_result: STTResult,
        tts_result: TTSResult,
    ) -> UsageMetrics:
        stt_ms = int(getattr(self._stt_provider, "latency_ms", 0))
        llm_ms = int(getattr(self._llm_provider, "latency_ms", 0))
        tts_ms = int(getattr(self._tts_provider, "latency_ms", 0))

        input_seconds = float(getattr(self._stt_provider, "input_seconds", 0.0))
        output_seconds = float(getattr(self._tts_provider, "output_seconds", 0.0))

        provider_stt = getattr(stt_result, "provider_id", getattr(self._stt_provider, "provider_id", "stt"))
        provider_llm = getattr(self._llm_provider, "provider_id", "llm")
        provider_tts = getattr(tts_result, "provider_id", getattr(self._tts_provider, "provider_id", "tts"))

        total_ms = stt_ms + llm_ms + tts_ms

        return UsageMetrics(
            stt_ms=stt_ms,
            llm_ms=llm_ms,
            tts_ms=tts_ms,
            total_ms=total_ms,
            provider_stt=provider_stt,
            provider_llm=provider_llm,
            provider_tts=provider_tts,
            input_seconds=input_seconds,
            output_seconds=output_seconds,
        )

    def process(self, ctx: AudioRequestContext) -> Union[AudioResponseContext, PipelineError]:
        api_key_id = ctx.get("api_key_id")
        audio_bytes = ctx.get("audio_bytes") or ctx.get("raw_audio")
        mime_type = ctx.get("mime_type", "")
        client_metadata = ctx.get("client_meta") or ctx.get("client_metadata")
        locale = ctx.get("locale") or ctx.get("language_hint") or ""

        if not api_key_id:
            return self._error(code="unauthorized", message="missing api key")

        if not audio_bytes:
            return self._error(code="bad_request", message="empty audio")

        if not mime_type.startswith("audio/"):
            return self._error(
                code="unsupported_media_type",
                message="unsupported media type",
                details={"mime_type": mime_type},
            )

        metadata = client_metadata
        munay_user_id: Optional[str] = None
        munay_context: Optional[str] = None

        if metadata:
            munay_user_id = metadata.get("munay_user_id")
            munay_context = metadata.get("munay_context")

        corr_id = ctx.get("corr_id", str(uuid.uuid4()))

        try:
            stt_result = self._stt_provider.transcribe(audio_bytes, locale)
        except TimeoutError as exc:  # pragma: no cover - defensive branch
            return self._error(code="provider_timeout", message=str(exc))
        except Exception as exc:  # pragma: no cover - defensive branch
            return self._error(code="stt_error", message=str(exc))

        llm_tier = ctx.get("llm_tier", "freemium")

        llm_context = {
            "llm_tier": llm_tier,
            "metadata": metadata or {},
            "user_external_id": ctx.get("user_external_id") or munay_user_id,
        }

        try:
            reply_text = self._llm_provider.generate_reply(stt_result.text, llm_context)
        except TimeoutError as exc:  # pragma: no cover - defensive branch
            return self._error(code="provider_timeout", message=str(exc))
        except Exception as exc:  # pragma: no cover - defensive branch
            return self._error(code="llm_error", message=str(exc))

        try:
            tts_result = self._tts_provider.synthesize(reply_text, locale, voice=None)
        except TimeoutError as exc:  # pragma: no cover - defensive branch
            return self._error(code="provider_timeout", message=str(exc))
        except Exception as exc:  # pragma: no cover - defensive branch
            return self._error(code="tts_error", message=str(exc))

        usage = self._build_usage(stt_result, tts_result)
        session_id = str(uuid.uuid4())

        tts_url = getattr(tts_result, "audio_url", None)

        session: AudioSession = {
            "id": session_id,
            "corr_id": corr_id,
            "api_key_id": api_key_id,
            "user_external_id": ctx.get("user_external_id") or munay_user_id,
            "created_at": datetime.utcnow(),
            "request_mime_type": mime_type,
            "request_duration_seconds": None,
            "transcript": stt_result.text,
            "reply_text": reply_text,
            "tts_available": bool(tts_result.audio_bytes),
            "tts_storage_ref": tts_url,
            "usage_stt_ms": usage["stt_ms"],
            "usage_llm_ms": usage["llm_ms"],
            "usage_tts_ms": usage["tts_ms"],
            "usage_total_ms": usage["total_ms"],
            "provider_stt": usage["provider_stt"],
            "provider_llm": usage["provider_llm"],
            "provider_tts": usage["provider_tts"],
            "usage": {
                "input_seconds": usage["input_seconds"],
                "output_seconds": usage["output_seconds"],
                "stt_ms": usage["stt_ms"],
                "llm_ms": usage["llm_ms"],
                "tts_ms": usage["tts_ms"],
                "total_ms": usage["total_ms"],
                "providers": {
                    "stt": usage["provider_stt"],
                    "llm": usage["provider_llm"],
                    "tts": usage["provider_tts"],
                },
            },
            "meta_tags": {"context": munay_context} if munay_context else None,
            "client_meta": client_metadata,
        }

        self._repository.create(session)

        return AudioResponseContext(
            transcript=session["transcript"],
            reply_text=session["reply_text"],
            tts_url=session["tts_storage_ref"],
            usage=usage,
            session_id=session_id,
            corr_id=session["corr_id"],
            meta=session.get("meta_tags"),
        )


class StubAudioPipeline(AudioPipeline):
    def __init__(self, repository: FileAudioSessionRepository | None = None) -> None:
        super().__init__(
            repository or get_default_audio_session_repository(),
            StubSTTProvider(),
            StubTTSProvider(),
            StubLLMProvider(),
        )


__all__ = [
    "AudioRequestContext",
    "AudioResponseContext",
    "UsageMetrics",
    "PipelineError",
    "AudioPipeline",
    "StubAudioPipeline",
]
</file>

<file path="src/bot_neutro/api.py">
import logging
import os
from uuid import uuid4
from typing import Dict, Optional

from fastapi import FastAPI, File, Form, Header, Request, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, PlainTextResponse

from . import __version__
from .audio_storage import get_default_audio_session_repository
from .audio_pipeline import AudioPipeline, AudioRequestContext, AudioResponseContext, PipelineError
from .middleware import (
    CorrelationIdMiddleware,
    JSONLoggingMiddleware,
    RateLimitMiddleware,
    RequestLatencyMiddleware,
)
from .llm_tiers import (
    TierInvalidError,
    effective_tier,
    is_forbidden,
    normalize_requested_tier,
    resolve_authorized_tier,
)
from .metrics_runtime import METRICS
from .providers.factory import build_llm_provider, build_stt_provider, build_tts_provider
from .security_ids import derive_api_key_id


METRICS_PAYLOAD = """# HELP sensei_request_latency_seconds Request latency
# TYPE sensei_request_latency_seconds histogram
# HELP sensei_rate_limit_hits_total Total requests rejected by rate limit
# TYPE sensei_rate_limit_hits_total counter
# HELP errors_total Total errors seen by route
# TYPE errors_total counter
# HELP llm_tier_denied_total Total denied LLM tier requests
# TYPE llm_tier_denied_total counter
# HELP mem_reads_total Memory reads
# TYPE mem_reads_total counter
# HELP mem_writes_total Memory writes
# TYPE mem_writes_total counter
# HELP audio_sessions_purged_total Audio sessions purged from storage
# TYPE audio_sessions_purged_total counter
# HELP audio_sessions_current Current audio sessions stored
# TYPE audio_sessions_current gauge
# HELP sensei_requests_total Total requests by route
# TYPE sensei_requests_total counter
"""


def _parse_stats_max_sessions() -> int:
    raw = os.getenv("AUDIO_STATS_MAX_SESSIONS", "20000")
    try:
        value = int(raw)
    except ValueError:
        return 20000
    if value < 0:
        return 0
    return value



def _parse_cors_origins() -> list[str]:
    raw = os.getenv("MUNAY_CORS_ORIGINS", "")
    if not raw:
        return ["http://localhost:5173", "http://127.0.0.1:5173"]
    return [origin.strip() for origin in raw.split(",") if origin.strip()]


CORS_ORIGINS = _parse_cors_origins()


def _with_outcome(response, outcome: str = "ok", detail: str | None = None) -> None:
    response.headers.setdefault("X-Outcome", outcome)
    if detail:
        response.headers["X-Outcome-Detail"] = detail


logger = logging.getLogger("bot_neutro")


def create_app() -> FastAPI:
    app = FastAPI(title="bot-neutro", version=__version__)
    app.state.audio_session_repo = get_default_audio_session_repository()
    app.state.audio_pipeline = AudioPipeline(
        session_repo=app.state.audio_session_repo,
        stt_provider=build_stt_provider(),
        tts_provider=build_tts_provider(),
        llm_provider=build_llm_provider(),
    )


    app.add_middleware(
        CORSMiddleware,
        allow_origins=CORS_ORIGINS,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    app.add_middleware(RequestLatencyMiddleware)
    app.add_middleware(CorrelationIdMiddleware)
    app.add_middleware(RateLimitMiddleware)
    app.add_middleware(JSONLoggingMiddleware)

    @app.middleware("http")
    async def set_default_outcome(request: Request, call_next):
        response = await call_next(request)
        response.headers.setdefault("X-Outcome", "ok")
        return response

    @app.exception_handler(Exception)
    async def global_exception_handler(request: Request, exc: Exception):
        corr_id = request.headers.get("X-Correlation-Id") or str(uuid4())
        logger.exception(
            "Unhandled exception",
            exc_info=exc,
            extra={"corr_id": corr_id}
        )
        response = JSONResponse(
            {"detail": "Internal Server Error"},
            status_code=500
        )
        _with_outcome(response, outcome="error", detail="internal_error")
        response.headers["X-Correlation-Id"] = corr_id
        return response

    @app.get("/healthz")
    async def healthcheck(request: Request):
        METRICS.inc_request("/healthz")
        response = JSONResponse({"status": "ok"})
        _with_outcome(response)
        return response

    @app.get("/readyz")
    async def readiness(request: Request):
        METRICS.inc_request("/readyz")
        response = JSONResponse({"status": "ok"})
        _with_outcome(response)
        return response

    @app.get("/version")
    async def version(request: Request):
        METRICS.inc_request("/version")
        response = JSONResponse({"version": __version__})
        _with_outcome(response)
        return response

    @app.get("/metrics")
    async def metrics(request: Request):
        METRICS.inc_request("/metrics")
        snapshot = METRICS.snapshot()
        dynamic_lines = []

        for route, latency in snapshot["latency"].items():
            for bound in snapshot["latency_bucket_bounds"]:
                bound_label = "+Inf" if bound == float("inf") else str(bound)
                value = latency["buckets"].get(bound, 0)
                dynamic_lines.append(
                    f'sensei_request_latency_seconds_bucket{{route="{route}",le="{bound_label}"}} {value}'
                )
            dynamic_lines.append(
                f'sensei_request_latency_seconds_count{{route="{route}"}} {latency["count"]}'
            )
            dynamic_lines.append(
                f'sensei_request_latency_seconds_sum{{route="{route}"}} {latency["sum"]}'
            )

        dynamic_lines.append(
            f'sensei_rate_limit_hits_total {snapshot["rate_limit_hits_total"]}'
        )
        dynamic_lines.append(f'mem_reads_total {snapshot["mem_reads_total"]}')
        dynamic_lines.append(f'mem_writes_total {snapshot["mem_writes_total"]}')
        dynamic_lines.append(
            f'audio_sessions_purged_total {snapshot["audio_sessions_purged_total"]}'
        )
        dynamic_lines.append(
            f'audio_sessions_current {snapshot["audio_sessions_current"]}'
        )

        for route, value in snapshot["requests_total"].items():
            dynamic_lines.append(f'sensei_requests_total{{route="{route}"}} {value}')

        for route, value in snapshot["errors_total"].items():
            dynamic_lines.append(f'errors_total{{route="{route}"}} {value}')

        for item in snapshot.get("llm_tier_denied_total", []):
            dynamic_lines.append(
                "llm_tier_denied_total"
                f'{{route="{item["route"]}",requested_tier="{item["requested_tier"]}",'
                f'authorized_tier="{item["authorized_tier"]}"}} {item["value"]}'
            )

        payload = METRICS_PAYLOAD + "\n".join(dynamic_lines)
        response = PlainTextResponse(
            payload,
            media_type="text/plain; version=0.0.4; charset=utf-8",
        )
        _with_outcome(response)
        return response

    @app.get("/audio/stats")
    async def audio_stats(
        request: Request, x_api_key: Optional[str] = Header(None, alias="X-API-Key")
    ):
        """
        Stats agregados por tenant. NO expone sesiones ni PII.
        Cumple CONTRATO_NEUTRO_AUDIO_STATS_V1 + POLITICA_PRIVACIDAD_SESIONES.
        """

        corr_id = request.headers.get("X-Correlation-Id") or str(uuid4())
        if not x_api_key:
            response = JSONResponse({"detail": "X-API-Key required"}, status_code=401)
            _with_outcome(response, outcome="error", detail="auth.missing_api_key")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response

        METRICS.inc_request("/audio/stats")

        api_key_id = derive_api_key_id(x_api_key)
        sessions = request.app.state.audio_session_repo.list_by_api_key(
            api_key_id,
            limit=STATS_MAX_SESSIONS,
            offset=0,
            api_key_id_autenticada=api_key_id,
        )

        by_stt: Dict[str, int] = {}
        by_llm: Dict[str, int] = {}
        by_tts: Dict[str, int] = {}
        for session in sessions:
            by_stt[session["provider_stt"]] = by_stt.get(session["provider_stt"], 0) + 1
            by_llm[session["provider_llm"]] = by_llm.get(session["provider_llm"], 0) + 1
            by_tts[session["provider_tts"]] = by_tts.get(session["provider_tts"], 0) + 1

        snapshot = METRICS.snapshot()
        payload = {
            "api_key_id": api_key_id,
            "totals": {
                "sessions_current": len(sessions),
                "limit_applied": STATS_MAX_SESSIONS,
                "sessions_purged_total": snapshot.get("audio_sessions_purged_total", 0),
            },
            "by_provider": {
                "stt": by_stt,
                "llm": by_llm,
                "tts": by_tts,
            },
        }

        response = JSONResponse(payload)
        _with_outcome(response)
        response.headers.setdefault("X-Correlation-Id", corr_id)
        return response

    ERROR_STATUS_MAPPING = {
        "bad_request": (400, "audio.bad_request"),
        "unsupported_media_type": (415, "audio.unsupported_media_type"),
        "unauthorized": (401, "auth.unauthorized"),
        "stt_error": (502, "audio.stt_error"),
        "llm_error": (502, "audio.llm_error"),
        "tts_error": (502, "audio.tts_error"),
        "provider_timeout": (504, "audio.provider_timeout"),
        "storage_error": (503, "audio.storage_error"),
        "internal_error": (500, "audio.internal_error"),
    }

    VALID_MUNAY_CONTEXTS = {"diario_emocional", "coach_habitos", "reflexion_general"}

    @app.post("/audio")
    async def audio_endpoint(
        request: Request,
        audio_file: UploadFile = File(..., description="Audio en formato soportado"),
        locale: str = Form("es-CO"),
        user_external_id: Optional[str] = Form(None),
        x_munay_llm_tier: Optional[str] = Header(
            default=None, alias="x-munay-llm-tier"
        ),
    ):
        METRICS.inc_request("/audio")

        corr_id = request.headers.get("X-Correlation-Id") or str(uuid4())
        api_key = request.headers.get("X-API-Key")
        if not api_key:
            METRICS.inc_error("/audio")
            response = JSONResponse({"detail": "X-API-Key required"}, status_code=401)
            _with_outcome(response, outcome="error", detail="auth.unauthorized")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response
        api_key_id = derive_api_key_id(api_key)
        munay_context = request.headers.get("x-munay-context")

        try:
            requested_tier = normalize_requested_tier(x_munay_llm_tier)
        except TierInvalidError:
            METRICS.inc_error("/audio")
            response = JSONResponse({"detail": "llm.tier_invalid"}, status_code=400)
            _with_outcome(response, outcome="error", detail="llm.tier_invalid")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response

        authorized_tier = resolve_authorized_tier(api_key)

        if is_forbidden(requested_tier, authorized_tier):
            METRICS.inc_error("/audio")
            METRICS.inc_llm_tier_denied_total(
                "/audio",
                requested_tier,
                authorized_tier,
            )
            logger.info(
                "llm_tier_denied",
                extra={
                    "event": "llm_tier_denied",
                    "requested_tier": requested_tier,
                    "authorized_tier": authorized_tier,
                    "api_key_id": api_key_id,
                    "corr_id": corr_id,
                },
            )
            response = JSONResponse({"detail": "llm.tier_forbidden"}, status_code=403)
            _with_outcome(response, outcome="error", detail="llm.tier_forbidden")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response

        if munay_context and munay_context not in VALID_MUNAY_CONTEXTS:
            METRICS.inc_error("/audio")
            response = JSONResponse(
                {"detail": "invalid x-munay-context"}, status_code=400
            )
            _with_outcome(response, outcome="error", detail="audio.bad_request")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response

        audio_bytes = await audio_file.read()
        if not audio_bytes:
            METRICS.inc_error("/audio")
            response = JSONResponse({"detail": "empty audio"}, status_code=400)
            _with_outcome(response, outcome="error", detail="audio.bad_request")
            response.headers.setdefault("X-Correlation-Id", corr_id)
            return response

        mime_type = audio_file.content_type or ""
        client_meta: Dict[str, str] = {}

        munay_user_id = request.headers.get("x-munay-user-id")
        if munay_user_id:
            client_meta["munay_user_id"] = munay_user_id
        if munay_context:
            client_meta["munay_context"] = munay_context

        llm_tier = effective_tier(requested_tier, authorized_tier)

        ctx: AudioRequestContext = {
            "corr_id": corr_id,
            "api_key_id": api_key_id or "",
            "audio_bytes": audio_bytes,
            "mime_type": mime_type,
            "locale": locale,
            "user_external_id": user_external_id,
            "client_meta": client_meta or None,
        }

        ctx["llm_tier"] = llm_tier

        result: AudioResponseContext | PipelineError = request.app.state.audio_pipeline.process(ctx)

        if "code" in result:
            status_code, detail_value = ERROR_STATUS_MAPPING.get(
                result["code"], (500, "audio.internal_error")
            )
            METRICS.inc_error("/audio")
            response = JSONResponse(
                {"detail": result.get("message")}, status_code=status_code
            )
            _with_outcome(response, outcome="error", detail=detail_value)
        else:
            body = {
                "session_id": result.get("session_id"),
                "corr_id": result.get("corr_id") or corr_id,
                "transcript": result["transcript"],
                "reply_text": result["reply_text"],
                "tts_url": result.get("tts_url"),
                "usage": {
                    "input_seconds": result["usage"]["input_seconds"],
                    "output_seconds": result["usage"]["output_seconds"],
                    "stt_ms": result["usage"]["stt_ms"],
                    "llm_ms": result["usage"]["llm_ms"],
                    "tts_ms": result["usage"]["tts_ms"],
                    "total_ms": result["usage"]["total_ms"],
                    "provider_stt": result["usage"]["provider_stt"],
                    "provider_llm": result["usage"]["provider_llm"],
                    "provider_tts": result["usage"]["provider_tts"],
                },
                "meta": result.get("meta"),
            }
            response = JSONResponse(body, status_code=200)
            _with_outcome(response, outcome="success", detail="audio_processed")

        response.headers.setdefault("X-Correlation-Id", corr_id)
        return response

    return app


_APP: FastAPI | None = None


def get_app() -> FastAPI:
    global _APP
    if _APP is None:
        _APP = create_app()
    return _APP
</file>

<file path="docs/02_ESTADO_Y_NORTE.md">
# NORTE MUNAY v2.1 — Estado y Principios Operativos

## 1. Principio Supremo
El proyecto Munay/SenseiKaizen debe avanzar sin contradicciones, sin retrocesos, sin redefinir decisiones previamente aprobadas.
Toda modificación debe pasar por una **ORDEN KAIZEN** (L1, L2 o L3).

## 2. Gobernanza del Proyecto
El proyecto sigue un modelo **Contracts-First**, con la siguiente secuencia OBLIGATORIA:

1. Actualizar los contratos en `/docs/`
2. Actualizar historial PR
3. Alinear ADRs si aplica
4. recién después tocar código

Los contratos NO se ignoran, NO se contradicen, NO se redefinen sin orden formal.

### Visión de plataforma

* `bot-neutro` es el **núcleo API de voz + LLM neutral**.
* Su objetivo es ofrecer un endpoint HTTP estable que reciba audio y devuelva:

  * transcripción (`transcript`),
  * respuesta del modelo (`reply_text`),
  * audio de respuesta opcional (`tts_url`),
  * métricas de uso (`usage.*`).
* La API está diseñada para ser:

  * consumida por **Munay** como primer cliente oficial,
  * reutilizada por otros proyectos propios del autor,
  * ofrecida como servicio a terceros (empresas, integradores tipo n8n/Make).
* El diseño es **multi-tenant-ready**: el uso real de múltiples clientes se hará por API keys, pero la filosofía ya asume varios consumidores desde el principio.
* La priorización de la siguiente capa encima del core (`dashboards`, `cliente oficial`, `planes por API key`) se detalla en `docs/ROADMAP_CAPA_SUPERIOR_V1.md`. Toda evolución debe alinearse a ese roadmap y actualizar este Norte si hay cambios estructurales.
* El primer cliente oficial definido para `/audio` es un dashboard web mínimo Munay, descrito en
  `docs/CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md` y `docs/UX_CLIENTE_OFICIAL_MUNAY_V1.md`, que actúa como referencia oficial de consumo de la API Pública v1.

### 2.1 Gobernanza SKB y ADRs
- `docs/CONTRATO_SKB_GOBERNANZA.md` es contrato fuente para prompts y órdenes (D→D→C, bloqueos y reglas contracts-first).
- `docs/CONTRATO_NEUTRO_CONTRIBUCION.md` es guía obligatoria para cualquier PR.
- `docs/adr/` contiene los ADRs obligatorios para cambios de arquitectura, seguridad o SLO/SLA; toda decisión usa `ADR_TEMPLATE.md`.
- Pipeline mínimo de CI (no negociable):
  - `.github/workflows/validate_norte.yml`
  - `.github/workflows/ci_tests.yml` (ejecuta `pytest -q` y `pytest --cov=src --cov-fail-under=80`).

---

## 3. SLOs oficiales (audio)
| Métrica | Valor |
|--------|--------|
| **audio_p95_ms** | ≤ 1500 ms |
| **error_rate_max** | ≤ 1% |
| **uptime_target** | 99.9% |
| **budget_burn_alert** | 85/90/95% |

Ver `docs/NEUTRO_SLO_AUDIO_OPERACIONAL.md` para la definición operativa, queries y alertas de referencia del SLO de audio.

Todas las implementaciones deben acercarse a estos límites incluso en pruebas.

---

## 4. UI como contrato
Toda respuesta debe incluir estos headers:

- `X-Outcome`
- `X-Correlation-Id`
- `X-Outcome-Detail` cuando aplica

El sistema debe mantener consistencia absoluta.

---

## 5. Observabilidad
Cada PR debe incluir:

- Métricas Prometheus necesarias  
- Queries PromQL  
- Alertas burn-rate  
- Umbrales alineados al SLO  
- Pruebas (k6 o equivalente)  

---

## 6. Flujo Kaizen (órdenes)

### **L1 — Agregar o corregir archivos de gobierno**
Contratos, NORTE, ADR, CI, runbooks.

### **L2 — Cambios en lógica, endpoints, modelos**
Implementación respetando contratos.

### **L3 — Refactors internos**
Sin cambiar comportamiento observable.

---

## 7. Regla de Coherencia entre Hilos
Cada nuevo hilo debe comenzar con este mensaje:

> Usa SIEMPRE los archivos del repo como verdad absoluta:  
> - `docs/02_ESTADO_Y_NORTE.md`  
> - `docs/HISTORIAL_PR.md`  
> - Todos los contratos NEUTRO  
> - Todos los contratos MUNAY  
> No redefines nada fuera de estos documentos.  
> Todo cambio requiere una ORDEN KAIZEN.

---

## 8. Estado Actual del Sistema (última actualización)
- Pipeline de audio completo con almacenamiento en memoria
- Pipeline de audio con providers enchufables (stub por defecto, Azure seleccionable por ENV)
- Azure Speech STT/TTS real disponible como opt-in local, con fallback automático a stub ante fallos
- LLMProvider neutral consolidado: stub por defecto, proveedores reales activables por ENV (`LLM_PROVIDER`)
- Selección freemium/premium modelada vía `context["llm_tier"]`, alimentada desde la capa HTTP vía header opcional `x-munay-llm-tier` (`freemium`/`premium`, case-insensitive). Header ausente → usa tier autorizado por API key. Header inválido → `400` con `X-Outcome-Detail=llm.tier_invalid`.
- Tests unitarios de providers externos deterministas y aislados del entorno real:
  - No dependen de SDKs instalados ni credenciales reales.
  - Los errores de dependencia (p. ej. falta de SDK) se validan mediante mocks controlados.
  - Pruebas reales con Azure existen como capa de integración opcional (`-m azure_integration`), nunca obligatoria en CI.
- Headers Munay (`x-munay-user-id`, `x-munay-context`) integrados
- Métricas runtime (`METRICS`) activas
- Rate-limit funcional por API key
- api_key_id persistido en sesiones es derivado sha256[:12]; X-API-Key nunca se persiste
- 100% de pruebas unitarias verdes
- PRs recientes documentados en `HISTORIAL_PR.md`
- Cliente oficial Munay v1 (dashboard web) implementado en `clients/munay-dashboard/`, alineado a `CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md` y `CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md`, con registro en `docs/HISTORIAL_PR.md` (2025-12-21).
- README actualizado para reflejar que `/audio` está implementado (antes indicaba stub 501) y documentar el payload real y modo stub por defecto con providers Azure/OpenAI opt-in.
- Contratos públicos ajustados a error 400 cuando falta audio; el frontend puede mostrar validaciones 422 en la UI, pero el backend responde 400.
- Storage de sesiones persistente en disco con TTL y purga interna (configurable por ENV), sin endpoints HTTP de lectura/listado; `transcript`/`reply_text` no se persisten por defecto y la retención sensible se limita a 1 día cuando se habilita.
- Contrato de Storage/Retención de sesiones definido (CONTRATO_NEUTRO_SESIONES_STORAGE_V1.md). La política de privacidad bloquea endpoints/dashboards de lectura/listado; persistencia mínima L2 permitida bajo TTL y sanitización.
- Política de sesiones definida en `CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md` y aplicada como bloqueo para exponer lecturas/dashboards/persistencia hasta cumplir control de acceso y retención.
- Política de tiers/costos LLM definida en `CONTRATO_NEUTRO_LLM_TIERS_COSTOS_V1.md`: la API-Key es la fuente de verdad, el header `x-munay-llm-tier` es solo `tier_solicitado` y no puede escalar privilegios.
- Enforcement L2 implementado en `/audio`: si `tier_solicitado` > `tier_autorizado` responde `403` con `X-Outcome-Detail=llm.tier_forbidden`, incrementa `llm_tier_denied_total{route="/audio",requested_tier,authorized_tier}` y `errors_total{route="/audio"}`, y emite logs estructurados (logger `extra`) con `requested_tier`, `authorized_tier`, `api_key_id` y `corr_id`.

---

## 9. Pruebas oficiales (stub vs Azure)

### 9.1 Modo stub (base CI y día a día)
- Limpiar ENV antes de probar para forzar stub y que cualquier test `azure_integration` quede `skipped`:

  ```powershell
  Remove-Item Env:AUDIO_STT_PROVIDER -ErrorAction SilentlyContinue
  Remove-Item Env:AUDIO_TTS_PROVIDER -ErrorAction SilentlyContinue
  Remove-Item Env:AZURE_SPEECH_KEY -ErrorAction SilentlyContinue
  Remove-Item Env:AZURE_SPEECH_REGION -ErrorAction SilentlyContinue
  Remove-Item Env:AZURE_SPEECH_STT_LANGUAGE_DEFAULT -ErrorAction SilentlyContinue
  Remove-Item Env:AZURE_SPEECH_TTS_VOICE_DEFAULT -ErrorAction SilentlyContinue
  Remove-Item Env:AZURE_SPEECH_TEST_WAV_PATH -ErrorAction SilentlyContinue
  Remove-Item Env:LLM_PROVIDER -ErrorAction SilentlyContinue
  Remove-Item Env:OPENAI_API_KEY -ErrorAction SilentlyContinue
  Remove-Item Env:OPENAI_BASE_URL -ErrorAction SilentlyContinue
  Remove-Item Env:OPENAI_MODEL_FREEMIUM -ErrorAction SilentlyContinue
  Remove-Item Env:OPENAI_MODEL_PREMIUM -ErrorAction SilentlyContinue
  ```

- Comandos oficiales:

  ```powershell
  python -m pytest -q
  python -m pytest --cov=src --cov-fail-under=80
  ```

- El header opcional `x-munay-llm-tier` para `/audio` no altera las pruebas base: si no se envía, el pipeline mantiene `freemium` por defecto y el stub sigue devolviendo `"stub reply text"`.

- Regla de oro: `--cov` se ejecuta siempre en modo stub (sin credenciales ni SDK Azure). Este será el paso obligatorio en CI.
- Futuras pruebas reales de LLM usarán un marcador dedicado (p. ej. `llm_integration`) y seguirán siendo opt-in, igual que Azure.

### 9.2 Modo Azure opt-in (integración manual)
- Cargar variables con `. .\set_env_azure_speech.ps1` (fuera de control de versiones) y activar el `.venv`.
- Validar providers reales con:

  ```powershell
  python -m pytest -m azure_integration -q
  ```

- Este bloque es opcional y no afecta al coverage base ni al pipeline CI.

### 9.3 Modo LLM OpenAI opt-in (integración manual)
- Marcador dedicado: `llm_integration`.
- Variables requeridas para habilitar la prueba real:

  - `OPENAI_API_KEY`
  - `OPENAI_MODEL_FREEMIUM`
  - `OPENAI_LLM_TEST_ENABLED=1`

- Ejemplo de ejecución (PowerShell):

  ```powershell
  $env:LLM_PROVIDER = "openai"
  $env:OPENAI_API_KEY = "<TU_API_KEY_OPENAI>"
  $env:OPENAI_MODEL_FREEMIUM = "gpt-4.1-mini"
  $env:OPENAI_LLM_TEST_ENABLED = "1"

  python -m pytest -m llm_integration -q
  ```

- Notas:

  - La prueba es opt-in y queda `skipped` si no se configuran los envs anteriores.
  - Los comandos base (`pytest -q` y `pytest --cov=src --cov-fail-under=80`) siguen ejecutándose en modo stub sin depender de OpenAI ni de red.

---

## 10. Integración LLM
- Contrato `LLMProvider` operativo con stub determinista como default.
- OpenAI disponible como provider opt-in vía `LLM_PROVIDER=openai`, con fallback automático al stub y selección de modelo mediante `context["llm_tier"]` (`freemium`/`premium`).
- Futuras integraciones (Azure OpenAI, modelos locales) seguirán el mismo patrón sin requerir credenciales en CI.
- La elección del proveedor LLM (OpenAI, futuros modelos, etc.) es un detalle interno del Bot Neutro.
- El contrato público `/audio` se mantiene estable: los clientes no necesitan saber qué proveedor hay por debajo, solo confían en:

  * formato de entrada (audio + headers),
  * formato de salida (JSON con `transcript`, `reply_text`, `usage.*`),
  * garantías de fallback (stub) ante fallos externos.
- Regla adicional: no se permiten paquetes locales con nombres que choquen con dependencias críticas (p. ej. `httpx`, `openai`). Cualquier cliente HTTP interno debe vivir bajo un nombre propio (ej. `httpx_local`).

- El detalle de la **API Pública v1** (endpoint `/audio`) se documenta en `docs/CONTRATO_API_PUBLICA_V1.md` y actúa como contrato de producto para clientes externos (incluyendo Munay).

- Comportamiento ante errores de OpenAI:
  - Si el SDK lanza errores de cuota/rate limit (por ejemplo `insufficient_quota`, HTTP 429), el provider registra `openai_llm_error` en logs y cae de forma controlada al `StubLLMProvider`.
  - En esos casos, el endpoint `/audio` sigue devolviendo `200 OK` y la métrica `usage.provider_llm` incluye la cadena de fallback (ej. `openai-llm|stub-llm`).
  - Este patrón garantiza que problemas externos de facturación/cuota no rompan el contrato HTTP ni la experiencia del cliente.

- Patrón de uso recomendado:
  - `freemium` (mini) como tier por defecto para casi todas las llamadas.
  - `premium` solo cuando el cliente envía el header `x-munay-llm-tier: Premium`, de forma explícita y consciente del mayor coste.
  - El mini-milestone actual se considera **“Audio + LLM listo para pruebas con crédito real”**: en cuanto la cuenta disponga de saldo, `/audio` empezará a devolver respuestas reales del LLM sin cambios de código.

---

## 11. Filosofía del Proyecto
- **Máxima claridad**
- **Cero contradicciones**
- **Iteración sin pérdidas de coherencia**
- La IA actúa como arquitecto, no como creativo descontrolado
- Cada avance debe poder reproducirse sin error

---

## 12. Mantenimiento
Toda evolución del proyecto DEBE modificar este archivo.
</file>

<file path="docs/HISTORIAL_PR.md">
# HISTORIAL_PR – Bot Neutro / Munay

> Convención: el último cambio va arriba. Solo registramos cambios que
> afectan contratos, comportamiento observable o el Norte del proyecto.

## 2025-12-24 – CI/Workflows habilitados para develop

- Se actualizaron los triggers de workflows guardianes para incluir `develop` junto a `main`.
- Archivos: `.github/workflows/ci_tests.yml`, `.github/workflows/validate_norte.yml`.
- Resultado CI: pendiente de ejecución en GitHub (local no ejecutado).

## 2025-12-23 – Persistencia y retención L2 de sesiones `/audio`

- Se reemplaza el storage in-memory por un repositorio persistente en disco con TTL y purga automática configurable.
- Se incorporan flags para persistir `transcript`/`reply_text` con TTL máximo de 1 día y sanitización de `client_meta` sin PII.
- Se amplían tests de retención, purga y métricas, y se actualiza el NORTE/ENV_VARS para reflejar la persistencia y el bloqueo de endpoints de lectura.

## 2025-12-22 – Contrato Storage & Retención de Sesiones (contracts-first)

- Se crea `CONTRATO_NEUTRO_SESIONES_STORAGE_V1.md` definiendo modelo de datos, retención/TTL, control de acceso y observabilidad declarativa para sesiones de audio.
- Se actualiza `02_ESTADO_Y_NORTE.md` para reflejar el contrato y mantener el bloqueo de persistencia/lecturas hasta L2.
- Sin cambios runtime.

## 2025-12-22 – Implementación L2 enforcement tiers LLM en /audio

- Se valida el header `x-munay-llm-tier` contra el tier autorizado por API key (`freemium|premium`), rechazando valores inválidos con `400` (`X-Outcome-Detail=llm.tier_invalid`).
- Se bloquean escaladas de tier con `403` (`X-Outcome-Detail=llm.tier_forbidden`), incrementando `llm_tier_denied_total{route="/audio",requested_tier,authorized_tier}` y `errors_total{route="/audio"}` y emitiendo logs estructurados (logger `extra`) con `requested_tier`, `authorized_tier`, `api_key_id`, `corr_id`.
- Se actualizan tests de enforcement y métricas, y se documenta el estado en el NORTE.

## 2024-12-19 – Hardening api_key_id derivado end-to-end

- Se deriva `api_key_id` con SHA-256 truncado en `/audio` y `/audio/stats`, sin persistir secretos ni aceptar `X-API-Key-Id` de cliente.
- `/audio/stats` filtra por el `api_key_id` derivado y mantiene respuesta agregada sin PII.
- Rate limit usa el `api_key_id` derivado como clave interna.

## 2025-12-17 – Política de tiers/costos LLM por API-Key (contracts-first, docs-only)

- Se crea `CONTRATO_NEUTRO_LLM_TIERS_COSTOS_V1.md` para definir los tiers permitidos (`freemium|premium`), las cuotas parametrizables y la regla de que la API-Key es la única fuente de verdad; el header `x-munay-llm-tier` es solo `tier_solicitado`.
- Se actualiza `02_ESTADO_Y_NORTE.md` para referenciar el nuevo contrato y dejar explícito que el enforcement llegará en L2 (este PR no cambia runtime; solo define la política contractual): `/audio` debe rechazar escaladas de tier, devolver `X-Outcome-Detail=llm.tier_forbidden|llm.tier_invalid` y exponer métricas/logs de denegación.
- Garantías: (a) bloque de no-escalado por header documentado, (b) semántica de errores/headers/correlación (`X-Outcome`, `X-Outcome-Detail`, `X-Correlation-Id`), (c) observabilidad esperada con `llm_tier_denied_total` e incrementos agregados en `errors_total{route="/audio"}`.
- Deuda anotada: normalizar el orden cronológico completo de `HISTORIAL_PR` en una próxima orden.

## 2025-12-17 – Kaizen Guardrails + Storage hardening + Stats agregados sin PII

- Se endurece `scripts/kaizen_validate_order.py` para validar metadata real (no placeholders) y aplicar regla: `diff --git` obligatorio solo cuando `TIPO=CAMBIAR`.
- Se agregan tests `tests/test_kaizen_validate_order.py` para que la calidad de órdenes sea estable y no dependa de “revisar después”.
- Se completa hardening del storage in-memory con tests de bordes: purge disabled + legado sin `expires_at`.
- Se crea `CONTRATO_NEUTRO_AUDIO_STATS_V1.md` e implementa `GET /audio/stats` (solo agregados; sin transcript/reply_text/etc).

## 2025-12-21 – Implementación cliente oficial Munay v1 (dashboard web mínimo)

- Se crea el proyecto frontend en `clients/munay-dashboard/` (React + TypeScript + Vite) como primer cliente oficial del endpoint `/audio`.
- Se agrega documentación técnica `CLIENTE_OFICIAL_MUNAY_TECNICO_V1.md` y variables de entorno `.env.example`.
- No se modifica el contrato HTTP ni el payload JSON de `/audio`; solo se construye el consumidor oficial siguiendo los contratos existentes.
## 2025-12-20 – Diseño cliente oficial Munay (dashboard mínimo)

- Se define `CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md` como contrato del primer cliente oficial de `/audio` (dashboard web mínimo para subir/grabar audio y consumir la API).
- Se documenta la UX mínima en `UX_CLIENTE_OFICIAL_MUNAY_V1.md` y se referencia desde `02_ESTADO_Y_NORTE.md`.
- No se modifica el endpoint `/audio` ni se añade código; es una preparación contracts-first para implementar el cliente oficial en una siguiente orden.

## 2025-12-20 – ROADMAP_CAPA_SUPERIOR_V1 y visión de siguiente paso

- Se crea `ROADMAP_CAPA_SUPERIOR_V1.md` para comparar y priorizar la siguiente capa encima del core `/audio` (dashboards, primer cliente oficial, límites/planes por `X-API-Key`).
- Se documenta en `02_ESTADO_Y_NORTE.md` que la priorización de la capa superior se rige por ese roadmap, sin modificar contratos HTTP ni payloads JSON actuales.
- No se toca código; es una actualización de gobernanza y planificación para consolidar el Bot Neutro como plataforma de voz + LLM multi-tenant.

## 2025-12-20 – Visión de plataforma y contrato API Pública v1

- Se actualiza `02_ESTADO_Y_NORTE.md` para dejar explícito que `bot-neutro`
  es una plataforma API de voz + LLM neutral, pensada para múltiples clientes,
  con Munay como primer consumidor oficial.
- Se crea `CONTRATO_API_PUBLICA_V1.md` describiendo el endpoint `/audio`
  como API Pública v1 (headers, body, respuesta, errores, notas de
  multi-tenant y ejemplos).
- No se modifica código ni contratos JSON existentes; se trata de una
  actualización de gobernanza y documentación para consolidar el Bot Neutro
  como producto vendible. El contrato v1 de `/audio` refleja exactamente
  el comportamiento ya observado en pruebas locales.

## 2025-12-20 – Cierre mini-milestone Audio + LLM M1 (fallback y operación)

- Se documenta en `02_ESTADO_Y_NORTE.md` y `RUNBOOK_LLM.md` el comportamiento del provider OpenAI ante errores de cuota/rate limit (`insufficient_quota` → fallback controlado al stub).
- Se explicita el patrón recomendado de uso freemium/premium y se marca el estado del sistema como “Audio + LLM listo para pruebas con crédito real”.
- No se modifica código: el pipeline `/audio` y las respuestas HTTP permanecen iguales; solo se clarifica la operación ante fallos externos del proveedor.

## 2025-12-20 – Eliminación de sombra local sobre `httpx` para OpenAI LLM

 - Se renombra el paquete local `httpx/` a `httpx_local/` para liberar el nombre `httpx` y permitir que el SDK de OpenAI use la biblioteca oficial de `site-packages`.
- No se modifica el contrato HTTP ni el pipeline `/audio`; solo se elimina el conflicto de import.
- Los tests base (`pytest -q`, `pytest --cov=src --cov-fail-under=80`) y la prueba opt-in `llm_integration` pasan con el SDK de OpenAI usando el `httpx` oficial.

## 2025-12-19 – Prueba opcional `llm_integration` para OpenAI LLM

- Se añade `tests/test_llm_openai_integration.py` con marcador `llm_integration`, gated por `OPENAI_LLM_TEST_ENABLED`, para validar el wiring real de `OpenAILLMProvider.from_env`.
- Se actualiza `docs/02_ESTADO_Y_NORTE.md` y `docs/RUNBOOK_LLM.md` documentando cómo ejecutar la prueba sin impactar el modo stub ni el CI.
- No se modifican contratos HTTP ni el comportamiento observable de `/audio`; los tests base y el coverage permanecen iguales.

## 2025-12-18 – Header `x-munay-llm-tier` y propagación de tier al LLM

- `/audio` acepta el header opcional `x-munay-llm-tier` (`freemium`/`premium`, case-insensitive) y lo normaliza a `context["llm_tier"]`.
- El pipeline de audio propaga la tier al `LLMProvider`, manteniendo default seguro `freemium` cuando falta o es inválida.
- La respuesta stub y el comportamiento para clientes sin el nuevo header permanecen iguales.

# 2025-12-17 – Hardening retención in-memory y gobernanza Kaizen

- Se endurece el parseo de `AUDIO_SESSION_RETENTION_DAYS` con fallback a 30 y clamp a 0 cuando el valor es inválido o negativo.
- Se documentan las variables de entorno en `docs/CONFIG/ENV_VARS.md` y se referencia desde README como fuente de verdad.
- Se añaden tests para validar fallback y clamp de retención en `tests/test_audio_storage_privacidad.py`.
- Se actualiza la plantilla de órdenes Kaizen para exigir diffs, DoD, sección de “NO IMPLEMENTADO” y comandos de verificación obligatorios.

## 2025-12-17 – Política de sesiones de audio v1 (contracts-first + enforcement mínimo in-memory)

- Se crea `CONTRATO_NEUTRO_POLITICA_PRIVACIDAD_SESIONES.md` para gobernar privacidad, seguridad, retención y control de acceso de `audio_session`.
- Se actualiza `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md` con `expires_at` y reglas de `list_by_*` que exigen coincidencia de `api_key_id` autenticada.
- Se incorpora `docs/MATRIZ_CUMPLIMIENTO_CONTRATOS.md` para trazar contrato ↔ código ↔ tests.
- Se mantiene el bloqueo: no se exponen endpoints de lectura/listado mientras rige la política.

## 2025-12-17 – Correcciones menores tras auditoría L1 (docs-only)

- Se corrigen referencias a componentes del dashboard en `ORDEN_KAIZEN_L1_AUDITORIA_20251217.md`.
- Se actualiza `README.md` para reflejar que `/audio` está implementado y usa providers stub por defecto (Azure/OpenAI opt-in).
- Se alinean `CONTRATO_CLIENTE_OFICIAL_MUNAY_V1.md` y `CONTRATO_API_PUBLICA_V1.md` con error 400 por audio faltante, dejando nota sobre validaciones 422 del frontend.
- Se agregan hallazgos al NORTE (`docs/02_ESTADO_Y_NORTE.md`) y se registra esta orden como actualización de gobernanza L1.

## 2025-12-17 – Orden Kaizen L1 (auditoría contratos vs código)

- Se documenta la auditoría global de gobernanza L1 en `ORDEN_KAIZEN_L1_AUDITORIA_20251217.md`, cubriendo mapa de repo, middlewares/providers/endpoints y cuadro Contrato ↔ Código.
- No se realizan cambios funcionales; se dejan hallazgos de privacidad, seguridad y zonas oscuras para futuras órdenes.

## 2025-12-17 – OpenAI LLM opt-in y selección freemium/premium

- Se añade `OpenAILLMProvider` como proveedor LLM opt-in, activable vía `LLM_PROVIDER=openai` con fallback automático a `StubLLMProvider`.
- Se documenta en `docs/02_ESTADO_Y_NORTE.md` y `docs/CONTRATO_NEUTRO_LLM.md` la selección de proveedor por ENV y el uso de `context["llm_tier"]` (`freemium`/`premium`) sin acoplarlo todavía a la capa HTTP.
- Se crea `docs/RUNBOOK_LLM.md` con instrucciones para operar el LLM en modo stub (CI) y modo OpenAI en local.
- Se actualiza la factoría de providers (`factory.py`) y el wiring del `AudioPipeline` para usar el `LLMProvider` neutral sin alterar el contrato observable de `/audio`.

## 2025-12-17 – LLMProvider neutral consolidado y wiring stub en pipeline de audio

- Se consolida el contrato `LLMProvider` con atributos `provider_id`/`latency_ms` alineados a STT/TTS y firma `generate_reply(transcript: str, context: dict) -> str`.
- Se implementa `StubLLMProvider` determinista que siempre devuelve `"stub reply text"` y mantiene latencia explícita para métricas.
- La fábrica de providers expone la construcción de LLM stub y el `AudioPipeline` sigue usando providers enchufables sin cambiar el contrato de `/audio`.
- No se integra ningún LLM externo; se preserva el modo stub y las respuestas actuales.

## 2025-12-16 – Órdenes de prueba stub vs Azure y mini-milestone LLM

- Se formalizan los comandos oficiales para pruebas en modo stub y con Azure opt-in en `docs/02_ESTADO_Y_NORTE.md` y `RUNBOOK_AZURE_SPEECH.md`, incluyendo limpieza de variables de entorno antes de `--cov`.
- Se refuerza que el coverage (`--cov=src --cov-fail-under=80`) se ejecuta siempre sin dependencias de Azure y que los tests `azure_integration` son opcionales.
- Se documenta el mini-milestone previo a LLM: consolidar el contrato neutral `LLMProvider` (`generate_reply(transcript: str, context: dict) -> str` con `provider_id`/`latency_ms`) antes de integrar proveedores reales.

## 2025-12-15 – Logging Azure Speech y prueba de integración opcional

- Se añaden logs claros en los providers Azure STT/TTS antes del fallback para exponer razones y detalles de cancelación.
- Se crea una prueba de integración opcional (`-m azure_integration`) que usa un WAV real definido por ENV para verificar el camino de STT real.
- Se documenta en `RUNBOOK_AZURE_SPEECH.md` cómo habilitar Azure Speech y ejecutar la prueba; las unitarias siguen siendo stub y deterministas.

## 2025-12-14 – Hardening tests de providers Azure (independientes de entorno real)

- Se ajustan los tests de `factory` para que la ruta de error por ausencia de SDK de Azure se pruebe mediante mocks sobre `_require_sdk`, en lugar de depender de la instalación local del SDK.
- Se añade un test simétrico para STT (`AzureSTTProvider`) que verifica el mismo patrón de fallo.
- Se documenta en el NORTE que los unit tests de providers externos son deterministas y no consultan el entorno real; las pruebas con Azure real se reservarán para una capa de integración futura.

## 2025-12-13 – Azure Speech real (opt-in) con fallback a stub

- Se activan las implementaciones reales de `AzureSTTProvider` y `AzureTTSProvider` con import perezoso del SDK de Azure Speech.
- La fábrica falla temprano si faltan credenciales o la librería, manteniendo el modo stub por defecto.
- Ante errores de Azure se degrada automáticamente al stub por petición, reflejando `provider_*` como `azure-*|stub-*`.
- Se documenta la semántica de fallback y se añaden pruebas unitarias para fábricas y pipeline de audio.

## 2025-12-12 – Pipeline de audio enchufable (stub + Azure skeleton)

- Se introduce un orquestador `AudioPipeline` con providers enchufables (STT/TTS/LLM) y selección por variables de entorno (`AUDIO_STT_PROVIDER`, `AUDIO_TTS_PROVIDER`).
- El modo por defecto sigue siendo el stub actual, preservando contratos y tests de `/audio`.
- Se agregan interfaces y factories de providers en `src/bot_neutro/providers/` y un skeleton de `AzureSTTProvider`/`AzureTTSProvider`, activables por ENV para futura integración real con Azure Speech.

## 2025-12-11 – Histograma de latencia para /audio y stub httpx de pruebas

- Se añade `RequestLatencyMiddleware` para medir la duración de cada petición y alimentar el
  histograma de latencia en `InMemoryMetrics.observe_latency`, por ruta.
- `/metrics` ahora exporta buckets `sensei_request_latency_seconds_bucket`, `count` y `sum`
  por ruta, incluyendo `/audio`, alineado con `docs/NEUTRO_SLO_AUDIO_OPERACIONAL.md`.
- Se agrega cobertura de regresión para el histograma de `/audio` en `tests/test_metrics_basic.py`
  verificando la exposición de buckets y agregados en `/metrics`.
- Se incorpora un stub mínimo de `httpx` embebido en el repo, usado únicamente por los tests
  (no se introduce dependencia de `httpx` externo en el runtime).

## 2025-12-10 – SLO audio operativos + queries y alertas (plantillas de referencia)

- Se crea `docs/NEUTRO_SLO_AUDIO_OPERACIONAL.md` con la semántica operativa del SLO de audio, queries PromQL y uso de k6 como validación manual/local.
- Se añaden reglas de alerta de referencia en `docs/prometheus_rules_slo_audio.yml` alineadas a p95 ≤1500 ms, error rate ≤1% y budget burn 85/90/95%.
- Se incorpora el script de carga `tools/load/k6_audio_slo.js` (con `sample_silence.wav`) para estresar `/audio` manualmente sin integrarlo al CI actual.

## 2025-12-09 – Observabilidad y métricas de rate limit

- `CONTRATO_NEUTRO_OBSERVABILIDAD.md` refuerza la lista de métricas núcleo, explicitando incrementos para `sensei_rate_limit_hits_total`, `mem_reads_total`, `mem_writes_total` y los contadores por ruta.
- `CONTRATO_NEUTRO_RATE_LIMIT.md` aclara que cada 429 mantiene los headers `X-Outcome`/`X-Outcome-Detail` y aumenta `sensei_rate_limit_hits_total`.
- `metrics_runtime.py`, `rate_limit.py`, `audio_storage_inmemory.py` y `/metrics` instrumentan los nuevos contadores; las pruebas cubren rechazos 429 y operaciones de memoria conforme al diagnóstico DESCUBRIR.

## 2025-12-08 – Blindaje de redacción de órdenes y bootstrap SKB

- Se refuerza `CONTRATO_SKB_GOBERNANZA.md` con reglas NORTE_version_no_inventada, diferenciación CI_REAL/CI_FUTURO, definición explícita de L1/L2/L3, referencia obligatoria al último DESCUBRIR y catálogo de artefactos de IA prohibidos.
- `MUNAY_GOB_GLOBAL.md` incorpora principios anti-alucinación y la obligación de declarar la gobernanza local que los hereda.
- `CONTRATO_NEUTRO_CONTRIBUCION.md` añade checklist de realidad del NORTE, CI real y limpieza de tokens de IA.
- Se crea `PLANTILLA_ORDEN_EJECUCION_KAIZEN.md` con campos NORTE_VERSION_ACTUAL, referencia a DESCUBRIR y separación CI_REAL/CI_FUTURO.
- `BOOTSTRAP_SKB_HILO.md` ordena que la primera respuesta DESCUBRIR cite la versión real del NORTE y trate referencias inventadas a NORTE/SLOs/CI como BLOQUEO.

## 2025-12-07 – Refinos bootstrap SKB y gobernanza global/local

- `docs/BOOTSTRAP_SKB_HILO.md` ahora declara memoria cero explícita en el mensaje semilla e incluye los contratos de gobernanza (`CONTRATO_SKB_GOBERNANZA.md`, `MUNAY_GOB_GLOBAL.md`) en la fuente de verdad.
- `docs/CONTRATO_SKB_GOBERNANZA.md` clarifica que los bloqueos `ci_rota_*` evalúan la rama `main` y referencia su alineación con `MUNAY_GOB_GLOBAL.md`.
- `docs/MUNAY_GOB_GLOBAL.md` exige que cada repo Munay defina un contrato de gobernanza local (`*_GOB_LOCAL.md` o equivalente) derivado de los principios globales.

## 2025-12-06 – Bootstrap SKB, bloqueos y gobernanza global

- Se crea `docs/BOOTSTRAP_SKB_HILO.md` como mensaje semilla y protocolo oficial para hilos nuevos con SKB.
- Se extiende `docs/CONTRATO_SKB_GOBERNANZA.md` con principios de memoria cero, protocolo de arranque y catálogo de bloqueos automáticos, incluyendo manejo de órdenes multi-tema.
- Se crea `docs/MUNAY_GOB_GLOBAL.md` como contrato base de gobernanza global para futuras repos Munay.

## 2025-12-05 – Gobernanza SKB formal + CI de tests/cobertura

- Se crea el workflow `.github/workflows/ci_tests.yml` que ejecuta `pytest -q` y `pytest --cov=src --cov-fail-under=80` en push/PR a `main`.
- Se establece infraestructura de ADRs en `docs/adr/` con `ADR_TEMPLATE.md` como plantilla obligatoria.
- Se agrega `docs/CONTRATO_SKB_GOBERNANZA.md` para formalizar D→D→C, bloqueos, contracts-first y reglas de pruebas/cobertura.
- Se agrega `docs/CONTRATO_NEUTRO_CONTRIBUCION.md` como checklist previo a PR.
- Se refuerza que el CI debe validar cobertura ≥80% para aprobar PRs y que la gobernanza SKB pasa a ser contrato formal del repositorio.

## 2025-12-04 – Estandarización de cobertura con pytest-cov

- Se define `pytest --cov=src --cov-fail-under=80` como comando estándar de
  cobertura para el proyecto, asegurando un umbral mínimo de 80% de cobertura.
- Se añade `pytest-cov` a las dependencias de desarrollo (pyproject/requirements)
  para que cualquier entorno pueda ejecutar el comando de cobertura sin errores.
- Este cambio no modifica contratos ni código de runtime; formaliza la práctica
  de calidad ya aplicada localmente (17 tests en verde y ~98% de cobertura).

## 2025-12-04 – Ajuste de semántica X-Outcome para /audio

- Se actualiza `CONTRATO_NEUTRO_AUDIO_PIPELINE.md` para alinear la semántica de
  headers con la implementación actual del endpoint `/audio`:
  - Respuestas exitosas usan `X-Outcome: success` y
    `X-Outcome-Detail: audio_processed`.
  - Las respuestas de error (`4xx`/`5xx`) mantienen `X-Outcome: error` y uno de
    los códigos `audio.*` / `auth.*` definidos en la tabla de errores.
- No se realizan cambios en código; este ajuste solo sincroniza la
  documentación del contrato con el comportamiento ya cubierto por los tests
  del endpoint `/audio`.

## 2025-12-04 – Alineación contrato AudioResponseContext con implementación

- Se actualiza `CONTRATO_NEUTRO_AUDIO_PIPELINE.md` para que `AudioResponseContext`
  use `tts_url` como campo canónico de URL TTS (en lugar de `audio_url` /
  `tts_audio_url`) y documentar los campos actualmente devueltos por el stub:
  `session_id`, `corr_id`, `tts_url`, `usage.input_seconds`, `usage.output_seconds`,
  `meta`.
- Se actualiza `MUNAY_CONTRATO_MODULO_AUDIO.md` para que el contrato del módulo
  de audio en Munay consuma `tts_url` y conozca `session_id`, `corr_id` y
  `meta.context`.
- No se modifican firmas de código; este cambio sincroniza documentación con el
  comportamiento ya implementado en el endpoint `/audio`.

## 2025-12-02 – Definición del NORTE MUNAY v2.1 + validación automática

- Se crea `docs/02_ESTADO_Y_NORTE.md` como documento fuente del NORTE MUNAY v2.1:
  - Establece principios operativos.
  - Define el modelo contracts-first (contratos → historial PR → ADR → código).
  - Fija SLOs oficiales de audio, reglas de observabilidad y flujo Kaizen (L1/L2/L3).
  - Define el protocolo de inicio para nuevos hilos (repositorio como fuente de verdad).
- Se crea el workflow `validate_norte.yml` para:
  - Verificar la existencia y encabezados de:
    - `docs/02_ESTADO_Y_NORTE.md`
    - `docs/HISTORIAL_PR.md`
  - Fallar el CI cuando haya cambios en:
    - Contratos NEUTRO (`docs/CONTRATO_*`)
    - Contratos MUNAY (`docs/MUNAY_*`)
    - El propio NORTE (`docs/02_ESTADO_Y_NORTE.md`),
    que no estén acompañados por una actualización de `docs/HISTORIAL_PR.md`.
- Este cambio consolida el NORTE como contrato de gobernanza y hace obligatorio
  mantener el historial PR sincronizado con cualquier cambio de contrato o del NORTE.

## 2025-12-02 – Rate limit en /audio + métricas dinámicas

- Se implementa rate limit real sobre `/audio`, controlado por variables de entorno:
  - `RATE_LIMIT_ENABLED`
  - `RATE_LIMIT_AUDIO_WINDOW_SECONDS`
  - `RATE_LIMIT_AUDIO_MAX_REQUESTS`
- Solo se limita `/audio`; rutas `/healthz`, `/readyz`, `/version` y `/metrics` quedan en allowlist.
- Las respuestas 429 devuelven:
  - `{ "detail": "rate limit exceeded" }`
  - Headers: `X-Outcome: error`, `X-Outcome-Detail: rate_limit`, `Retry-After`.
- Se añade `InMemoryMetrics` (`metrics_runtime.py`) para registrar:
  - `sensei_requests_total{route="…"}`
  - `errors_total{route="…"}`
  y exponerlos dinámicamente en `/metrics`, manteniendo el payload estático original.
- Contratos relacionados:
  - `CONTRATO_NEUTRO_RATE_LIMIT.md`
  - `CONTRATO_NEUTRO_OBSERVABILIDAD.md`

## 2025-12-02 – Pipeline de audio + storage de sesiones + headers Munay

- Se define el contrato lógico del pipeline de audio:
  - `CONTRATO_NEUTRO_AUDIO_PIPELINE.md`:
    - `AudioRequestContext`, `UsageMetrics`, `AudioResponseContext`, `PipelineError`.
    - Interfaz `AudioPipeline.process(ctx)`.
- Se implementa `StubAudioPipeline` en `audio_pipeline_stub.py`:
  - Valida `api_key`, tipo MIME y que el audio no esté vacío.
  - Genera respuesta stub con `transcript`, `reply_text`, `usage` y `session_id`.
- Se añade storage en memoria de sesiones de audio:
  - `audio_storage_inmemory.py` con `AudioSession` e `InMemoryAudioSessionRepository`.
  - `DEFAULT_AUDIO_SESSION_REPOSITORY` compartido.
  - Contrato documentado en `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`.
- El endpoint `/audio` ahora:
  - Acepta `multipart/form-data` con campo `file`.
  - Usa `X-API-Key` y `X-Correlation-Id`.
  - Acepta headers cliente Munay:
    - `x-munay-user-id`
    - `x-munay-context` (valores válidos: `diario_emocional`, `coach_habitos`, `reflexion_general`).
  - Rechaza contextos inválidos con 400 y `X-Outcome-Detail: audio.bad_request`.
  - Propaga `munay_user_id` y `munay_context` como metadatos hacia la sesión de audio:
    - `user_external_id`
    - `meta_tags["context"]`
- Se añaden tests de contrato de `/audio`:
  - `tests/test_audio_contract.py` cubre:
    - Happy path.
    - Errores por MIME inválido, audio vacío, falta de API key.
    - Persistencia en `DEFAULT_AUDIO_SESSION_REPOSITORY`.
    - Enriquecimiento con headers Munay.
- Contratos relacionados:
  - `CONTRATO_NEUTRO_AUDIO.md`
  - `CONTRATO_NEUTRO_AUDIO_PIPELINE.md`
  - `CONTRATO_NEUTRO_STORAGE_SESIONES_AUDIO.md`
  - `MUNAY_CONTRATO_MODULO_AUDIO.md`
  - `MUNAY_CONTRATO_PROGRESO_USUARIO.md`

## 2025-12-02 – Ajuste contratos de headers y observabilidad

- Se aclara la semántica de headers estándar en `CONTRATO_NEUTRO_HEADERS.md`:
  - `X-Outcome` es obligatorio en todas las respuestas:
    - `ok` para 2xx
    - `error` para 4xx/5xx
  - `X-Outcome-Detail` se reserva para errores (`X-Outcome=error`).
- Se garantiza que `/healthz`, `/readyz`, `/version` y `/metrics`:
  - Siempre incluyen `X-Outcome`.
  - Se integran con las métricas dinámicas a través de `METRICS.inc_request(route)`.
- Se mantiene el payload estático de `/metrics` para compatibilidad con tests previos,
  añadiendo solo líneas dinámicas para contadores por ruta.
</file>

</files>
